<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />



<meta name="date" content="2025-11-09" />

<title>RPP norming tutorial</title>

<script src="site_libs/header-attrs-2.27/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="tutorial.html">MRP Norming Tutorial</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/TaymAlsalti/MRP_Norming">
    <span class="fa fa-github"></span>
     
    
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">RPP norming tutorial</h1>
<h4 class="date">2025-11-09</h4>

</div>


<style>
.main-container {
  max-width: 1400px !important;  /* Adjust the width as needed */
}

pre, code {
  white-space: pre-wrap;  /* Ensures that long lines wrap */
  word-wrap: break-word;  /* Breaks long words if necessary */
}

pre {
  max-width: 100% !important;
  width: 100% !important;
  overflow-x: auto !important; /* Add horizontal scrollbar if content overflows */
  white-space: pre-line !important; /* Convert line breaks to spaces */
  word-wrap: break-word !important; /* Break long words if necessary */
  word-break: break-all !important; /* Break words to fit the container */
  font-size: 14px !important; /* Adjust font size if needed */
}

</style>
<pre class="r"><code>knitr::opts_chunk$set(
    message = FALSE,
    warning = T,
    include = TRUE,
    error = TRUE,
    fig.width = 8,
    fig.height = 4
)

library(tidyverse)
library(haven)
library(data.table)
library(ggrepel)
library(kableExtra)
library(brms)
library(tidybayes)
library(marginaleffects)
library(bayesplot)
library(rstan)

# depending on the platform on which you want to run the brm you might need this or not. We ran the models on a Linux-operated server
options(mc.cores = 4,
        brms.backend = &quot;cmdstanr&quot;,
        scipen = 999,
        digits = 4,
        width = 120)

# windowsFonts(Times = windowsFont(&quot;Times New Roman&quot;))
theme_set(theme_minimal(base_size = 12, base_family = &quot;Times&quot;))

## load preprocessed datasets (see preprocessing code below)

sb_data &lt;- readRDS(&quot;data/preprocessed/wordsum/sb_data.rds&quot;)
census_sb &lt;- readRDS(&quot;data/preprocessed/us_census/census_sb.rds&quot;)


# RPP/RPP function
source(&quot;age_norm_comparisons.R&quot;)</code></pre>
<div id="data-preprocessing" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Data preprocessing</h1>
<div id="sample-data" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Sample data</h2>
<pre class="r"><code># load dataset after basic cleaning and labelling (see github.com/synth-science/synth-rep-dataset for the raw data and basic cleaning code)
sb_raw &lt;- read_rds(&quot;data/raw/sb/sosci_labelled.rds&quot;) 


OCC_classification &lt;- readxl::read_xlsx(path = &quot;data/raw/sb/OCC_classification.xlsx&quot;, sheet = &quot;classification_table&quot; ) %&gt;% 
  mutate(occ = as.character(occ_occupation)) 

# load the degfield classification table

degfield_hierarchy &lt;- readxl::read_excel(&quot;data/raw/sb/degfield_hierarchy.xlsx&quot;) %&gt;% # contains a classification of the general codes into larger categories based on this wikipedia article: https://en.wikipedia.org/wiki/Outline_of_academic_disciplines
  mutate(
    degfield_label = str_to_lower(degfield_label),
    degfield_category = str_to_lower(degfield_category),
    degfield_alternative_category = str_to_lower(degfield_alternative_category))

divisions &lt;- list(
  new_england = c(&quot;connecticut&quot;, &quot;maine&quot;, &quot;massachusetts&quot;, &quot;new hampshire&quot;, &quot;rhode island&quot;, &quot;vermont&quot;),
  middle_atlantic = c(&quot;new jersey&quot;, &quot;new york&quot;, &quot;pennsylvania&quot;),
  east_north_central = c(&quot;illinois&quot;, &quot;indiana&quot;, &quot;michigan&quot;, &quot;ohio&quot;, &quot;wisconsin&quot;),
  west_north_central = c(&quot;iowa&quot;, &quot;kansas&quot;, &quot;minnesota&quot;, &quot;missouri&quot;, &quot;nebraska&quot;, &quot;north dakota&quot;, &quot;south dakota&quot;),
  south_atlantic = c(&quot;delaware&quot;, &quot;district of columbia&quot;, &quot;florida&quot;, &quot;georgia&quot;, &quot;maryland&quot;, 
                     &quot;north carolina&quot;, &quot;south carolina&quot;, &quot;virginia&quot;, &quot;west virginia&quot;),
  east_south_central = c(&quot;alabama&quot;, &quot;kentucky&quot;, &quot;mississippi&quot;, &quot;tennessee&quot;),
  west_south_central = c(&quot;arkansas&quot;, &quot;louisiana&quot;, &quot;oklahoma/indian territory&quot;, &quot;oklahoma&quot;, &quot;texas&quot;),
  mountain = c(&quot;arizona&quot;, &quot;colorado&quot;, &quot;idaho&quot;, &quot;montana&quot;, &quot;nevada&quot;, &quot;new mexico&quot;, &quot;utah&quot;, &quot;wyoming&quot;),
  pacific = c(&quot;alaska&quot;, &quot;california&quot;, &quot;hawaii&quot;, &quot;oregon&quot;, &quot;washington&quot;)
)


sb_data &lt;- sb_raw %&gt;% 
  select(pid = CASE,
         starts_with(&quot;SD&quot;),
         gender,
         starts_with(&quot;WS&quot;)) %&gt;%
  rename(educ = SD08,
         occ = SD10) %&gt;%
    setNames(sapply(names(.), function(x) {
    label &lt;- attr(sb_raw[[x]], &quot;label&quot;, exact = TRUE)
    if (!is.null(label)) label else x
  })) %&gt;% 
  rename_all(tolower) %&gt;% 
  rename(age = &quot;age: [01]&quot;,
         inctot = &quot;inctot: [01]&quot;) %&gt;% 
  left_join(OCC_classification %&gt;% select(occ, occ_category),
            by = &quot;occ&quot;) %&gt;% # to classify the occ variable merge with the OCC_classification df
    mutate(across(where(~ is.character(.) || is.factor(.) || inherits(., &quot;labelled&quot;)),
                ~ if (is.factor(.)) {
                    factor(tolower(as.character(.)))
                  } else if (inherits(., &quot;labelled&quot;)) {
                    haven::labelled(tolower(as.character(.)), attr(., &quot;labels&quot;))
                  } else {
                    tolower(.)
                  })) %&gt;% 
  left_join(degfield_hierarchy %&gt;% select(degfield_label, degfield_category), # to categorize degfield merge with degfield_hierarchy
            by = c(&quot;degfield&quot; = &quot;degfield_label&quot;)) %&gt;% 
  rename_all(~ gsub(&quot; &quot;, &quot;_&quot;, .)) %&gt;% 
  rename_all(~ gsub(&quot;-&quot;, &quot;&quot;, .)) %&gt;% 
  mutate(
      region_birth = case_when(
        bpl_state %in% divisions$new_england ~ &quot;new england division&quot;,
        bpl_state %in% divisions$middle_atlantic ~ &quot;middle atlantic division&quot;,
        bpl_state %in% divisions$east_north_central ~ &quot;east north central division&quot;,
        bpl_state %in% divisions$west_north_central ~ &quot;west north central division&quot;,
        bpl_state %in% divisions$south_atlantic ~ &quot;south atlantic division&quot;,
        bpl_state %in% divisions$east_south_central ~ &quot;east south central division&quot;,
        bpl_state %in% divisions$west_south_central ~ &quot;west south central division&quot;,
        bpl_state %in% divisions$mountain ~ &quot;mountain division&quot;,
        bpl_state %in% divisions$pacific ~ &quot;pacific division&quot;,
        TRUE ~ &quot;abroad&quot;
      ),
      region_residence = case_when(
        state %in% divisions$new_england ~ &quot;new england division&quot;,
        state %in% divisions$middle_atlantic ~ &quot;middle atlantic division&quot;,
        state %in% divisions$east_north_central ~ &quot;east north central division&quot;,
        state %in% divisions$west_north_central ~ &quot;west north central division&quot;,
        state %in% divisions$south_atlantic ~ &quot;south atlantic division&quot;,
        state %in% divisions$east_south_central ~ &quot;east south central division&quot;,
        state %in% divisions$west_south_central ~ &quot;west south central division&quot;,
        state %in% divisions$mountain ~ &quot;mountain division&quot;,
        state %in% divisions$pacific ~ &quot;pacific division&quot;,
        TRUE ~ &quot;abroad&quot;
      ),
    income_brackets = cut(as.integer(inctot),
                        breaks = c(-Inf, 1000, 6000, 12500, 22500, 35000, 50000, 60000, 75000, 90000, 110000, Inf),
                        ordered_result = FALSE,
                        labels = c(&quot;&lt; $1,000&quot;, &quot;$1,000 - $5,999&quot;, &quot;$6,000 - $12,499&quot;, &quot;$12,500 - $22,499&quot;, 
                                   &quot;$22,500 - $34,999&quot;, &quot;$35,000 - $49,999&quot;, &quot;$50,000 - $59,999&quot;, 
                                   &quot;$60,000 - $74,999&quot;, &quot;$75,000 - $89,999&quot;, &quot;$90,000 - $109,999&quot;, &quot;&gt;$110,000&quot;)),
    educ = case_when(
      educ %in% c(&quot;n/a or no schooling&quot;, 
                  &quot;grade 5, 6, 7, or 8&quot;, 
                  &quot;grade 9&quot;, 
                  &quot;grade 10&quot;,
                  &quot;grade 11&quot;,
                  &quot;grade 12&quot;) ~ &quot;high school or less&quot;,
      educ == &quot;3 years of college&quot; ~ &quot;2 years of college&quot;,
      TRUE ~ educ # Retain other categories as they are
    ),
    female = sex == &quot;female&quot;,
    hispan = hispan != &quot;no, not of hispanic, latino, or spanish origin&quot;,
    marst = case_when(
      marst %in% c(&quot;divorced&quot;, &quot;separated&quot;, &quot;widowed&quot;) ~ &quot;separated, widowed, or divorced&quot;,
      TRUE ~ marst # Keep other categories as is
    ),
    race = case_when(
      race %in% c(&quot;chinese&quot;,
                  &quot;japanese&quot;,
                  &quot;other asian or pacific islander&quot;,
                  &quot;american indian or alaska native&quot;,
                  &quot;other race&quot;) ~ &quot;other&quot;,
      race %in% c(&quot;three or more major races&quot;,
                  &quot;two major races (e.g., white and japanese)&quot;) ~ &quot;two or more major races&quot;,
      TRUE ~ race # Keep other categories as is
    ),
    degfield_branch = case_when(
      degfield_category %in% c(&quot;formal sciences&quot;, &quot;interdisciplinary and multi-disciplinary studies (general)&quot;, &quot;natural sciences&quot;) ~ &quot;natural, formal, and other sciences&quot;,
      is.na(degfield_category) ~ &quot;n/a&quot;,
      TRUE ~ degfield_category
    ),
    occ_category = case_when(
      occ_category %in% c(&quot;Natural Resources, Construction, and Maintenance Occupations&quot;, &quot;Service Occupations&quot;) ~
        &quot;other&quot;,
      is.na(occ_category) ~ &quot;n/a: unemployed&quot;,
      TRUE ~ occ_category
    ),
         wordsum_1 =  if_else(wordsum_1 == 4, 1, 0),
         wordsum_2 =  if_else(wordsum_2 == 5, 1, 0),
         wordsum_3 =  if_else(wordsum_3 == 5, 1, 0),
         wordsum_4 =  if_else(wordsum_4 == 3, 1, 0),
         wordsum_5 =  if_else(wordsum_5 == 1, 1, 0),
         wordsum_6 =  if_else(wordsum_6 == 3, 1, 0),
         wordsum_7 =  if_else(wordsum_7 == 5, 1, 0),
         wordsum_8 =  if_else(wordsum_8 == 4, 1, 0),
         wordsum_9 =  if_else(wordsum_9 == 4, 1, 0),
         wordsum_10 = if_else(wordsum_10 == 1, 1, 0),
         wordsum = wordsum_1 + wordsum_2 + wordsum_3 + wordsum_4 + wordsum_5 + wordsum_6 + wordsum_7 + wordsum_8 + wordsum_9 + wordsum_10,
         wordsum_ordinal = as.ordered(wordsum),
         censoring = case_when(
           wordsum == 0 ~ &quot;left&quot;,
           wordsum == 10 ~ &quot;right&quot;,
           TRUE ~ &quot;none&quot;
           
         )
  ) %&gt;%
  select(pid, age, female, educ, income_brackets, income = inctot, race, hispan, region_residence, state, region_birth, degfield_branch, marst, occ_category, starts_with(&quot;wordsum&quot;), censoring) %&gt;%
  filter(complete.cases(.)) %&gt;%
  left_join(sb_raw %&gt;% rename(pid = &quot;CASE&quot;), by = &quot;pid&quot;) %&gt;% 
    select(-ends_with(&quot;_R&quot;))


saveRDS(sb_data, &quot;data/preprocessed/wordsum/sb_data.rds&quot;)


ggplot(sb_data, aes(x = wordsum)) +
    geom_histogram(bins = 11, fill = &quot;blue&quot;, color = &quot;black&quot;) +  # Set bins to 11 for values 0 to 10
    scale_x_continuous(breaks = 0:10) +  # Set x-axis breaks for each possible value
    labs(x = &quot;Wordsum score&quot;, 
         y = &quot;Frequency&quot;) +  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.background = element_rect(fill = &quot;transparent&quot;, color = NA),
        # panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) + 
  geom_text(stat = &#39;count&#39;, aes(label = after_stat(count)), 
            vjust = -0.5,  # Adjust vertical position of labels
            color = &quot;black&quot;)  # Color of the labels</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-1-1.svg" width="768" /></p>
</div>
<div id="census-data" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Census data</h2>
<pre class="r"><code>census_sb_raw &lt;- setDT(read_dta(&quot;data/raw/us_census/usa_00015.dta.gz&quot;))

OCC_classification &lt;- readxl::read_xlsx(path = &quot;data/raw/sb/OCC_classification.xlsx&quot;, sheet = &quot;classification_table&quot; ) %&gt;% 
  mutate(occ = as.character(occ),
         occ_category = tolower(as.character(occ_category))) # change class to character

# Convert labelled columns to factors
census_sb_raw &lt;- census_sb_raw %&gt;%
  mutate_if(haven::is.labelled, as_factor)

# Convert to data.table
census_sb_raw &lt;- as.data.table(census_sb_raw)

# Define income brackets
income_breaks &lt;- c(-Inf, 1000, 6000, 12500, 22500, 35000, 50000, 60000, 75000, 90000, 110000, Inf)
income_labels &lt;- c(&quot;&lt; $1,000&quot;, &quot;$1,000 - $5,999&quot;, &quot;$6,000 - $12,499&quot;, &quot;$12,500 - $22,499&quot;, 
                   &quot;$22,500 - $34,999&quot;, &quot;$35,000 - $49,999&quot;, &quot;$50,000 - $59,999&quot;, 
                   &quot;$60,000 - $74,999&quot;, &quot;$75,000 - $89,999&quot;, &quot;$90,000 - $109,999&quot;, &quot;&gt;$110,000&quot;)

# Main processing
census_sb &lt;- census_sb_raw[, `:=`(
  income_brackets = cut(as.integer(inctot), breaks = income_breaks, labels = income_labels, ordered_result = TRUE)
)][, .(census_n = sum(perwt)), by = .(state = statefip, sex, age, marst, race, hispan, bpl, educ, degfield, occ, income_brackets)]

# Convert columns to factors and lowercase
factor_cols &lt;- c(&quot;state&quot;, &quot;sex&quot;, &quot;marst&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;bpl&quot;, &quot;educ&quot;, &quot;degfield&quot;, &quot;occ&quot;, &quot;income_brackets&quot;)
census_sb[, (factor_cols) := lapply(.SD, function(x) factor(tolower(as.character(x)))), .SDcols = factor_cols]

OCC_classification &lt;- as.data.table(OCC_classification)

degfield_hierarchy &lt;- as.data.table(degfield_hierarchy)
# Join with OCC_classification and degfield_hierarchy
census_sb &lt;- merge(census_sb, OCC_classification[, .(occ, occ_category)], by = &quot;occ&quot;, all.x = TRUE)
census_sb &lt;- merge(census_sb, degfield_hierarchy[, .(degfield_label, degfield_category)], by.x = &quot;degfield&quot;, by.y = &quot;degfield_label&quot;, all.x = TRUE)

# Apply transformations
census_sb[, `:=`(
region_birth = fcase(
  bpl %in% divisions$new_england, &quot;new england division&quot;,
  bpl %in% divisions$middle_atlantic, &quot;middle atlantic division&quot;,
  bpl %in% divisions$east_north_central, &quot;east north central division&quot;,
  bpl %in% divisions$west_north_central, &quot;west north central division&quot;,
  bpl %in% divisions$south_atlantic, &quot;south atlantic division&quot;,
  bpl %in% divisions$east_south_central, &quot;east south central division&quot;,
  bpl %in% divisions$west_south_central, &quot;west south central division&quot;,
  bpl %in% divisions$mountain, &quot;mountain division&quot;,
  bpl %in% divisions$pacific, &quot;pacific division&quot;,
  default = &quot;abroad&quot;
),
region_residence = fcase(
  state %in% divisions$new_england, &quot;new england division&quot;,
  state %in% divisions$middle_atlantic, &quot;middle atlantic division&quot;,
  state %in% divisions$east_north_central, &quot;east north central division&quot;,
  state %in% divisions$west_north_central, &quot;west north central division&quot;,
  state %in% divisions$south_atlantic, &quot;south atlantic division&quot;,
  state %in% divisions$east_south_central, &quot;east south central division&quot;,
  state %in% divisions$west_south_central, &quot;west south central division&quot;,
  state %in% divisions$mountain, &quot;mountain division&quot;,
  state %in% divisions$pacific, &quot;pacific division&quot;,
  default = &quot;abroad&quot;
),
  age = as.numeric(age),
  female = sex == &quot;female&quot;,
  marst = fcase(
    marst %in% c(&quot;married, spouse present&quot;, &quot;married, spouse absent&quot;), &quot;married&quot;,
    marst %in% c(&quot;divorced&quot;, &quot;separated&quot;, &quot;widowed&quot;), &quot;separated, widowed, or divorced&quot;,
    default = as.character(marst)
  ),
  educ = fcase(
    educ %in% c(&quot;nursery school to grade 4&quot;, &quot;n/a or no schooling&quot;, &quot;grade 5, 6, 7, or 8&quot;, &quot;grade 9&quot;, &quot;grade 10&quot;, &quot;grade 11&quot;, &quot;grade 12&quot;), &quot;high school or less&quot;,
    default = as.character(educ)
  ),
  hispan = hispan != &quot;not hispanic&quot;,
  race = fcase(
    race %in% c(&quot;chinese&quot;, &quot;japanese&quot;, &quot;other asian or pacific islander&quot;, &quot;american indian or alaska native&quot;, &quot;other race, nec&quot;), &quot;other&quot;,
    race %in% c(&quot;three or more major races&quot;, &quot;two major races&quot;), &quot;two or more major races&quot;,
    default = as.character(race)
  ),
  degfield_branch = fcase(
    degfield_category %in% c(&quot;formal sciences&quot;, &quot;interdisciplinary and multi-disciplinary studies (general)&quot;, &quot;natural sciences&quot;), &quot;natural, formal, and other sciences&quot;,
    is.na(degfield_category), &quot;n/a&quot;,
    default = as.character(degfield_category)
  ),
  occ_category = fcase(
    occ_category %in% c(&quot;Natural Resources, Construction, and Maintenance Occupations&quot;, &quot;Service Occupations&quot;), &quot;other&quot;,
    default = as.character(occ_category)
  )
)]

# Select and filter
census_sb &lt;- census_sb[, .SD, .SDcols = !c(&quot;degfield&quot;, &quot;bpl&quot;, &quot;state&quot;, &quot;occ&quot;, &quot;degfield_category&quot;, &quot;sex&quot;)]
census_sb &lt;- census_sb[between(age, 21, 67)]

# Convert remaining columns to factors
factor_cols &lt;- names(census_sb)[sapply(census_sb, is.character)]
census_sb[, (factor_cols) := lapply(.SD, as.factor), .SDcols = factor_cols]

census_sb &lt;- census_sb %&gt;% 
  relocate(census_n, .after = &quot;degfield_branch&quot;) %&gt;% 
  group_by(age, female, educ, income_brackets, race, hispan, region_residence, region_birth, degfield_branch, marst, occ_category) %&gt;% 
  summarise(census_n = sum(census_n)) %&gt;% 
  ungroup()

saveRDS(census_sb, &quot;data/preprocessed/us_census/census_sb.rds&quot;)</code></pre>
<pre class="r"><code>census_sb %&gt;% head(14) %&gt;% kable(digits = 2) %&gt;% kable_styling(full_width = FALSE)</code></pre>
<table class="table" style="color: black; width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
age
</th>
<th style="text-align:left;">
female
</th>
<th style="text-align:left;">
educ
</th>
<th style="text-align:left;">
income_brackets
</th>
<th style="text-align:left;">
race
</th>
<th style="text-align:left;">
hispan
</th>
<th style="text-align:left;">
region_residence
</th>
<th style="text-align:left;">
region_birth
</th>
<th style="text-align:left;">
degfield_branch
</th>
<th style="text-align:left;">
marst
</th>
<th style="text-align:left;">
occ_category
</th>
<th style="text-align:right;">
census_n
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
abroad
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
n/a: unemployed
</td>
<td style="text-align:right;">
321
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
abroad
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
sales and office occupations
</td>
<td style="text-align:right;">
29
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
management, business, science, and arts occupations
</td>
<td style="text-align:right;">
122
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
n/a: unemployed
</td>
<td style="text-align:right;">
2776
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
production, transportation, and material moving occupations
</td>
<td style="text-align:right;">
305
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
sales and office occupations
</td>
<td style="text-align:right;">
400
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
service occupations
</td>
<td style="text-align:right;">
567
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
middle atlantic division
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
n/a: unemployed
</td>
<td style="text-align:right;">
31
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
new england division
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
sales and office occupations
</td>
<td style="text-align:right;">
35
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
pacific division
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
service occupations
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
south atlantic division
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
n/a: unemployed
</td>
<td style="text-align:right;">
123
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
south atlantic division
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
sales and office occupations
</td>
<td style="text-align:right;">
67
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
west north central division
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
production, transportation, and material moving occupations
</td>
<td style="text-align:right;">
21
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
1 year of college
</td>
<td style="text-align:left;">
&lt; $1,000
</td>
<td style="text-align:left;">
black/african american
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:left;">
east north central division
</td>
<td style="text-align:left;">
west north central division
</td>
<td style="text-align:left;">
n/a
</td>
<td style="text-align:left;">
never married/single
</td>
<td style="text-align:left;">
sales and office occupations
</td>
<td style="text-align:right;">
22
</td>
</tr>
</tbody>
</table>
</div>
<div id="check-that-the-two-sources-have-the-same-variable-categories"
class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Check that the two
sources have the same variable categories</h2>
<pre class="r"><code>cat_sizes_census &lt;- census_sb %&gt;%
  select(-age, -census_n) %&gt;%
  map_dfr(~ count(tibble(Category = as.character(.x)), Category), 
          .id = &quot;Variable&quot;) %&gt;%
  arrange(Variable, Category)


cat_sizes_sb &lt;- sb_data %&gt;%
   select(-age, -wordsum, -id) %&gt;%
  map_dfr(~ count(tibble(Category = as.character(.x)), Category), 
          .id = &quot;Variable&quot;) %&gt;%
  arrange(Variable, Category)</code></pre>
<pre><code>## Error in `select()`:
## ! Can&#39;t select columns that don&#39;t exist.
## ✖ Column `id` doesn&#39;t exist.</code></pre>
<pre class="r"><code>anti_join(cat_sizes_census, cat_sizes_sb, by = &quot;Category&quot;)</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;cat_sizes_sb&#39; not found</code></pre>
</div>
</div>
<div id="distributional-disparities" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Distributional
disparities</h1>
<p>Before applying RPP to correct estimates (be it for norming or other
purposes), it’s worthwhile to check if there are any differences between
the sample and the population (on which we have data from the census)
with respect to the variables we wish to use for the correction.</p>
<pre class="r"><code>aggregated_sample &lt;- sb_data %&gt;% 
               filter(between(age, 21, 67)) %&gt;% 
               mutate(across(-c(starts_with(&quot;wordsum&quot;), censoring, pid, age, female, hispan, income_brackets), as.factor)) %&gt;% 
  group_by(age, female, educ, income_brackets, race, hispan, region_residence, region_birth, degfield_branch, marst, occ_category) %&gt;% 
  summarise(sample_n = n()) %&gt;% ungroup()

disparities_plot &lt;- census_sb %&gt;% 
  full_join(aggregated_sample, by = c(&quot;age&quot;, &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, &quot;region_birth&quot;, &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;)) %&gt;% 
  mutate(sample_n = replace_na(sample_n, 0),
         census_n = replace_na(census_n, 0),
         occ_category = case_when(
           occ_category == &quot;management, business, science, and arts occupations&quot; ~ &quot;MBSA&quot;,
           occ_category == &quot;sales and office occupations&quot; ~ &quot;SO&quot;,
           occ_category == &quot;production, transportation, and material moving occupations&quot; ~ &quot;PTMM&quot;,
           occ_category == &quot;service occupations&quot; ~ &quot;S&quot;,
           occ_category == &quot;natural resources, construction, and maintenance occupations&quot; ~ &quot;NRCM&quot;,
           TRUE ~ occ_category
         )) %&gt;%
  pivot_longer(cols = c(census_n:sample_n), names_to = &quot;source&quot;, values_to = &quot;n&quot;) %&gt;% 
  mutate(source = str_sub(source, 1, -3),
         n = replace_na(n, 0))  %&gt;%
  mutate(across(-c(n), as.factor)) %&gt;% 
pivot_longer(cols = -c(n, source), names_to = &quot;variable&quot;, values_to = &quot;category&quot;) %&gt;% 
  group_by(source, variable, category) %&gt;% 
  summarise(n = sum(n)) %&gt;% 
  mutate(percentage = n/sum(n)*100)

# plot age disparities
disparities_plot %&gt;%
  filter(variable == &quot;age&quot;) %&gt;% 
  ggplot(aes(x = category, y = percentage, group = source, colour = source, label = round(percentage, digits = 1))) +
  theme_minimal(base_size = 9, base_family = &quot;Times&quot;) +
  geom_line(linewidth = .5) +
  facet_grid(cols = vars(variable), scales = &quot;free&quot;, space = &#39;free&#39;, as.table = TRUE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = &quot;none&quot;, 
        # legend.justification = c(1, 1), 
        legend.background = element_rect(fill = &quot;transparent&quot;, color = NA),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.x = element_line(linetype = &quot;dashed&quot;, size = 0.3)) + 
  labs(x = &quot;&quot;, y = &quot;Percentage&quot;, colour = &quot;&quot;, label = &quot;Percentage&quot;) +
  scale_colour_manual(values = c(&quot;#0072B5FF&quot;, &quot;#BC3C29FF&quot;), labels = function(x) str_to_title(x)) +
  scale_x_discrete(breaks = seq(21, 67, by = 2))</code></pre>
<pre><code>## Warning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.
## ℹ Please use the `linewidth` argument instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-5-1.svg" width="960" /></p>
<pre class="r"><code># ggsave(&quot;p.jpeg&quot;, height = 2, width = 10)</code></pre>
<pre class="r"><code>disparities_plot %&gt;%
  mutate(category = case_when(
    variable == &quot;educ&quot; ~ factor(category, levels = c(&quot;high school or less&quot;, &quot;1 year of college&quot;, &quot;2 years of college&quot;, &quot;4 years of college&quot;, &quot;5+ years of college&quot;)),
    variable == &quot;income_brackets&quot; ~ factor(category, levels = c(&quot;&lt; $1,000&quot;, &quot;$1,000 - $5,999&quot;, &quot;$6,000 - $12,499&quot;, &quot;$12,500 - $22,499&quot;, &quot;$22,500 - $34,999&quot;, &quot;$35,000 - $49,999&quot;, &quot;$50,000 - $59,999&quot;, &quot;$60,000 - $74,999&quot;, &quot;$75,000 - $89,999&quot;, &quot;$90,000 - $109,999&quot;, &quot;&gt;$110,000&quot;)),
    variable == &quot;degfield_branch&quot; ~ factor(category, levels = c(&quot;n/a&quot;, &quot;humanities&quot;, &quot;social sciences&quot;, &quot;applied sciences and professions&quot;,   &quot;natural, formal, and other sciences&quot;)),
    variable == &quot;occ_category&quot; ~ factor(category, levels = c(&quot;n/a: unemployed&quot;, &quot;MBSA&quot;, &quot;SO&quot;, &quot;S&quot;, &quot;NRCM&quot;, &quot;PTMM&quot;)),
    variable == &quot;race&quot; ~ factor(category, levels = c(&quot;white&quot;, &quot;black/african american&quot;, &quot;two or more major races&quot;, &quot;other&quot;)),
    variable == &quot;region_birth&quot; ~ factor(category, levels = c(&quot;abroad&quot;, &quot;pacific division&quot;, &quot;middle atlantic division&quot;, &quot;new england division&quot;, &quot;mountain division&quot;, &quot;east south central division&quot;, &quot;south atlantic division&quot;, &quot;west south central division&quot;, &quot;east north central division&quot;, &quot;west north central division&quot;)),
    TRUE ~ category
  )) %&gt;% 
  filter(variable != &quot;age&quot;) %&gt;% 
  ggplot(aes(x = category, y = percentage, group = source, colour = source, label = round(percentage, digits = 1))) +
  theme_minimal(base_size = 9, base_family = &quot;Times&quot;) +
  geom_line(linewidth = .5) +
  facet_grid(cols = vars(variable), scales = &quot;free&quot;, space = &#39;free&#39;) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1),
        legend.position = c(1, 1.08), 
        legend.justification = c(1, 1), 
        legend.background = element_rect(fill = &quot;transparent&quot;, color = NA),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.x = element_line(linetype = &quot;dashed&quot;, size = 0.3),
        plot.margin = margin(0, 0, 0, .05, &quot;cm&quot;)) + 
  labs(x = &quot;Category&quot;, y = &quot;Percentage&quot;, colour = &quot;&quot;, label = &quot;Percentage&quot;) +
  scale_colour_manual(values = c(&quot;#0072B5FF&quot;, &quot;#BC3C29FF&quot;), labels = function(x) str_to_title(x))</code></pre>
<pre><code>## Warning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2 3.5.0.
## ℹ Please use the `legend.position.inside` argument of `theme()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-6-1.svg" width="864" /></p>
<pre class="r"><code># ggsave(&quot;p.jpeg&quot;, height = 3, width = 9)</code></pre>
</div>
<div id="regularised-prediction-model" class="section level1"
number="3">
<h1><span class="header-section-number">3</span> Regularised prediction
model</h1>
<div id="model-comparison" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Model comparison</h2>
<p>Terms of this form <code>(1 | variable)</code> represent random
intercepts, <code>female</code> and <code>hispan</code> were included as
a fixed effect to avoid estimation problems due to the small number of
categories, <code>s(age)</code> is a thin plate spline of age.</p>
<div id="normal-with-interactions" class="section level3"
number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Normal with
interactions</h3>
<pre class="r"><code>library(tidyverse)
library(brms)
options(mc.cores = 20,
        threads = threading(5, static = TRUE),
        brms.backend = &quot;cmdstanr&quot;)
sb_data &lt;- readRDS(&quot;data/preprocessed/wordsum/sb_data.rds&quot;) 
rstan::rstan_options(auto_write = TRUE)

  

sb_data_scaled &lt;- sb_data %&gt;% 
  mutate(age = scale(age),
         wordsum = scale(wordsum))

brm_1 &lt;- brm(bf(wordsum ~ s(age, by = educ) + (1 | educ) + female + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + (1 | income_brackets) +
(1 | educ:race) +
(1 | educ:hispan) +
(1 | educ:region_residence) +
(1 | educ:marst) +
(1 | educ:degfield_branch) +
(1 | educ:occ_category) +
(1 | educ:region_birth) +
(1 | educ:income_brackets) +
(1 | race:hispan) +
(1 | race:region_residence) +
(1 | race:marst) +
(1 | race:degfield_branch) +
(1 | race:occ_category) +
(1 | race:region_birth) +
(1 | race:income_brackets) +
(1 | hispan:region_residence) +
(1 | hispan:marst) +
(1 | hispan:degfield_branch) +
(1 | hispan:occ_category) +
(1 | hispan:region_birth) +
(1 | hispan:income_brackets) +
(1 | region_residence:marst) +
(1 | region_residence:degfield_branch) +
(1 | region_residence:occ_category) +
(1 | region_residence:region_birth) +
(1 | region_residence:income_brackets) +
(1 | marst:degfield_branch) +
(1 | marst:occ_category) +
(1 | marst:region_birth) +
(1 | marst:income_brackets) +
(1 | degfield_branch:occ_category) +
(1 | degfield_branch:region_birth) +
(1 | degfield_branch:income_brackets) +
(1 | occ_category:region_birth) +
(1 | occ_category:income_brackets) +
(1 | region_birth:income_brackets) +
(1 | female:educ) +
(1 | female:race) +
(1 | female:hispan) +
(1 | female:region_residence) +
(1 | female:marst) +
(1 | female:degfield_branch) +
(1 | female:occ_category) +
(1 | female:region_birth) +
(1 | female:income_brackets),
                   sigma ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets)
                   ),
    seed = 14,
    chains = 4,
    prior = prior(normal(0,1), class = &quot;b&quot;) +
            prior(normal(0,3), class = &quot;Intercept&quot;) +
            prior(exponential(1), class = &quot;sd&quot;) + 
            prior(exponential(1), class = &quot;sds&quot;),
    file = &quot;data/brms/wordsum/sb/brm_1&quot;,
    data = sb_data_scaled) %&gt;%
  add_criterion(&quot;loo&quot;)

brm_1</code></pre>
<pre><code>## Warning: There were 35 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = log 
## Formula: wordsum ~ s(age, by = educ) + (1 | educ) + female + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + (1 | income_brackets) + (1 | educ:race) + (1 | educ:hispan) + (1 | educ:region_residence) + (1 | educ:marst) + (1 | educ:degfield_branch) + (1 | educ:occ_category) + (1 | educ:region_birth) + (1 | educ:income_brackets) + (1 | race:hispan) + (1 | race:region_residence) + (1 | race:marst) + (1 | race:degfield_branch) + (1 | race:occ_category) + (1 | race:region_birth) + (1 | race:income_brackets) + (1 | hispan:region_residence) + (1 | hispan:marst) + (1 | hispan:degfield_branch) + (1 | hispan:occ_category) + (1 | hispan:region_birth) + (1 | hispan:income_brackets) + (1 | region_residence:marst) + (1 | region_residence:degfield_branch) + (1 | region_residence:occ_category) + (1 | region_residence:region_birth) + (1 | region_residence:income_brackets) + (1 | marst:degfield_branch) + (1 | marst:occ_category) + (1 | marst:region_birth) + (1 | marst:income_brackets) + (1 | degfield_branch:occ_category) + (1 | degfield_branch:region_birth) + (1 | degfield_branch:income_brackets) + (1 | occ_category:region_birth) + (1 | occ_category:income_brackets) + (1 | region_birth:income_brackets) + (1 | female:educ) + (1 | female:race) + (1 | female:hispan) + (1 | female:region_residence) + (1 | female:marst) + (1 | female:degfield_branch) + (1 | female:occ_category) + (1 | female:region_birth) + (1 | female:income_brackets) 
##          sigma ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets)
##    Data: sb_data_scaled (Number of observations: 478) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Smoothing Spline Hyperparameters:
##                                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sds(sageeduc1yearofcollege_1)       0.56      0.55     0.02     2.00 1.00     2712     2098
## sds(sageeduc2yearsofcollege_1)      0.49      0.47     0.02     1.68 1.00     2445     2486
## sds(sageeduc4yearsofcollege_1)      0.61      0.56     0.02     2.12 1.00     2153     1898
## sds(sageeduc5Pyearsofcollege_1)     0.82      0.56     0.05     2.21 1.00     2352     2210
## sds(sageeduchighschoolorless_1)     0.43      0.43     0.01     1.57 1.00     2748     2253
## sds(sigma_sage_1)                   1.01      0.82     0.04     3.12 1.00     1399     1729
## 
## Multilevel Hyperparameters:
## ~degfield_branch (Number of levels: 5) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.20      0.19     0.01     0.71 1.00     3107     2432
## sd(sigma_Intercept)     0.12      0.12     0.00     0.45 1.00     1372     1718
## 
## ~degfield_branch:income_brackets (Number of levels: 52) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.08      0.06     0.00     0.23 1.00     1998     2357
## 
## ~degfield_branch:occ_category (Number of levels: 24) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.21      0.11     0.02     0.45 1.00     1307     1557
## 
## ~degfield_branch:region_birth (Number of levels: 47) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.07      0.05     0.00     0.20 1.00     2248     2307
## 
## ~educ (Number of levels: 5) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.21      0.20     0.01     0.76 1.00     3285     2899
## sd(sigma_Intercept)     0.10      0.11     0.00     0.39 1.00     2030     2268
## 
## ~educ:degfield_branch (Number of levels: 17) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.15      0.12     0.01     0.43 1.00     1656     2491
## 
## ~educ:hispan (Number of levels: 10) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.17      0.14     0.01     0.51 1.00     1893     2332
## 
## ~educ:income_brackets (Number of levels: 53) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.07      0.05     0.00     0.20 1.00     1820     1857
## 
## ~educ:marst (Number of levels: 15) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.12      0.10     0.00     0.36 1.00     1675     2139
## 
## ~educ:occ_category (Number of levels: 28) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.15      0.10     0.01     0.37 1.00     1177     1470
## 
## ~educ:race (Number of levels: 20) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.17      0.11     0.01     0.42 1.00     1576     2584
## 
## ~educ:region_birth (Number of levels: 48) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.06      0.05     0.00     0.18 1.00     2060     2096
## 
## ~educ:region_residence (Number of levels: 43) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.08      0.06     0.00     0.21 1.00     2061     2070
## 
## ~female:degfield_branch (Number of levels: 10) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.13      0.11     0.00     0.40 1.00     2341     2256
## 
## ~female:educ (Number of levels: 10) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.14      0.11     0.00     0.42 1.00     1852     2013
## 
## ~female:hispan (Number of levels: 4) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.28      0.32     0.01     1.19 1.00     2426     2518
## 
## ~female:income_brackets (Number of levels: 22) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.11      0.08     0.00     0.28 1.00     1872     2346
## 
## ~female:marst (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.17      0.17     0.01     0.61 1.00     2141     2588
## 
## ~female:occ_category (Number of levels: 12) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.14      0.13     0.00     0.47 1.00     2129     2384
## 
## ~female:race (Number of levels: 8) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.20      0.16     0.01     0.58 1.00     1645     2169
## 
## ~female:region_birth (Number of levels: 20) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.06      0.05     0.00     0.19 1.00     2873     2305
## 
## ~female:region_residence (Number of levels: 18) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.07      0.06     0.00     0.23 1.00     2465     2220
## 
## ~hispan:degfield_branch (Number of levels: 10) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.12      0.11     0.01     0.41 1.00     3377     2990
## 
## ~hispan:income_brackets (Number of levels: 22) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.08      0.06     0.00     0.23 1.00     2344     2185
## 
## ~hispan:marst (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.21      0.20     0.01     0.73 1.00     2083     2048
## 
## ~hispan:occ_category (Number of levels: 12) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.15      0.13     0.01     0.49 1.00     1862     2084
## 
## ~hispan:region_birth (Number of levels: 19) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.07      0.06     0.00     0.22 1.00     2803     2605
## 
## ~hispan:region_residence (Number of levels: 18) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.13      0.10     0.01     0.36 1.00     1187     2440
## 
## ~income_brackets (Number of levels: 11) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.09      0.07     0.00     0.27 1.00     2727     2064
## sd(sigma_Intercept)     0.07      0.06     0.00     0.21 1.00     1991     2396
## 
## ~marst (Number of levels: 3) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.35      0.37     0.01     1.35 1.00     2811     2137
## sd(sigma_Intercept)     0.53      0.53     0.09     1.97 1.00     1959     2694
## 
## ~marst:degfield_branch (Number of levels: 15) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.09      0.08     0.00     0.29 1.00     2059     1568
## 
## ~marst:income_brackets (Number of levels: 33) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.08      0.06     0.00     0.23 1.00     1622     2175
## 
## ~marst:occ_category (Number of levels: 17) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.09      0.08     0.00     0.32 1.00     2362     1761
## 
## ~marst:region_birth (Number of levels: 30) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.07      0.06     0.00     0.21 1.00     2258     2012
## 
## ~occ_category (Number of levels: 6) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.20      0.19     0.01     0.68 1.00     3303     2851
## sd(sigma_Intercept)     0.19      0.18     0.01     0.66 1.00     1691     1918
## 
## ~occ_category:income_brackets (Number of levels: 48) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.09      0.07     0.00     0.25 1.00     1688     2388
## 
## ~occ_category:region_birth (Number of levels: 46) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.06      0.05     0.00     0.19 1.00     2367     2280
## 
## ~race (Number of levels: 4) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.22      0.24     0.01     0.90 1.00     2824     2027
## sd(sigma_Intercept)     0.17      0.23     0.00     0.76 1.00     2045     2265
## 
## ~race:degfield_branch (Number of levels: 20) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.09      0.07     0.00     0.28 1.00     2580     2263
## 
## ~race:hispan (Number of levels: 8) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.13      0.13     0.00     0.45 1.00     3154     2755
## 
## ~race:income_brackets (Number of levels: 44) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.12      0.08     0.00     0.30 1.00     1551     2275
## 
## ~race:marst (Number of levels: 12) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.15      0.13     0.01     0.47 1.00     1844     2534
## 
## ~race:occ_category (Number of levels: 20) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.16      0.12     0.01     0.46 1.00     1519     1912
## 
## ~race:region_birth (Number of levels: 34) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.08      0.06     0.00     0.23 1.00     2419     2516
## 
## ~race:region_residence (Number of levels: 33) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.08      0.06     0.00     0.23 1.00     2346     2227
## 
## ~region_birth (Number of levels: 10) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.09      0.08     0.00     0.29 1.00     3176     2559
## sd(sigma_Intercept)     0.09      0.08     0.00     0.28 1.00     1528     1832
## 
## ~region_birth:income_brackets (Number of levels: 104) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.17      0.09     0.01     0.35 1.01      760      931
## 
## ~region_residence (Number of levels: 9) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.10      0.09     0.00     0.31 1.00     3208     2612
## sd(sigma_Intercept)     0.12      0.09     0.01     0.35 1.00     1380     1598
## 
## ~region_residence:degfield_branch (Number of levels: 43) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.11      0.07     0.00     0.27 1.00     1551     2232
## 
## ~region_residence:income_brackets (Number of levels: 96) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.14      0.09     0.01     0.31 1.00      837     1567
## 
## ~region_residence:marst (Number of levels: 27) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.09      0.07     0.00     0.25 1.00     1849     2260
## 
## ~region_residence:occ_category (Number of levels: 42) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.08      0.06     0.00     0.24 1.00     1965     2345
## 
## ~region_residence:region_birth (Number of levels: 66) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.12      0.09     0.01     0.32 1.00     1043     2187
## 
## Regression Coefficients:
##                             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept                       0.03      0.61    -1.17     1.29 1.00     2118     1745
## sigma_Intercept                -0.19      0.43    -1.11     0.72 1.00     2183     1690
## femaleTRUE                      0.05      0.44    -0.87     0.93 1.00     2959     2291
## hispanTRUE                     -0.07      0.45    -0.99     0.84 1.00     3028     2507
## sigma_hispanTRUE               -0.07      0.16    -0.40     0.24 1.00     2842     2759
## sigma_femaleTRUE               -0.19      0.10    -0.38     0.01 1.00     2693     3533
## sage:educ1yearofcollege_1       0.41      0.90    -1.43     2.12 1.00     5694     2944
## sage:educ2yearsofcollege_1      0.18      0.75    -1.42     1.58 1.00     4322     2953
## sage:educ4yearsofcollege_1      0.69      0.88    -1.18     2.27 1.00     3874     3004
## sage:educ5Pyearsofcollege_1     0.46      0.90    -1.33     2.15 1.00     5115     3172
## sage:educhighschoolorless_1     0.11      0.74    -1.42     1.54 1.00     4833     3056
## sigma_sage_1                    0.20      2.37    -4.45     5.42 1.00     2515     2049
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>plot(brm_1, widths = c(1, 2))</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-7-1.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-2.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-3.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-4.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-5.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-6.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-7.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-8.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-9.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-10.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-11.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-12.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-13.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-14.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-15.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-7-16.svg" width="768" /></p>
<p>Many large sd estimates for the random intercepts but most CI bounds,
especially for interactions, either include 0 or approach it, indicating
that the data are not large enough to estimate interaction effects.</p>
</div>
<div id="without-interactions" class="section level3" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> Without
interactions</h3>
<pre class="r"><code>library(tidyverse)
library(brms)
options(mc.cores = 20,
        threads = threading(5, static = TRUE),
        brms.backend = &quot;cmdstanr&quot;)
sb_data &lt;- readRDS(&quot;data/preprocessed/wordsum/sb_data.rds&quot;) 
rstan::rstan_options(auto_write = TRUE)




brm_2 &lt;- brm(bf(
  wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets),
  sigma ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets)
                   ),
    family = gaussian(), # default
    prior = prior(normal(0,1), class = &quot;b&quot;) + # coefficients of fixed effects
            prior(normal(0,3), class = &quot;Intercept&quot;) + # overall intercept
            prior(exponential(1), class = &quot;sd&quot;) + # SDs of the random intercepts
            prior(exponential(1), class = &quot;sds&quot;), # wigliness parameters
    iter = 2000, # default
    chains = 4, # default 
    control = list(adapt_delta = 0.8), # default
    seed = 14,
    file = &quot;data/brms/wordsum/sb/brm_2&quot;,
    data = sb_data_scaled) %&gt;%
  add_criterion(&quot;loo&quot;)




brm_2</code></pre>
<pre><code>## Warning: There were 79 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = log 
## Formula: wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets) 
##          sigma ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets)
##    Data: sb_data_scaled (Number of observations: 478) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Smoothing Spline Hyperparameters:
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sds(sage_1)           0.48      0.41     0.02     1.56 1.00     1295     1904
## sds(sigma_sage_1)     0.65      0.60     0.02     2.38 1.00      793      294
## 
## Multilevel Hyperparameters:
## ~degfield_branch (Number of levels: 5) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.29      0.17     0.08     0.74 1.00     1811     2065
## sd(sigma_Intercept)     0.09      0.10     0.00     0.32 1.00     1934     2358
## 
## ~educ (Number of levels: 5) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.29      0.18     0.08     0.78 1.00     1483     1954
## sd(sigma_Intercept)     0.07      0.08     0.00     0.26 1.00     2035     2222
## 
## ~income_brackets (Number of levels: 11) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.10      0.07     0.01     0.26 1.00     1274     2143
## sd(sigma_Intercept)     0.06      0.05     0.00     0.19 1.00     1154     1894
## 
## ~marst (Number of levels: 3) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.38      0.34     0.06     1.40 1.00      830      281
## sd(sigma_Intercept)     0.50      0.47     0.10     1.87 1.00     1405     1768
## 
## ~occ_category (Number of levels: 6) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.21      0.18     0.01     0.66 1.00     1108     1742
## sd(sigma_Intercept)     0.12      0.13     0.00     0.43 1.00     1660     2096
## 
## ~race (Number of levels: 4) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.18      0.17     0.01     0.64 1.00     1081     1640
## sd(sigma_Intercept)     0.12      0.15     0.00     0.50 1.00     1523     1827
## 
## ~region_birth (Number of levels: 10) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.06      0.05     0.00     0.19 1.00     1947     1878
## sd(sigma_Intercept)     0.08      0.06     0.00     0.23 1.00     1422     1839
## 
## ~region_residence (Number of levels: 9) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.07      0.06     0.00     0.22 1.00     1734     2006
## sd(sigma_Intercept)     0.08      0.06     0.00     0.24 1.00     1352     1732
## 
## Regression Coefficients:
##                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept            0.08      0.41    -0.72     0.89 1.00     1736     1700
## sigma_Intercept     -0.08      0.37    -0.92     0.66 1.00     1875     1244
## hispanTRUE          -0.17      0.12    -0.42     0.07 1.00     5184     2823
## femaleTRUE          -0.06      0.09    -0.24     0.12 1.00     5584     3002
## sigma_hispanTRUE     0.03      0.11    -0.18     0.24 1.00     2373     1954
## sigma_femaleTRUE    -0.11      0.08    -0.26     0.05 1.00     5304     3052
## sage_1               0.43      0.82    -1.35     1.75 1.00     2094     3263
## sigma_sage_1         0.06      1.76    -3.03     4.53 1.01      584      191
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>plot(brm_2, widths = c(1, 2))</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-8-1.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-8-2.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-8-3.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-8-4.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-8-5.svg" width="768" /><img src="tutorial_files/figure-html/unnamed-chunk-8-6.svg" width="768" /></p>
<pre class="r"><code>loo_compare(brm_1, brm_2)</code></pre>
<pre><code>##       elpd_diff se_diff
## brm_2   0.0       0.0  
## brm_1 -10.2       7.0</code></pre>
<p>The model without interactions fits slightly better, probably because
any predictions based on the interactions are way too uncertain to make
a difference in average prediction accuracy. The divergent transitions
are concerning, but most of them are gone when modelling the outcome as
ordinal or when boosting the adapt_delta parameter.</p>
<div id="boosted-n-of-iterations-and-adapt_delta" class="section level4"
number="3.1.2.1">
<h4><span class="header-section-number">3.1.2.1</span> Boosted n of
iterations and adapt_delta</h4>
<pre class="r"><code>library(tidyverse)
library(brms)
options(mc.cores = 20,
        threads = threading(5, static = TRUE),
        brms.backend = &quot;cmdstanr&quot;)
sb_data &lt;- readRDS(&quot;data/preprocessed/wordsum/sb_data.rds&quot;) 
rstan::rstan_options(auto_write = TRUE)



sb_data_scaled &lt;- sb_data %&gt;% 
  mutate(age = scale(age),
         wordsum = scale(wordsum))



brm_2_boosted &lt;- brm(bf(wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets),
                   sigma ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets)
                   ),
    seed = 14,
    chains = 4,
    iter = 5000,
    control = list(adapt_delta = 0.999),
    prior = prior(normal(0,1), class = &quot;b&quot;) +
            prior(normal(0,3), class = &quot;Intercept&quot;) +
            prior(exponential(1), class = &quot;sd&quot;) + 
            prior(exponential(1), class = &quot;sds&quot;),
    file = &quot;data/brms/wordsum/sb/brm_2_boosted&quot;,
    data = sb_data_scaled) %&gt;%
  add_criterion(&quot;loo&quot;)


brm_2_boosted</code></pre>
<pre><code>## Warning: There were 1 divergent transitions after warmup. Increasing adapt_delta above 0.999 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = log 
## Formula: wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets) 
##          sigma ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets)
##    Data: sb_data_scaled (Number of observations: 478) 
##   Draws: 4 chains, each with iter = 5000; warmup = 2500; thin = 1;
##          total post-warmup draws = 10000
## 
## Smoothing Spline Hyperparameters:
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sds(sage_1)           0.47      0.40     0.02     1.52 1.00     4652     6057
## sds(sigma_sage_1)     0.62      0.58     0.03     2.13 1.00     4005     5069
## 
## Multilevel Hyperparameters:
## ~degfield_branch (Number of levels: 5) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.29      0.18     0.08     0.74 1.00     4473     5200
## sd(sigma_Intercept)     0.09      0.09     0.00     0.32 1.00     5072     6195
## 
## ~educ (Number of levels: 5) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.30      0.20     0.08     0.78 1.00     3407     4354
## sd(sigma_Intercept)     0.06      0.08     0.00     0.25 1.00     5696     6104
## 
## ~income_brackets (Number of levels: 11) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.10      0.07     0.00     0.27 1.00     3048     4430
## sd(sigma_Intercept)     0.06      0.05     0.00     0.18 1.00     4614     5301
## 
## ~marst (Number of levels: 3) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.36      0.33     0.06     1.20 1.00     4346     4519
## sd(sigma_Intercept)     0.54      0.60     0.10     2.18 1.00     4013     4481
## 
## ~occ_category (Number of levels: 6) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.21      0.17     0.01     0.66 1.00     2941     4269
## sd(sigma_Intercept)     0.12      0.11     0.00     0.40 1.00     3933     5111
## 
## ~race (Number of levels: 4) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.18      0.17     0.01     0.61 1.00     4049     4133
## sd(sigma_Intercept)     0.13      0.17     0.00     0.57 1.00     4299     5668
## 
## ~region_birth (Number of levels: 10) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.06      0.05     0.00     0.20 1.00     5100     4955
## sd(sigma_Intercept)     0.08      0.06     0.00     0.23 1.00     3935     4310
## 
## ~region_residence (Number of levels: 9) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.07      0.06     0.00     0.22 1.00     4859     4764
## sd(sigma_Intercept)     0.08      0.06     0.00     0.24 1.00     4108     5590
## 
## Regression Coefficients:
##                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept            0.10      0.40    -0.71     0.88 1.00     4897     5027
## sigma_Intercept     -0.04      0.44    -0.93     0.88 1.00     4143     3874
## hispanTRUE          -0.17      0.13    -0.43     0.08 1.00    15911     7836
## femaleTRUE          -0.07      0.09    -0.25     0.11 1.00    15532     8037
## sigma_hispanTRUE     0.02      0.11    -0.18     0.24 1.00    16438     7775
## sigma_femaleTRUE    -0.11      0.08    -0.26     0.04 1.00    15506     7147
## sage_1               0.45      0.83    -1.40     1.79 1.00     6495     7277
## sigma_sage_1        -0.08      1.53    -2.89     3.50 1.00     5829     5260
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>loo_compare(brm_2, brm_2_boosted)</code></pre>
<pre><code>##               elpd_diff se_diff
## brm_2          0.0       0.0   
## brm_2_boosted -0.2       0.3</code></pre>
<p>No difference between the model with 10/4000 divergent transitions
and the same model with 1/10000 divergent transition.</p>
<p>Divergent transitions reduced and some effect estimates changed, but
no change in prediction accuracy.</p>
</div>
</div>
<div id="ordinal-model" class="section level3" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Ordinal model</h3>
<pre class="r"><code>library(tidyverse)
library(brms)
options(mc.cores = 20,
        threads = threading(5, static = TRUE),
        brms.backend = &quot;cmdstanr&quot;)
sb_data &lt;- readRDS(&quot;data/preprocessed/wordsum/sb_data.rds&quot;) 
rstan::rstan_options(auto_write = TRUE)


brm_4 &lt;- brm(bf(wordsum_ordinal ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets),
                disc ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets)
                   ),
    seed = 14,
    chains = 4,
    family = cumulative(),
    prior = prior(normal(0,1), class = &quot;b&quot;) +
            # prior(normal(0,3), class = &quot;Intercept&quot;) +
            prior(exponential(1), class = &quot;sd&quot;) + 
            prior(exponential(1), class = &quot;sds&quot;),
    file = &quot;data/brms/wordsum/sb/brm_4&quot;,
    data = sb_data) %&gt;%
  add_criterion(&quot;loo&quot;)

brm_4</code></pre>
<pre><code>## Warning: There were 5 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = logit; disc = log 
## Formula: wordsum_ordinal ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets) 
##          disc ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets)
##    Data: sb_data (Number of observations: 478) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Smoothing Spline Hyperparameters:
##                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sds(sage_1)          0.93      0.64     0.09     2.54 1.00     1687     1516
## sds(disc_sage_1)     0.77      0.69     0.03     2.62 1.00     1748     2459
## 
## Multilevel Hyperparameters:
## ~degfield_branch (Number of levels: 5) 
##                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)          0.70      0.42     0.18     1.81 1.00     1981     2007
## sd(disc_Intercept)     0.10      0.11     0.00     0.38 1.00     1872     2711
## 
## ~educ (Number of levels: 5) 
##                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)          0.73      0.43     0.21     1.83 1.00     1768     1955
## sd(disc_Intercept)     0.12      0.13     0.00     0.43 1.00     1814     2577
## 
## ~income_brackets (Number of levels: 11) 
##                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)          0.28      0.20     0.01     0.76 1.01     1148     1722
## sd(disc_Intercept)     0.09      0.07     0.00     0.25 1.00     1744     1884
## 
## ~marst (Number of levels: 3) 
##                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)          0.64      0.58     0.07     2.28 1.00     1901     1671
## sd(disc_Intercept)     0.60      0.56     0.12     2.14 1.00     1956     2602
## 
## ~occ_category (Number of levels: 6) 
##                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)          0.48      0.41     0.02     1.53 1.00     1225     1607
## sd(disc_Intercept)     0.18      0.18     0.01     0.63 1.00     1625     2050
## 
## ~race (Number of levels: 4) 
##                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)          0.30      0.32     0.01     1.18 1.00     1576     2423
## sd(disc_Intercept)     0.15      0.21     0.00     0.64 1.00     2020     2296
## 
## ~region_birth (Number of levels: 10) 
##                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)          0.15      0.13     0.01     0.48 1.00     2181     2314
## sd(disc_Intercept)     0.16      0.09     0.01     0.38 1.00     1647     1923
## 
## ~region_residence (Number of levels: 9) 
##                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)          0.17      0.15     0.01     0.55 1.00     1911     2214
## sd(disc_Intercept)     0.22      0.12     0.04     0.52 1.00     1342     1199
## 
## Regression Coefficients:
##                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept[1]       -9.59      3.04   -16.77    -5.00 1.00     1478     2229
## Intercept[2]       -7.66      2.26   -12.91    -4.14 1.00     1306     1910
## Intercept[3]       -6.05      1.77   -10.09    -3.16 1.00     1270     1654
## Intercept[4]       -5.18      1.54    -8.71    -2.59 1.00     1278     2027
## Intercept[5]       -3.55      1.20    -6.15    -1.41 1.00     1484     2157
## Intercept[6]       -1.74      0.92    -3.58     0.05 1.00     2230     2228
## Intercept[7]       -0.36      0.82    -1.80     1.46 1.00     3729     2999
## Intercept[8]        0.68      0.84    -0.69     2.59 1.00     4060     3352
## Intercept[9]        2.00      0.97     0.54     4.23 1.00     2789     3081
## Intercept[10]       3.93      1.30     1.93     6.95 1.00     1892     2294
## disc_Intercept     -0.26      0.46    -1.11     0.72 1.00     2131     2585
## hispanTRUE         -0.31      0.29    -0.94     0.22 1.00     4207     2046
## femaleTRUE         -0.20      0.22    -0.67     0.23 1.00     4359     2941
## disc_hispanTRUE    -0.00      0.13    -0.26     0.26 1.00     7357     3207
## disc_femaleTRUE     0.19      0.10    -0.00     0.38 1.00     6794     3272
## sage_1              0.53      1.01    -1.51     2.41 1.00     4255     2758
## disc_sage_1         0.11      1.81    -4.16     3.65 1.00     3345     2793
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>pp_check(brm_4)</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-10-1.svg" width="768" /></p>
<p>The ordinal model fits the data better and has only 3 divergent
transitions, probably because it accounts for the discrete and bounded
nature of the outcome, but we stick with normal because it does not
matter for the final RPP results (see below).</p>
</div>
<div id="negative-binomial-model" class="section level3" number="3.1.4">
<h3><span class="header-section-number">3.1.4</span> Negative binomial
model</h3>
<pre class="r"><code>brm_5 &lt;- brm(bf(wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets),
                   shape ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets)
                   ),
    seed = 14,
    chains = 4,
    family = negbinomial(),
    prior = prior(normal(0,1), class = &quot;b&quot;) +
            # prior(normal(0,3), class = &quot;Intercept&quot;) +
            prior(exponential(1), class = &quot;sd&quot;) + 
            prior(exponential(1), class = &quot;sds&quot;),
    file = &quot;data/brms/wordsum/sb/brm_5&quot;,
    data = sb_data) %&gt;%
  add_criterion(&quot;loo&quot;)

brm_5</code></pre>
<pre><code>## Warning: Parts of the model have not converged (some Rhats are &gt; 1.05). Be careful when analysing the results! We
## recommend running more iterations and/or setting stronger priors.</code></pre>
<pre><code>##  Family: negbinomial 
##   Links: mu = log; shape = log 
## Formula: wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets) 
##          shape ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets)
##    Data: sb_data (Number of observations: 478) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Smoothing Spline Hyperparameters:
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sds(sage_1)           0.11      0.10     0.02     0.28 3.67        4       11
## sds(shape_sage_1)     1.83      1.92     0.26     5.18 3.03        5       24
## 
## Multilevel Hyperparameters:
## ~degfield_branch (Number of levels: 5) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.04      0.02     0.00     0.06 3.19        4       11
## sd(shape_Intercept)     1.26      1.05     0.13     2.96 3.49        4       12
## 
## ~educ (Number of levels: 5) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.02      0.02     0.00     0.05 3.62        4       15
## sd(shape_Intercept)     0.61      0.58     0.13     1.61 3.44        4       11
## 
## ~income_brackets (Number of levels: 11) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.02      0.01     0.00     0.04 3.29        4       11
## sd(shape_Intercept)     1.74      0.84     1.05     3.37 2.68        5       16
## 
## ~marst (Number of levels: 3) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.14      0.09     0.04     0.27 3.28        5       12
## sd(shape_Intercept)     4.74      7.55     0.06    17.87 2.98        5       15
## 
## ~occ_category (Number of levels: 6) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.06      0.03     0.02     0.10 3.73        4       13
## sd(shape_Intercept)     2.12      1.12     0.55     3.46 3.59        5       18
## 
## ~race (Number of levels: 4) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.04      0.05     0.00     0.13 3.14        5       15
## sd(shape_Intercept)     1.54      0.68     0.75     2.71 3.69        4       12
## 
## ~region_birth (Number of levels: 10) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.01      0.01     0.00     0.02 3.25        4       18
## sd(shape_Intercept)     2.36      1.97     0.31     5.83 3.09        5       22
## 
## ~region_residence (Number of levels: 9) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.02      0.02     0.00     0.06 3.33        4       12
## sd(shape_Intercept)     0.18      0.11     0.02     0.31 2.57        5       26
## 
## Regression Coefficients:
##                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept            1.99      0.03     1.95     2.04 2.94        5       18
## shape_Intercept     10.17      5.96     0.94    16.51 3.03        5       23
## hispanTRUE          -0.07      0.06    -0.21     0.00 3.94        4       11
## femaleTRUE          -0.03      0.05    -0.13     0.03 2.40        5       13
## shape_hispanTRUE     1.71      2.53    -1.27     4.48 3.10        5       16
## shape_femaleTRUE     0.13      1.32    -1.71     2.02 4.21        4       11
## sage_1               0.26      0.23    -0.04     0.64 2.99        5       13
## shape_sage_1         7.62     11.90    -0.80    28.54 3.54        4       15
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Does not converge.</p>
<pre class="r"><code>brm_5_v2 &lt;- brm(bf(wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets)),
    seed = 14,
    chains = 4,
    family = negbinomial(),
    prior = prior(normal(0,1), class = &quot;b&quot;) +
            # prior(normal(0,3), class = &quot;Intercept&quot;) +
            prior(exponential(1), class = &quot;sd&quot;) + 
            prior(exponential(1), class = &quot;sds&quot;),
    file = &quot;data/brms/wordsum/sb/brm_5_v2&quot;,
    data = sb_data) %&gt;%
  add_criterion(&quot;loo&quot;)

brm_5_v2</code></pre>
<pre><code>## Warning: Parts of the model have not converged (some Rhats are &gt; 1.05). Be careful when analysing the results! We
## recommend running more iterations and/or setting stronger priors.</code></pre>
<pre><code>## Warning: There were 776 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>##  Family: negbinomial 
##   Links: mu = log; shape = identity 
## Formula: wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets) 
##    Data: sb_data (Number of observations: 478) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Smoothing Spline Hyperparameters:
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sds(sage_1)     0.15      0.15     0.01     0.56 1.04       69     1814
## 
## Multilevel Hyperparameters:
## ~degfield_branch (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.05      0.05     0.00     0.20 1.05       62     1119
## 
## ~educ (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.05      0.04     0.00     0.16 1.15      777     1614
## 
## ~income_brackets (Number of levels: 11) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.02      0.02     0.00     0.07 1.06      238     1631
## 
## ~marst (Number of levels: 3) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.09      0.11     0.00     0.38 1.20       14      121
## 
## ~occ_category (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.03      0.04     0.00     0.13 1.22       13        9
## 
## ~race (Number of levels: 4) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.04      0.05     0.00     0.18 1.12     1024     1694
## 
## ~region_birth (Number of levels: 10) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.02      0.02     0.00     0.07 1.04      172     1286
## 
## ~region_residence (Number of levels: 9) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.02      0.02     0.00     0.07 1.10      634     1403
## 
## Regression Coefficients:
##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept      2.01      0.09     1.81     2.19 1.05      242     1332
## hispanTRUE    -0.04      0.05    -0.14     0.05 1.15     3078     2722
## femaleTRUE    -0.01      0.03    -0.08     0.06 1.14     3558     2462
## sage_1         0.16      0.37    -0.74     0.87 1.10     1824     1232
## 
## Further Distributional Parameters:
##                Estimate          Est.Error l-95% CI          u-95% CI Rhat Bulk_ESS Tail_ESS
## shape 81200605902640.36 725962434370902.25   543.76 74239200000000.00 1.36        9       15
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>brm_5_more_iters &lt;- brm(bf(wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets),
                   shape ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets)
                   ),
    seed = 14,
    chains = 4,
    iter = 5000,
    family = negbinomial(),
    prior = prior(normal(0,1), class = &quot;b&quot;) +
            # prior(normal(0,3), class = &quot;Intercept&quot;) +
            prior(exponential(1), class = &quot;sd&quot;) + 
            prior(exponential(1), class = &quot;sds&quot;),
    file = &quot;data/brms/wordsum/sb/brm_5_more_iters&quot;,
    data = sb_data) %&gt;%
  add_criterion(&quot;loo&quot;)


brm_5_more_iters</code></pre>
<pre><code>## Warning: Parts of the model have not converged (some Rhats are &gt; 1.05). Be careful when analysing the results! We
## recommend running more iterations and/or setting stronger priors.</code></pre>
<pre><code>##  Family: negbinomial 
##   Links: mu = log; shape = log 
## Formula: wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets) 
##          shape ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets)
##    Data: sb_data (Number of observations: 478) 
##   Draws: 4 chains, each with iter = 5000; warmup = 2500; thin = 1;
##          total post-warmup draws = 10000
## 
## Smoothing Spline Hyperparameters:
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sds(sage_1)           0.25      0.12     0.07     0.51 2.42        5       20
## sds(shape_sage_1)     5.11      1.27     2.76     7.03 2.56        5       11
## 
## Multilevel Hyperparameters:
## ~degfield_branch (Number of levels: 5) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.05      0.03     0.01     0.09 3.16        4       11
## sd(shape_Intercept)     2.35      1.76     0.48     4.74 3.13        4       12
## 
## ~educ (Number of levels: 5) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.03      0.02     0.02     0.06 2.90        5       30
## sd(shape_Intercept)     1.66      1.02     0.13     3.27 2.87        5       16
## 
## ~income_brackets (Number of levels: 11) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.03      0.01     0.01     0.04 4.19        4       11
## sd(shape_Intercept)     1.62      1.15     0.21     3.39 2.70        5       21
## 
## ~marst (Number of levels: 3) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.16      0.10     0.05     0.29 2.61        5       21
## sd(shape_Intercept)     2.23      2.82     0.16     7.67 3.81        4       12
## 
## ~occ_category (Number of levels: 6) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.05      0.01     0.03     0.07 3.45        4       11
## sd(shape_Intercept)     2.99      0.50     2.35     4.12 2.27        5       17
## 
## ~race (Number of levels: 4) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.05      0.04     0.02     0.12 3.49        4       18
## sd(shape_Intercept)     1.96      1.05     0.20     3.27 2.59        5       14
## 
## ~region_birth (Number of levels: 10) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.01      0.01     0.00     0.02 2.97        5       21
## sd(shape_Intercept)     0.99      0.44     0.41     1.87 3.38        4       11
## 
## ~region_residence (Number of levels: 9) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.03      0.02     0.01     0.06 2.63        5       12
## sd(shape_Intercept)     1.51      1.13     0.02     3.09 3.15        5       24
## 
## Regression Coefficients:
##                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept            2.07      0.12     1.95     2.27 3.84        4       12
## shape_Intercept     13.35      3.77     6.75    16.77 3.49        4       11
## hispanTRUE          -0.08      0.05    -0.20    -0.03 2.02        6       23
## femaleTRUE           0.01      0.02    -0.02     0.06 2.37        6       29
## shape_hispanTRUE     1.70      2.19    -1.82     4.24 2.96        5       14
## shape_femaleTRUE     0.31      1.40    -1.27     1.97 3.07        5       17
## sage_1               0.41      0.28    -0.03     0.81 2.49        5       12
## shape_sage_1        22.30     11.34     8.07    39.50 2.95        5       18
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Failed to converge even with more iterations.</p>
</div>
<div id="poisson-model" class="section level3" number="3.1.5">
<h3><span class="header-section-number">3.1.5</span> Poisson model</h3>
<pre class="r"><code>brm_6 &lt;- brm(bf(wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets)),
    seed = 14,
    chains = 4,
    iter = 2000,
    family = poisson(),
    prior = prior(normal(0,1), class = &quot;b&quot;) +
            # prior(normal(0,3), class = &quot;Intercept&quot;) +
            prior(exponential(1), class = &quot;sd&quot;) + 
            prior(exponential(1), class = &quot;sds&quot;),
    file = &quot;data/brms/wordsum/sb/brm_6&quot;,
    data = sb_data) %&gt;%
  add_criterion(&quot;loo&quot;)

brm_6</code></pre>
<pre><code>## Warning: There were 85 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>##  Family: poisson 
##   Links: mu = log 
## Formula: wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets) 
##    Data: sb_data (Number of observations: 478) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Smoothing Spline Hyperparameters:
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sds(sage_1)     0.18      0.18     0.01     0.67 1.01      938      329
## 
## Multilevel Hyperparameters:
## ~degfield_branch (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.06      0.05     0.00     0.19 1.00     1417     1760
## 
## ~educ (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.05      0.05     0.00     0.19 1.01     1193     2330
## 
## ~income_brackets (Number of levels: 11) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.02      0.02     0.00     0.07 1.00     2019     1693
## 
## ~marst (Number of levels: 3) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.11      0.12     0.01     0.46 1.00     1112     1317
## 
## ~occ_category (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.04      0.04     0.00     0.15 1.00     1625     1332
## 
## ~race (Number of levels: 4) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.05      0.06     0.00     0.23 1.01     1115     1532
## 
## ~region_birth (Number of levels: 10) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.02      0.02     0.00     0.07 1.00     2228     1925
## 
## ~region_residence (Number of levels: 9) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.02      0.02     0.00     0.08 1.00     2297     1874
## 
## Regression Coefficients:
##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept      2.00      0.11     1.76     2.23 1.00     1072      911
## hispanTRUE    -0.04      0.05    -0.14     0.05 1.00     3781     2778
## femaleTRUE    -0.01      0.04    -0.08     0.06 1.00     3482     2705
## sage_1         0.15      0.46    -1.09     0.92 1.01      848      294
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>pp_check(brm_6)</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-14-1.svg" width="768" /></p>
<pre class="r"><code>loo_compare(brm_4, brm_6)</code></pre>
<pre><code>## Warning: Not all models have the same y variable. (&#39;yhash&#39; attributes do not match)</code></pre>
<pre><code>##       elpd_diff se_diff
## brm_4    0.0       0.0 
## brm_6 -125.7      10.8</code></pre>
<p>Bad fit compared to normal and ordinal models.</p>
</div>
<div id="binomial-model" class="section level3" number="3.1.6">
<h3><span class="header-section-number">3.1.6</span> Binomial model</h3>
<pre class="r"><code>brm_7 &lt;- brm(bf(wordsum | trials(10) ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets)),
    family = binomial(),  
    seed = 14,
    chains = 4,
    iter = 2000,
    prior = prior(normal(0,1), class = &quot;b&quot;) +
            # prior(normal(0,3), class = &quot;Intercept&quot;) +
            prior(exponential(1), class = &quot;sd&quot;) + 
            prior(exponential(1), class = &quot;sds&quot;),
    file = &quot;data/brms/wordsum/sb/brm_7&quot;,
    data = sb_data) %&gt;%
  add_criterion(&quot;loo&quot;)

pp_check(brm_7)</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-15-1.svg" width="768" /></p>
<pre class="r"><code>brm_7</code></pre>
<pre><code>## Warning: There were 30 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>##  Family: binomial 
##   Links: mu = logit 
## Formula: wordsum | trials(10) ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets) 
##    Data: sb_data (Number of observations: 478) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Smoothing Spline Hyperparameters:
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sds(sage_1)     0.51      0.56     0.02     1.72 1.00      866      534
## 
## Multilevel Hyperparameters:
## ~degfield_branch (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.27      0.16     0.08     0.70 1.00     1513     2343
## 
## ~educ (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.26      0.17     0.06     0.70 1.00     1114     1587
## 
## ~income_brackets (Number of levels: 11) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.13      0.07     0.01     0.28 1.01      790      684
## 
## ~marst (Number of levels: 3) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.36      0.29     0.08     1.22 1.00     1066      716
## 
## ~occ_category (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.14      0.12     0.01     0.46 1.00     1372     1703
## 
## ~race (Number of levels: 4) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.17      0.14     0.01     0.54 1.00     1303     1187
## 
## ~region_birth (Number of levels: 10) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.07      0.06     0.00     0.20 1.00     1425     1603
## 
## ~region_residence (Number of levels: 9) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.11      0.08     0.01     0.29 1.00     1106     1769
## 
## Regression Coefficients:
##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept      1.08      0.35     0.36     1.78 1.00     1400     1675
## hispanTRUE    -0.12      0.10    -0.31     0.07 1.00     3713     2937
## femaleTRUE    -0.04      0.07    -0.18     0.10 1.00     3868     3046
## sage_1         0.31      0.81    -1.54     1.56 1.01     1186      598
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>loo_compare(brm_4, brm_7)</code></pre>
<pre><code>## Warning: Not all models have the same y variable. (&#39;yhash&#39; attributes do not match)</code></pre>
<pre><code>##       elpd_diff se_diff
## brm_4   0.0       0.0  
## brm_7 -20.8      10.2</code></pre>
<p>Binomial doesn’t seem to be too bad a fit.</p>
<div id="binomial-with-random-person-intercept" class="section level4"
number="3.1.6.1">
<h4><span class="header-section-number">3.1.6.1</span> Binomial with
random person intercept</h4>
<pre class="r"><code>brm_7_ab &lt;- brm(bf(wordsum | trials(10) ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets) + (1 | pid)),
    family = binomial(),  
    seed = 14,
    chains = 4,
    iter = 2000,
    prior = prior(normal(0,1), class = &quot;b&quot;) +
            # prior(normal(0,3), class = &quot;Intercept&quot;) +
            prior(exponential(1), class = &quot;sd&quot;) + 
            prior(exponential(1), class = &quot;sds&quot;),
    file = &quot;data/brms/wordsum/sb/brm_7_ab&quot;,
    data = sb_data) %&gt;%
  add_criterion(&quot;loo&quot;)


pp_check(brm_7_ab)</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-16-1.svg" width="768" /></p>
<pre class="r"><code>brm_7_ab</code></pre>
<pre><code>## Warning: There were 21 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>##  Family: binomial 
##   Links: mu = logit 
## Formula: wordsum | trials(10) ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets) + (1 | pid) 
##    Data: sb_data (Number of observations: 478) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Smoothing Spline Hyperparameters:
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sds(sage_1)     0.42      0.38     0.02     1.39 1.00     1706     1995
## 
## Multilevel Hyperparameters:
## ~degfield_branch (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.28      0.18     0.06     0.78 1.00     1276     1288
## 
## ~educ (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.25      0.17     0.05     0.67 1.00     1568     1959
## 
## ~income_brackets (Number of levels: 11) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.11      0.07     0.01     0.27 1.00     1138     1726
## 
## ~marst (Number of levels: 3) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.35      0.28     0.08     1.16 1.00     1822     2028
## 
## ~occ_category (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.12      0.12     0.00     0.42 1.00     1398     2013
## 
## ~pid (Number of levels: 478) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.44      0.06     0.32     0.56 1.00     1290     1990
## 
## ~race (Number of levels: 4) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.16      0.15     0.01     0.54 1.00     1223     1839
## 
## ~region_birth (Number of levels: 10) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.07      0.06     0.00     0.21 1.00     1271     1465
## 
## ~region_residence (Number of levels: 9) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.10      0.07     0.00     0.28 1.01      932     1641
## 
## Regression Coefficients:
##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept      1.12      0.38     0.33     1.83 1.00     1458     1429
## hispanTRUE    -0.14      0.12    -0.38     0.08 1.00     4341     3294
## femaleTRUE    -0.04      0.09    -0.21     0.12 1.00     3846     3296
## sage_1         0.46      0.74    -1.19     1.68 1.00     3026     3137
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>loo_compare(brm_2, brm_4, brm_7, brm_7_ab)</code></pre>
<pre><code>## Warning: Not all models have the same y variable. (&#39;yhash&#39; attributes do not match)</code></pre>
<pre><code>##          elpd_diff se_diff
## brm_2       0.0       0.0 
## brm_4    -235.3       5.8 
## brm_7_ab -242.9       6.1 
## brm_7    -256.1       7.2</code></pre>
</div>
</div>
<div id="beta-model" class="section level3" number="3.1.7">
<h3><span class="header-section-number">3.1.7</span> Beta model</h3>
<pre class="r"><code>sb_data &lt;- sb_data %&gt;% mutate(wordsum_prop = wordsum / 11) %&gt;% filter(wordsum_prop != 0) # exclude one person with a score of 0

brm_8 &lt;- brm(bf(wordsum_prop ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets),
                phi ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets)),
    family = Beta(),  
    seed = 14,
    chains = 4,
    iter = 2000,
    prior = prior(normal(0,1), class = &quot;b&quot;) +
            # prior(normal(0,3), class = &quot;Intercept&quot;) +
            prior(exponential(1), class = &quot;sd&quot;) + 
            prior(exponential(1), class = &quot;sds&quot;),
    file = &quot;data/brms/wordsum/sb/brm_8&quot;,
    data = sb_data) %&gt;%
  add_criterion(&quot;loo&quot;)

brm_8</code></pre>
<pre><code>## Warning: There were 42 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>##  Family: beta 
##   Links: mu = logit; phi = log 
## Formula: wordsum_prop ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets) 
##          phi ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets)
##    Data: sb_data (Number of observations: 477) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Smoothing Spline Hyperparameters:
##                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sds(sage_1)         0.34      0.32     0.01     1.17 1.00     1690     1755
## sds(phi_sage_1)     0.85      0.77     0.02     2.90 1.00     1333     1759
## 
## Multilevel Hyperparameters:
## ~degfield_branch (Number of levels: 5) 
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)         0.23      0.15     0.05     0.61 1.00     1333     1229
## sd(phi_Intercept)     0.17      0.17     0.01     0.61 1.00     1992     2521
## 
## ~educ (Number of levels: 5) 
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)         0.21      0.14     0.05     0.57 1.00     1272     1498
## sd(phi_Intercept)     0.21      0.20     0.01     0.74 1.00     1565     2316
## 
## ~income_brackets (Number of levels: 11) 
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)         0.08      0.05     0.01     0.21 1.01     1030     1928
## sd(phi_Intercept)     0.12      0.10     0.01     0.36 1.00     1839     1856
## 
## ~marst (Number of levels: 3) 
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)         0.28      0.26     0.05     1.05 1.00     1636     1908
## sd(phi_Intercept)     0.77      0.65     0.16     2.53 1.00     1641     1640
## 
## ~occ_category (Number of levels: 6) 
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)         0.16      0.14     0.01     0.50 1.00     1126     1424
## sd(phi_Intercept)     0.23      0.22     0.01     0.85 1.00     1692     2097
## 
## ~race (Number of levels: 4) 
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)         0.11      0.12     0.00     0.43 1.00     1535     1754
## sd(phi_Intercept)     0.24      0.29     0.01     1.06 1.00     1577     2283
## 
## ~region_birth (Number of levels: 10) 
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)         0.05      0.04     0.00     0.14 1.00     1541     1527
## sd(phi_Intercept)     0.17      0.12     0.01     0.45 1.00     1507     1850
## 
## ~region_residence (Number of levels: 9) 
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)         0.05      0.05     0.00     0.17 1.00     1444     1947
## sd(phi_Intercept)     0.27      0.16     0.02     0.64 1.00     1002      753
## 
## Regression Coefficients:
##                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept          0.75      0.30     0.15     1.34 1.00     1631     1985
## phi_Intercept      2.12      0.63     0.60     3.27 1.00     1443      963
## hispanTRUE        -0.08      0.08    -0.24     0.09 1.00     5113     3063
## femaleTRUE        -0.06      0.06    -0.19     0.07 1.00     4287     2609
## phi_hispanTRUE     0.13      0.21    -0.28     0.52 1.00     5043     2560
## phi_femaleTRUE     0.20      0.15    -0.10     0.47 1.00     4440     2775
## sage_1             0.37      0.66    -1.20     1.41 1.00     2287     2318
## phi_sage_1         0.56      2.34    -5.06     5.37 1.00     1830     1463
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>pp_check(brm_8)</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-17-1.svg" width="768" /></p>
<p>Can’t loo_compare because we’re missing one data point, but pp_check
doesn’t look too bad.</p>
</div>
<div id="beta-binomial-model" class="section level3" number="3.1.8">
<h3><span class="header-section-number">3.1.8</span> Beta-binomial
model</h3>
<pre class="r"><code>library(tidyverse)
library(brms)
options(mc.cores = 20,
        threads = threading(5, static = TRUE),
        brms.backend = &quot;cmdstanr&quot;)
sb_data &lt;- readRDS(&quot;data/preprocessed/wordsum/sb_data.rds&quot;) 
rstan::rstan_options(auto_write = TRUE)


brm_9 &lt;- brm(bf(wordsum | trials(10) ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets)),
                # phi ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets))
    family = beta_binomial(),
    seed = 14,
    chains = 4,
    iter = 2000,
    prior = prior(normal(0,1), class = &quot;b&quot;) +
            # prior(normal(0,3), class = &quot;Intercept&quot;) +
            prior(exponential(1), class = &quot;sd&quot;) + 
            prior(exponential(1), class = &quot;sds&quot;),
    file = &quot;data/brms/wordsum/sb/brm_9&quot;,
    data = sb_data) %&gt;%
  add_criterion(&quot;loo&quot;)</code></pre>
<pre><code>## Warning in parallel::mclapply(X = X, FUN = FUN, mc.cores = cores, ...): all scheduled cores encountered errors in user
## code</code></pre>
<pre><code>## Error in exp(x): non-numeric argument to mathematical function</code></pre>
<pre class="r"><code># 
# pp_check(brm_9)
# brm_9
# loo_compare(brm_2, brm_4, brm_9)</code></pre>
<p>Took too long and kept crashing.</p>
</div>
</div>
<div id="some-model-exploration-of-the-selected-model"
class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Some model
exploration of the selected model</h2>
<div id="summary" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Summary</h3>
<pre class="r"><code>brm_2</code></pre>
<pre><code>## Warning: There were 79 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = log 
## Formula: wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets) 
##          sigma ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth) + female + (1 | income_brackets)
##    Data: sb_data_scaled (Number of observations: 478) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Smoothing Spline Hyperparameters:
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sds(sage_1)           0.48      0.41     0.02     1.56 1.00     1295     1904
## sds(sigma_sage_1)     0.65      0.60     0.02     2.38 1.00      793      294
## 
## Multilevel Hyperparameters:
## ~degfield_branch (Number of levels: 5) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.29      0.17     0.08     0.74 1.00     1811     2065
## sd(sigma_Intercept)     0.09      0.10     0.00     0.32 1.00     1934     2358
## 
## ~educ (Number of levels: 5) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.29      0.18     0.08     0.78 1.00     1483     1954
## sd(sigma_Intercept)     0.07      0.08     0.00     0.26 1.00     2035     2222
## 
## ~income_brackets (Number of levels: 11) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.10      0.07     0.01     0.26 1.00     1274     2143
## sd(sigma_Intercept)     0.06      0.05     0.00     0.19 1.00     1154     1894
## 
## ~marst (Number of levels: 3) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.38      0.34     0.06     1.40 1.00      830      281
## sd(sigma_Intercept)     0.50      0.47     0.10     1.87 1.00     1405     1768
## 
## ~occ_category (Number of levels: 6) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.21      0.18     0.01     0.66 1.00     1108     1742
## sd(sigma_Intercept)     0.12      0.13     0.00     0.43 1.00     1660     2096
## 
## ~race (Number of levels: 4) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.18      0.17     0.01     0.64 1.00     1081     1640
## sd(sigma_Intercept)     0.12      0.15     0.00     0.50 1.00     1523     1827
## 
## ~region_birth (Number of levels: 10) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.06      0.05     0.00     0.19 1.00     1947     1878
## sd(sigma_Intercept)     0.08      0.06     0.00     0.23 1.00     1422     1839
## 
## ~region_residence (Number of levels: 9) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.07      0.06     0.00     0.22 1.00     1734     2006
## sd(sigma_Intercept)     0.08      0.06     0.00     0.24 1.00     1352     1732
## 
## Regression Coefficients:
##                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept            0.08      0.41    -0.72     0.89 1.00     1736     1700
## sigma_Intercept     -0.08      0.37    -0.92     0.66 1.00     1875     1244
## hispanTRUE          -0.17      0.12    -0.42     0.07 1.00     5184     2823
## femaleTRUE          -0.06      0.09    -0.24     0.12 1.00     5584     3002
## sigma_hispanTRUE     0.03      0.11    -0.18     0.24 1.00     2373     1954
## sigma_femaleTRUE    -0.11      0.08    -0.26     0.05 1.00     5304     3052
## sage_1               0.43      0.82    -1.35     1.75 1.00     2094     3263
## sigma_sage_1         0.06      1.76    -3.03     4.53 1.01      584      191
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>We can conclude that the 4 chains converged since the
<code>Rhat</code>s are consistently <span
class="math inline">\(&lt;=1.01\)</span>. We see that the sd
<code>Estimate</code>s of the random intercepts for <span
class="math inline">\(\sigma\)</span> are pretty small so we don’t
expect large variations in the residual variance depending on the
predictors. Larger sds can be observed for predicting <code>\mu</code>
(i.e., the actual Wordsum Scores). Males scored on average 0.11 higher
on Wordsum than females.</p>
</div>
<div id="check-model-fit" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Check model
fit</h3>
<pre class="r"><code>pp_check(brm_2) </code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-20-1.svg" width="768" /></p>
<div id="within-age-groups" class="section level4" number="3.2.2.1">
<h4><span class="header-section-number">3.2.2.1</span> Within age
groups</h4>
<pre class="r"><code>t &lt;- sb_data %&gt;% mutate(age_group = if_else(age &gt; 40, &quot;&gt; 40&quot;, &quot;=&lt; 40&quot;))


yrep &lt;- posterior_predict(brm_2, newdata = t, ndraws = 1000)


p &lt;- ppc_pit_ecdf_grouped(t$wordsum, yrep, group = as.factor(t$age_group), prob = 0.99, plot_diff = F)

p</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-21-1.svg" width="768" /></p>
<p>Some deviations at the right tail but not too bad.</p>
</div>
</div>
<div id="r2" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> R2</h3>
<pre class="r"><code>loo_R2(brm_2)</code></pre>
<pre><code>## Warning: Some Pareto k diagnostic values are too high. See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<pre><code>##    Estimate Est.Error    Q2.5  Q97.5
## R2  0.06978   0.02736 0.01507 0.1217</code></pre>
<p>The included predictors do not explain a lot of variance (~7%), so
not a lot of adjustment can happen even if there are differences between
the sample and the population.</p>
</div>
</div>
</div>
<div id="poststratifcation" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Poststratifcation</h1>
<p>This is the P part of RPP.</p>
<div
id="simulate-a-sample-with-the-same-joint-distribution-as-the-census"
class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Simulate a sample
with the same joint distribution as the census</h2>
<pre class="r"><code>set.seed(810)

sim_pop_sample &lt;- census_sb %&gt;% 
  sample_n(size = 100000, 
           weight = census_n, 
           replace = TRUE)


sim_pop_sample &lt;- census_sb %&gt;% 
  sample_n(size = 100000, 
           weight = census_n, 
           replace = TRUE) %&gt;% 
  mutate(pid = row_number() + max(sb_data$id)) |&gt; 
  select(pid, everything())</code></pre>
<pre><code>## Warning: There were 2 warnings in `mutate()`.
## The first warning was:
## ℹ In argument: `pid = row_number() + max(sb_data$id)`.
## Caused by warning:
## ! Unknown or uninitialised column: `id`.
## ℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.</code></pre>
</div>
<div id="estimate-cft-20-r-for-those-simulated-participants"
class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Estimate CFT 20-R for
those simulated participants</h2>
<p>Now that we have a post-stratified sample, we can use
<em>tidybayes</em>’s <code>add_predicted_draws()</code> function to draw
1000 samples (i.e., Wordsum Scores) from the posterior for each one of
the 100000 simulated participants in <code>sim_pop_sample</code>:</p>
<pre class="r"><code>sim_pop_sample_with_draws2 &lt;- sim_pop_sample %&gt;%
  add_predicted_draws(brm_7_ab, 
                      ndraws = 1000, 
                      seed = 810, 
                      allow_new_levels = TRUE) %&gt;% 
  mutate(.prediction = round(pmax(0, pmin(10, .prediction))))



sim_pop_sample_with_draws &lt;- sim_pop_sample %&gt;%
  add_predicted_draws(brm_2, 
                      ndraws = 1000, 
                      seed = 810, 
                      allow_new_levels = TRUE) %&gt;% 
  mutate(.prediction = round(pmax(0, pmin(10, .prediction))))

data.table::fwrite(sim_pop_sample_with_draws, &quot;data/results/wordsum/sim_pop_sample_with_draws.csv.gz&quot;)</code></pre>
<p>This yields a dataframe in long format with 100000 (number of
simulated participants) * 1000 (number of draws from the posterior) =
100 million rows. <code>allow_new_levels = TRUE</code> is necessary for
estimating the outcome for combinations of the 11 predictors which do
not occur in the actual TL sample. This is inevitable in detailed enough
poststratification tables and was the case here as the
poststratification table we used had over 3 million subcategories/rows.
The <code>mutate()</code> call serves to set all predicted CFT 20-R 20-R
score scores which go below or above the scale limits (0 and 10,
respectively), to those scale limits.</p>
</div>
</div>
<div id="produce-norms" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Produce norms</h1>
<div id="age-group-means-and-sds" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Age group means and
SDs</h2>
<p>Here we aggregate the intelligence scores by age and compute the RPP
corrected means and SDs (+ their SEs) for each age group:</p>
<pre class="r"><code>sim_pop_sample_with_draws &lt;- data.table::fread(&quot;data/results/wordsum/sim_pop_sample_with_draws.csv.gz&quot;)</code></pre>
<pre><code>## Error in data.table::fread(&quot;data/results/wordsum/sim_pop_sample_with_draws.csv.gz&quot;): File &#39;data/results/wordsum/sim_pop_sample_with_draws.csv.gz&#39; does not exist or is non-readable. getwd()==&#39;/home/sc.uni-leipzig.de/fb21ogim/SOBER/MRP_Norming_Tutorial&#39;</code></pre>
<pre class="r"><code>means_sds_and_ses_RPP &lt;- sim_pop_sample_with_draws2 %&gt;% 
  group_by(age, .draw) %&gt;% 
  summarise(mean_prediction = mean(.prediction), 
            sd_prediction = sd(.prediction)) %&gt;%
  group_by(age) %&gt;% 
  summarise(RPP_mean = mean(mean_prediction), 
            RPP_se_of_mean = sd(mean_prediction), 
            RPP_sd = sqrt(mean(sd_prediction^2)), 
            RPP_se_of_sd = sd(sd_prediction))</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;sim_pop_sample_with_draws2&#39; not found</code></pre>
<pre class="r"><code>means_sds_and_ses_RPP %&gt;% head(14) %&gt;% kable(digits = 2) %&gt;% kable_styling(full_width = FALSE)</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;means_sds_and_ses_RPP&#39; not found</code></pre>
<p>This code chunk first aggregates by age and posterior draw (1000) to
compute the mean and SD of Wordsum estimates across the 100000 simulated
participants. Then it computes the means and SDs across the draws (which
form the RPP means and SDs for each age group) and the SDs of the means
and SDs calculated in the previous step, hence yielding the Bayesian SEs
of the RPP means and SDs, respectively.</p>
</div>
<div id="age-norm-tables" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Age norm tables</h2>
<div id="linearly-transformed-iqs-t-scores" class="section level3"
number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Linearly
transformed IQs / T-scores</h3>
<p>Here we calculate linearly transformed IQs for all cft scores that
occur in the poststratified sample.</p>
<pre class="r"><code>iq &lt;- function(cft_score, mean, sd) {
  iq_score &lt;- ((cft_score - mean) / sd) * 15 + 100
  return(iq_score)
}

t &lt;- function(raw_score, mean, sd) {
  t_score_value &lt;- ((raw_score - mean) / sd) * 10 + 50
  return(t_score_value)
}

iqs_linear &lt;- sim_pop_sample_with_draws %&gt;% 
  left_join(select(means_sds_and_ses_RPP, c(RPP_mean, RPP_sd, age)), by = &quot;age&quot;) %&gt;%
  group_by(age) %&gt;% 
  mutate(wordsum_score = .prediction,
         RPP_IQ = iq(wordsum_score, RPP_mean, RPP_sd),
         RPP_T = t(wordsum_score, RPP_mean, RPP_sd)) %&gt;% 
  group_by(age, wordsum_score) %&gt;% 
  summarise(RPP_IQ = round(mean(iq_score)),
            RPP_T = round(mean(T_score)))</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;sim_pop_sample_with_draws&#39; not found</code></pre>
<pre class="r"><code>iqs_linear %&gt;% head(14) %&gt;% kable %&gt;% kable_styling(full_width = FALSE)</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;iqs_linear&#39; not found</code></pre>
<p>Due to the left skewed distributions linear transformation probably
underestimates IQs at the lower tail.</p>
</div>
<div id="normalised-area-transformed-normal-rank-transformed-iqs"
class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Normalised (area
transformed / normal rank transformed) IQs</h3>
<pre class="r"><code>iqs_normalised &lt;- sim_pop_sample_with_draws  %&gt;% 
  mutate(wordsum_score = as.numeric(as.character(.prediction))) %&gt;%
  group_by(age, .draw) %&gt;%
  mutate(n = n(),
         normal_transformed_score = qnorm((rank(wordsum_score) - 0.5) / n)) %&gt;%
  mutate(iq_score = normal_transformed_score * 15 + 100,
         T_score = normal_transformed_score * 10 + 50) %&gt;%
  group_by(age, wordsum_score) %&gt;%
  summarise(RPP_IQ = round(mean(iq_score)),
            RPP_T = round(mean(T_score)))</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;sim_pop_sample_with_draws&#39; not found</code></pre>
<pre class="r"><code>iqs_normalised %&gt;% head(14) %&gt;% kable %&gt;% kable_styling(full_width = FALSE)</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;iqs_normalised&#39; not found</code></pre>
</div>
<div id="percentile-based-scores" class="section level3" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Percentile based
scores</h3>
<p>Like above but without converting the cumulative distribution
function values to standard Gaussian quantiles and then to IQs/Ts.</p>
<pre class="r"><code>percentiles &lt;- sim_pop_sample_with_draws  %&gt;% 
  mutate(wordsum_score = .prediction) %&gt;%
  group_by(age, .draw) %&gt;%
  mutate(n = n(),
         percentile = (rank(wordsum_score) - 0.5) / n) %&gt;%
  group_by(age, wordsum_score) %&gt;%
  summarise(RPP_percentile = mean(percentile))</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;sim_pop_sample_with_draws&#39; not found</code></pre>
<pre class="r"><code>percentiles %&gt;% head(14) %&gt;% kable %&gt;% kable_styling(full_width = FALSE)</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;percentiles&#39; not found</code></pre>
</div>
</div>
</div>
<div id="additional-analyses-and-comparisons" class="section level1"
number="6">
<h1><span class="header-section-number">6</span> Additional analyses and
comparisons</h1>
<p>Here we use the home-made <code>age_norm_comparisons</code> function
to do some robustness checks and other analyses.</p>
<div id="rpp-vs-raw-vs-rp" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> RPP vs Raw vs RP</h2>
<pre class="r"><code>prediction_transform = list(
  function(x) round(pmax(0, pmin(10, x))) # for handling normal predictons (that go out of wordsum bounds)
)


sb_raw_vs_rpp_rp &lt;- age_norm_comparisons(
  brm_2,
  ps_table = census_sb, 
  RP = c(&quot;census&quot;, &quot;norming_sample&quot;),
  ps_variables = c(&quot;age&quot;, &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, &quot;region_birth&quot;, &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), 
  sim_size = 100000,
  prediction_transform = prediction_transform,
  labels = c(labels = c(&quot;Raw&quot;, &quot;RPP&quot;, &quot;RP&quot;)),
   palette = c(
  &quot;#BC3C29FF&quot;,
  &quot;#0072B5FF&quot;,
  # &quot;#20854EFF&quot;,
  # &quot;#7876B1FF&quot;,
  # &quot;#6F99ADFF&quot;,
  &quot;#E18727FF&quot;
  # &quot;#FFDC91FF&quot;,
  # &quot;#EE4C97FF&quot;
),
  output_file = &quot;data/results/wordsum/sb_raw_vs_rpp_rp.rds&quot;
  )


sb_raw_vs_rpp_rp[-1]</code></pre>
<pre><code>## $overall_estimates
## # A tibble: 3 × 5
##    Mean SE_of_Mean    SD SE_of_SD Model    
##   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    
## 1  7.30    NA       1.71  NA      Raw      
## 2  7.01     0.113   1.75   0.0726 RPP_brm_2
## 3  7.25     0.0733  1.70   0.0514 RP_brm_2 
## 
## $means_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-29-1.svg" width="768" /></p>
<pre><code>## 
## $SDs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_pointrange()`).</code></pre>
<pre><code>## Warning: Removed 46 rows containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-29-2.svg" width="768" /></p>
<pre><code>## 
## $SEs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_point()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-29-3.svg" width="768" /></p>
<pre><code>## 
## $percentile_plot</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-29-4.svg" width="768" /></p>
<p>As can be expected given the small associations between the
adjustment variables and the outcome, most of the adjustment to the age
group means were the result of the regularisation rather than the
poststratification. Nevertheless, poststratification led to a downward
adjustment of ~.3 points, indicating that Wordsum scores in this
Prolific sample are higher than in the broader US population. The
percentile plot also indicates that the poststratification introduced
additional consistency in the estimates across age groups.</p>
<div id="differences-in-iqs" class="section level3" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> Differences in
IQs</h3>
<pre class="r"><code>set.seed(810)

sim_norming_sample &lt;- sb_data %&gt;% 
  group_by(age, female, educ, income_brackets, race, hispan, region_residence, region_birth, degfield_branch, marst, occ_category) %&gt;% 
  summarise(sample_n = n()) %&gt;% 
  ungroup() %&gt;% 
  sample_n(size = 100000, 
           weight = sample_n, 
           replace = TRUE)


sim_norming_sample_with_draws &lt;- sim_norming_sample %&gt;%
  add_predicted_draws(brm_2, 
                      ndraws = 1000, 
                      seed = 810, 
                      allow_new_levels = TRUE) %&gt;% 
  mutate(.prediction = round(pmax(0, pmin(10, .prediction))))


RP_iqs_normalised &lt;- sim_norming_sample_with_draws  %&gt;% 
  group_by(age, .draw) %&gt;%
  mutate(n = n(),
         normal_transformed_score = qnorm((rank(.prediction) - 0.5) / n)) %&gt;%
  mutate(iq_score = normal_transformed_score * 15 + 100,
         T_score = normal_transformed_score * 10 + 50) %&gt;%
  group_by(age, wordsum_score = .prediction) %&gt;%
  summarise(RP_IQ = round(mean(iq_score)),
            RP_T = round(mean(T_score)))




raw_iqs_normalised &lt;- sb_data %&gt;% 
  group_by(age) %&gt;% 
  mutate(n = n(),
         normal_transformed_score = qnorm((rank(wordsum) - 0.5) / n)) %&gt;%
  mutate(iq_score = normal_transformed_score * 15 + 100,
         T_score = normal_transformed_score * 10 + 50) %&gt;%
  group_by(age, wordsum_score = wordsum) %&gt;%
  summarise(Raw_IQ = round(mean(iq_score)),
            Raw_T = round(mean(T_score)))

iqs &lt;- iqs_normalised %&gt;% 
  left_join(RP_iqs_normalised, by = c(&quot;age&quot;, &quot;wordsum_score&quot;)) %&gt;% 
  left_join(raw_iqs_normalised, by = c(&quot;age&quot;, &quot;wordsum_score&quot;)) </code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;iqs_normalised&#39; not found</code></pre>
<pre class="r"><code>mean(iqs$RPP_IQ-iqs$RP_IQ)</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;iqs&#39; not found</code></pre>
<pre class="r"><code>mean(abs(iqs$RPP_IQ-iqs$RP_IQ))</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;iqs&#39; not found</code></pre>
<pre class="r"><code>max(iqs$RPP_IQ-iqs$RP_IQ)</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;iqs&#39; not found</code></pre>
<pre class="r"><code>mean(iqs$RPP_IQ-iqs$Raw_IQ, na.rm = T)</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;iqs&#39; not found</code></pre>
<pre class="r"><code>mean(abs(iqs$RPP_IQ-iqs$Raw_IQ), na.rm = T)</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;iqs&#39; not found</code></pre>
<pre class="r"><code>max(iqs$RPP_IQ-iqs$Raw_IQ, na.rm = T)</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;iqs&#39; not found</code></pre>
<p>RPP IQs were on average 1.6 IQ points larger than raw ones (absolute
difference 4.9, max difference 20). Again illustrating that
poststratification made an incremental difference beyond the
regularisation, RPP IQs were almost 2 points larger than RP ones (max =
12).</p>
</div>
</div>
<div id="normal-vs.-ordinal" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Normal
vs. ordinal</h2>
<pre class="r"><code>prediction_transform = list(
  function(x) round(pmax(0, pmin(10, x))), # for handling normal predictons
  function(x) as.numeric(as.character(x))  # for handling ordinal predictions
)


sb_ord_nor &lt;- age_norm_comparisons(
  brm_2, brm_4, 
  ps_table = census_sb, 
  # RP = c(&quot;census&quot;, &quot;norming_sample&quot;),
  ps_variables = c(&quot;age&quot;, &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, &quot;region_birth&quot;, &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), 
  prediction_transform  = prediction_transform,
  sim_size = 100000,
  labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, normal&quot;, &quot;RPP, ordinal&quot;)),
   palette = c(
  &quot;#BC3C29FF&quot;,
  &quot;#0072B5FF&quot;,
  &quot;#20854EFF&quot;
  # &quot;#7876B1FF&quot;,
  # &quot;#6F99ADFF&quot;
  # &quot;#E18727FF&quot;
  # &quot;#FFDC91FF&quot;,
  # &quot;#EE4C97FF&quot;
),
  output_file = &quot;data/results/wordsum/sb_ord_nor.rds&quot;
  )


sb_ord_nor[-1]</code></pre>
<pre><code>## $overall_estimates
## # A tibble: 3 × 5
##    Mean SE_of_Mean    SD SE_of_SD Model    
##   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    
## 1  7.30     NA      1.71  NA      Raw      
## 2  7.01      0.113  1.75   0.0721 RPP_brm_2
## 3  6.98      0.126  1.83   0.0960 RPP_brm_4
## 
## $means_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-31-1.svg" width="768" /></p>
<pre><code>## 
## $SDs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_pointrange()`).</code></pre>
<pre><code>## Warning: Removed 46 rows containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-31-2.svg" width="768" /></p>
<pre><code>## 
## $SEs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_point()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-31-3.svg" width="768" /></p>
<pre><code>## 
## $percentile_plot</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-31-4.svg" width="768" /></p>
<p>Barely any difference in means, although ordinal predictions are
somewhat more dispersed.</p>
</div>
<div id="normal-vs.-binomial" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Normal
vs. binomial</h2>
<pre class="r"><code>prediction_transform = list(
  function(x) round(pmax(0, pmin(10, x))), # for handling normal predictons
  function(x) x  # leave binomial predicitons as is
)


sb_nor_bin &lt;- age_norm_comparisons(
  brm_2, brm_7, 
  ps_table = census_sb, 
  # RP = c(&quot;census&quot;, &quot;norming_sample&quot;),
  ps_variables = c(&quot;age&quot;, &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, &quot;region_birth&quot;, &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), 
  prediction_transform  = prediction_transform,
  sim_size = 100000,
  labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, normal&quot;, &quot;RPP, binomial&quot;)),
   palette = c(
  &quot;#BC3C29FF&quot;,
  &quot;#0072B5FF&quot;,
  &quot;#20854EFF&quot;
  # &quot;#7876B1FF&quot;,
  # &quot;#6F99ADFF&quot;
  # &quot;#E18727FF&quot;
  # &quot;#FFDC91FF&quot;,
  # &quot;#EE4C97FF&quot;
),
  output_file = &quot;data/results/wordsum/sb_nor_bin.rds&quot;
  )


sb_nor_bin[-1]</code></pre>
<pre><code>## $overall_estimates
## # A tibble: 3 × 5
##    Mean SE_of_Mean    SD SE_of_SD Model    
##   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    
## 1  7.30     NA      1.71  NA      Raw      
## 2  7.01      0.113  1.75   0.0722 RPP_brm_2
## 3  7.03      0.107  1.60   0.0446 RPP_brm_7
## 
## $means_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-32-1.svg" width="768" /></p>
<pre><code>## 
## $SDs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_pointrange()`).</code></pre>
<pre><code>## Warning: Removed 46 rows containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-32-2.svg" width="768" /></p>
<pre><code>## 
## $SEs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_point()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-32-3.svg" width="768" /></p>
<pre><code>## 
## $percentile_plot</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-32-4.svg" width="768" /></p>
<pre class="r"><code>prediction_transform = list(
  function(x) round(pmax(0, pmin(10, x))), # for handling normal predictons
  function(x) x,
  function(x) x  # leave binomial predicitons as is# leave binomial predicitons as is
)

source(&quot;age_norm_comparisons.R&quot;)

debug(age_norm_comparisons)


sb_nor_bin2 &lt;- age_norm_comparisons(
  brm_2, brm_7, brm_7_ab, 
  ps_table = census_sb, 
  # RP = c(&quot;census&quot;, &quot;norming_sample&quot;),
  # ps_variables = c(&quot;age&quot;, &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, &quot;region_birth&quot;, &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), 
  prediction_transform  = prediction_transform,
  sim_size = 100000,
  labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, normal&quot;, &quot;RPP, binomial&quot;, &quot;RPP, binomial + ID intercept&quot;)),
   palette = c(
  &quot;#BC3C29FF&quot;,
  &quot;#0072B5FF&quot;,
  &quot;#20854EFF&quot;,
  &quot;#7876B1FF&quot;
  # &quot;#6F99ADFF&quot;
  # &quot;#E18727FF&quot;
  # &quot;#FFDC91FF&quot;,
  # &quot;#EE4C97FF&quot;
),
  output_file = &quot;data/results/wordsum/sb_nor_bin2.rds&quot;
  )</code></pre>
<pre><code>## debugging in: age_norm_comparisons(brm_2, brm_7, brm_7_ab, ps_table = census_sb, 
##     prediction_transform = prediction_transform, sim_size = 100000, 
##     labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, normal&quot;, &quot;RPP, binomial&quot;, 
##         &quot;RPP, binomial + ID intercept&quot;)), palette = c(&quot;#BC3C29FF&quot;, 
##         &quot;#0072B5FF&quot;, &quot;#20854EFF&quot;, &quot;#7876B1FF&quot;), output_file = &quot;data/results/wordsum/sb_nor_bin2.rds&quot;)
## debug: {
##     if (file.exists(output_file)) {
##         message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
##         existing_data &lt;- readRDS(output_file)
##         means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
##         overall_estimates &lt;- existing_data$overall_estimates
##         percentile_data &lt;- existing_data$percentile_data
##         plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##             ps_table)
##         percentile_plot &lt;- NULL
##         if (!is.null(percentile_data)) {
##             approach_set &lt;- levels(percentile_data$Source)
##             if (&quot;Raw&quot; %in% approach_set) {
##                 color_values &lt;- palette
##             }
##             else {
##                 color_values &lt;- palette[-1]
##             }
##             baseMaxLabelLen &lt;- if (is.null(labels)) 
##                 1
##             else max(nchar(labels))
##             maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), 
##                 na.rm = TRUE)
##             myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 
##                 1)/1.7
##             max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##             percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##                 y = Raw_score, color = Source, group = interaction(Source, 
##                   percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##                 linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##                 max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##                 myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##                 name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##                 age == max_age_val, show_text, !is.na(line_label)), 
##                 ggplot2::aes(label = line_label), nudge_x = 1, 
##                 hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##                 y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##                 hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##                 panel.grid.minor.y = ggplot2::element_blank(), 
##                 panel.grid.minor.x = ggplot2::element_blank(), 
##                 panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##                   linewidth = 0.3), legend.position = &quot;top&quot;)
##         }
##         final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##             overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##             SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, 
##             percentile_plot = percentile_plot)
##         rm(existing_data, plots, percentile_data)
##         gc(verbose = FALSE)
##         return(final_list)
##     }
##     if (is.null(RP)) {
##         RP &lt;- &quot;census&quot;
##     }
##     if (is.character(RP) &amp;&amp; length(RP) == 1) {
##         RP &lt;- c(RP)
##     }
##     brms_models &lt;- list(...)
##     raw_call_names &lt;- sapply(substitute(list(...))[-1], deparse)
##     if (!all(sapply(brms_models, inherits, &quot;brmsfit&quot;))) {
##         stop(&quot;All &#39;...&#39; must be brmsfit models.&quot;)
##     }
##     nModels &lt;- length(brms_models)
##     if (is.null(ps_variables)) {
##         ps_variables &lt;- lapply(brms_models, function(model) {
##             all.vars(model$formula$formula)[-1]
##         })
##     }
##     else if (!is.list(ps_variables)) {
##         ps_variables &lt;- replicate(nModels, ps_variables, simplify = FALSE)
##     }
##     else if (length(ps_variables) != nModels) {
##         stop(&quot;If ps_variables is a list, its length must match number of brms models.&quot;)
##     }
##     if (!is.null(prediction_transform)) {
##         if (is.function(prediction_transform)) {
##             prediction_transform &lt;- replicate(nModels, prediction_transform, 
##                 simplify = FALSE)
##         }
##         else if (is.list(prediction_transform)) {
##             if (length(prediction_transform) != nModels) {
##                 stop(&quot;&#39;prediction_transform&#39; must match # of brms models if it&#39;s a list.&quot;)
##             }
##         }
##         else {
##             stop(&quot;&#39;prediction_transform&#39; must be NULL or a function or list of functions.&quot;)
##         }
##     }
##     else {
##         prediction_transform &lt;- replicate(nModels, NULL, simplify = FALSE)
##     }
##     first_mod_data &lt;- brms_models[[1]]$data
##     out_name &lt;- all.vars(brms_models[[1]]$formula$formula)[1]
##     if (is.na(out_name)) {
##         stop(&quot;Could not detect outcome from first brms model (multi-param?).&quot;)
##     }
##     first_mod_data[[out_name]] &lt;- as.numeric(as.character(first_mod_data[[out_name]]))
##     means_sds_and_ses_raw &lt;- first_mod_data %&gt;% dplyr::mutate(age = floor(age)) %&gt;% 
##         dplyr::group_by(age) %&gt;% dplyr::summarise(Raw_n = dplyr::n(), 
##         Raw_mean = mean(.data[[out_name]], na.rm = TRUE), Raw_sd = sd(.data[[out_name]], 
##             na.rm = TRUE), Raw_seOfmean = Raw_sd/sqrt(Raw_n), 
##         .groups = &quot;drop&quot;)
##     row_level_draws &lt;- list()
##     row_level_draws[[&quot;raw&quot;]] &lt;- list()
##     row_level_draws[[&quot;raw&quot;]][[raw_call_names[1]]] &lt;- first_mod_data %&gt;% 
##         dplyr::mutate(age = floor(age), .draw = 1, .prediction = .data[[out_name]])
##     age_level_list &lt;- list()
##     for (this_approach in RP) {
##         prefix &lt;- if (this_approach == &quot;census&quot;) 
##             &quot;RPP_&quot;
##         else &quot;RP_&quot;
##         approach_age_wide_list &lt;- list()
##         row_level_draws[[this_approach]] &lt;- list()
##         for (i in seq_along(brms_models)) {
##             model &lt;- brms_models[[i]]
##             model_name &lt;- raw_call_names[i]
##             short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##             full_name &lt;- paste0(prefix, &quot;brm_&quot;, short_name)
##             this_ps_vars &lt;- ps_variables[[i]]
##             if (this_approach == &quot;census&quot;) {
##                 sim_data &lt;- ps_table %&gt;% dplyr::filter(census_n != 
##                   0) %&gt;% dplyr::ungroup() %&gt;% dplyr::sample_n(size = sim_size, 
##                   weight = census_n, replace = TRUE)
##             }
##             else if (this_approach == &quot;norming_sample&quot;) {
##                 sim_data &lt;- first_mod_data %&gt;% dplyr::select(dplyr::all_of(this_ps_vars)) %&gt;% 
##                   dplyr::mutate(age = floor(age)) %&gt;% dplyr::filter(between(age, 
##                   min(ps_table$age), max(ps_table$age))) %&gt;% 
##                   dplyr::group_by(dplyr::across(dplyr::everything())) %&gt;% 
##                   dplyr::summarise(Raw_n = dplyr::n(), .groups = &quot;drop&quot;) %&gt;% 
##                   dplyr::sample_n(size = sim_size, weight = Raw_n, 
##                     replace = TRUE)
##             }
##             else {
##                 stop(&quot;RP must be &#39;census&#39; or &#39;norming_sample&#39;.&quot;)
##             }
##             sim_data_with_draws &lt;- sim_data %&gt;% mutate(pid = row_number() + 
##                 100000) %&gt;% select(pid, everything()) %&gt;% tidybayes::add_predicted_draws(model, 
##                 ndraws = 1000, seed = 810, re_formula = re_formula, 
##                 allow_new_levels = TRUE)
##             fun_pred &lt;- prediction_transform[[i]]
##             if (!is.null(fun_pred)) {
##                 sim_data_with_draws$.prediction &lt;- fun_pred(sim_data_with_draws$.prediction)
##             }
##             summary_df &lt;- sim_data_with_draws %&gt;% dplyr::group_by(age, 
##                 .draw) %&gt;% dplyr::summarise(mean_prediction = mean(.prediction), 
##                 sd_prediction = sd(.prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::group_by(age) %&gt;% dplyr::summarise(`:=`(!!paste0(full_name, 
##                 &quot;_mean&quot;), mean(mean_prediction)), `:=`(!!paste0(full_name, 
##                 &quot;_seOfmean&quot;), stats::sd(mean_prediction)), `:=`(!!paste0(full_name, 
##                 &quot;_sd&quot;), sqrt(mean(sd_prediction^2))), `:=`(!!paste0(full_name, 
##                 &quot;_seOfsd&quot;), stats::sd(sd_prediction)), .groups = &quot;drop&quot;)
##             approach_age_wide_list[[model_name]] &lt;- summary_df
##             row_level_draws[[this_approach]][[model_name]] &lt;- sim_data_with_draws
##         }
##         approach_age_wide &lt;- purrr::reduce(approach_age_wide_list, 
##             dplyr::left_join, by = &quot;age&quot;)
##         age_level_list[[this_approach]] &lt;- approach_age_wide
##     }
##     if (length(age_level_list) == 1) {
##         combined_results &lt;- age_level_list[[1]]
##     }
##     else if (length(age_level_list) &gt; 1) {
##         combined_results &lt;- purrr::reduce(age_level_list, dplyr::left_join, 
##             by = &quot;age&quot;)
##     }
##     else {
##         combined_results &lt;- means_sds_and_ses_raw
##     }
##     combined_results &lt;- combined_results %&gt;% dplyr::left_join(means_sds_and_ses_raw, 
##         by = &quot;age&quot;)
##     means_ns_sds_and_ses &lt;- combined_results %&gt;% tidyr::pivot_longer(-age, 
##         names_to = c(&quot;source&quot;, &quot;.value&quot;), names_pattern = &quot;(.*)_(.*)&quot;)
##     final_levels &lt;- &quot;Raw&quot;
##     for (i in seq_along(brms_models)) {
##         model_name &lt;- raw_call_names[i]
##         short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##         if (&quot;census&quot; %in% RP) {
##             final_levels &lt;- c(final_levels, paste0(&quot;RPP_brm_&quot;, 
##                 short_name))
##         }
##         if (&quot;norming_sample&quot; %in% RP) {
##             final_levels &lt;- c(final_levels, paste0(&quot;RP_brm_&quot;, 
##                 short_name))
##         }
##     }
##     existing_sources &lt;- unique(means_ns_sds_and_ses$source)
##     level_order &lt;- final_levels[final_levels %in% existing_sources]
##     leftover &lt;- setdiff(existing_sources, level_order)
##     if (length(leftover) &gt; 0) {
##         level_order &lt;- c(level_order, leftover)
##     }
##     means_ns_sds_and_ses &lt;- means_ns_sds_and_ses %&gt;% dplyr::mutate(source = factor(source, 
##         levels = level_order))
##     if (!is.null(labels)) {
##         if (length(labels) != length(level_order)) {
##             stop(&quot;Length of &#39;labels&#39; must match final # of sources.\n&quot;, 
##                 &quot;We have &quot;, length(level_order), &quot; sources in order: &quot;, 
##                 paste(level_order, collapse = &quot;, &quot;), &quot;\n&quot;, &quot;But you supplied &quot;, 
##                 length(labels), &quot; labels.&quot;)
##         }
##         means_ns_sds_and_ses$source &lt;- forcats::fct_relabel(means_ns_sds_and_ses$source, 
##             function(x) labels[match(x, level_order)])
##     }
##     overall_estimates &lt;- list()
##     for (appr in names(row_level_draws)) {
##         prefix &lt;- if (appr == &quot;census&quot;) 
##             &quot;RPP_&quot;
##         else if (appr == &quot;norming_sample&quot;) 
##             &quot;RP_&quot;
##         else &quot;Raw_&quot;
##         for (i in seq_along(brms_models)) {
##             model_name &lt;- raw_call_names[i]
##             short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##             full_label &lt;- if (appr == &quot;raw&quot;) {
##                 &quot;Raw&quot;
##             }
##             else {
##                 paste0(prefix, &quot;brm_&quot;, short_name)
##             }
##             df_sim &lt;- row_level_draws[[appr]][[model_name]]
##             if (!is.data.frame(df_sim)) 
##                 next
##             sum_df &lt;- df_sim %&gt;% dplyr::group_by(.draw) %&gt;% dplyr::summarise(mean_prediction = mean(.prediction), 
##                 sd_prediction = sd(.prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::summarise(Mean = mean(mean_prediction), 
##                   SE_of_Mean = stats::sd(mean_prediction), SD = sqrt(mean(sd_prediction^2)), 
##                   SE_of_SD = stats::sd(sd_prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::mutate(Model = full_label)
##             overall_estimates[[length(overall_estimates) + 1]] &lt;- sum_df
##         }
##     }
##     overall_estimates &lt;- dplyr::bind_rows(overall_estimates)
##     approach_set &lt;- setdiff(names(row_level_draws), &quot;raw&quot;)
##     target_p &lt;- c(0.01, 0.05, 0.5, 0.95, 0.99)
##     df_percentile_curves &lt;- list()
##     for (appr_name in approach_set) {
##         for (i in seq_along(brms_models)) {
##             modn &lt;- raw_call_names[i]
##             shortn &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, modn)
##             prefix_line &lt;- if (appr_name == &quot;census&quot;) 
##                 &quot;RPP_&quot;
##             else &quot;RP_&quot;
##             df_sim &lt;- row_level_draws[[appr_name]][[modn]]
##             if (!is.data.frame(df_sim)) 
##                 next
##             if (!is.numeric(df_sim$.prediction)) 
##                 next
##             source_string &lt;- paste0(prefix_line, &quot;brm_&quot;, shortn)
##             df_percent &lt;- df_sim %&gt;% dplyr::group_by(age) %&gt;% 
##                 dplyr::arrange(.prediction, .by_group = TRUE) %&gt;% 
##                 dplyr::mutate(N = dplyr::n(), percentile = (dplyr::row_number() - 
##                   0.5)/N) %&gt;% dplyr::ungroup() %&gt;% dplyr::group_by(age) %&gt;% 
##                 dplyr::summarise(pvals = list(target_p), scores = list(stats::approx(x = percentile, 
##                   y = .prediction, xout = target_p, ties = &quot;ordered&quot;)$y), 
##                   .groups = &quot;drop&quot;) %&gt;% tidyr::unnest(cols = c(pvals, 
##                 scores)) %&gt;% dplyr::rename(percentile_value = pvals, 
##                 Raw_score = scores) %&gt;% dplyr::mutate(Source = source_string)
##             df_percentile_curves[[length(df_percentile_curves) + 
##                 1]] &lt;- df_percent
##         }
##     }
##     df_percentile_final &lt;- dplyr::bind_rows(df_percentile_curves) %&gt;% 
##         dplyr::mutate(percentile_label = dplyr::case_when(abs(percentile_value - 
##             0.01) &lt; 0.000000001 ~ &quot;1st percentile&quot;, abs(percentile_value - 
##             0.05) &lt; 0.000000001 ~ &quot;5th percentile&quot;, abs(percentile_value - 
##             0.5) &lt; 0.000000001 ~ &quot;50th percentile&quot;, abs(percentile_value - 
##             0.95) &lt; 0.000000001 ~ &quot;95th percentile&quot;, abs(percentile_value - 
##             0.99) &lt; 0.000000001 ~ &quot;99th percentile&quot;, TRUE ~ paste0(round(100 * 
##             percentile_value, 1), &quot;th percentile&quot;)))
##     df_percentile_final$Source &lt;- factor(df_percentile_final$Source, 
##         levels = level_order[level_order != &quot;Raw&quot;])
##     if (!is.null(labels) &amp;&amp; length(labels) == length(level_order)) {
##         adjusted_labels &lt;- labels[-1]
##         level_order_no_raw &lt;- level_order[level_order != &quot;Raw&quot;]
##         if (length(adjusted_labels) != length(level_order_no_raw)) {
##             stop(&quot;Number of labels doesn&#39;t match number of sources for percentiles.&quot;)
##         }
##         df_percentile_final$Source &lt;- forcats::fct_relabel(df_percentile_final$Source, 
##             function(x) adjusted_labels[match(x, level_order_no_raw)])
##     }
##     methodLevels &lt;- levels(df_percentile_final$Source)
##     df_percentile_final &lt;- df_percentile_final %&gt;% dplyr::mutate(show_text = Source == 
##         methodLevels[1], line_label = dplyr::if_else(show_text, 
##         percentile_label, NA_character_))
##     percentile_data &lt;- df_percentile_final
##     final_data &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##         overall_estimates = overall_estimates, percentile_data = percentile_data)
##     saveRDS(final_data, file = output_file, compress = &quot;xz&quot;)
##     plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##         ps_table)
##     approach_set &lt;- levels(percentile_data$Source)
##     color_values &lt;- palette[-1]
##     baseMaxLabelLen &lt;- if (is.null(labels)) 
##         1
##     else max(nchar(labels))
##     maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
##     myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
##     max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##     percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##         y = Raw_score, color = Source, group = interaction(Source, 
##             percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##         linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##         max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##         myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##         name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##         age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##         nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##         y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##         hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##         panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##         panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##             linewidth = 0.3), legend.position = &quot;top&quot;)
##     list(means_ns_sds_and_ses = means_ns_sds_and_ses, overall_estimates = overall_estimates, 
##         means_plot = plots$means_plot, SDs_plot = plots$SDs_plot, 
##         SEs_plot = plots$SEs_plot, percentile_plot = percentile_plot)
## }
## debug: if (file.exists(output_file)) {
##     message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
##     existing_data &lt;- readRDS(output_file)
##     means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
##     overall_estimates &lt;- existing_data$overall_estimates
##     percentile_data &lt;- existing_data$percentile_data
##     plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##         ps_table)
##     percentile_plot &lt;- NULL
##     if (!is.null(percentile_data)) {
##         approach_set &lt;- levels(percentile_data$Source)
##         if (&quot;Raw&quot; %in% approach_set) {
##             color_values &lt;- palette
##         }
##         else {
##             color_values &lt;- palette[-1]
##         }
##         baseMaxLabelLen &lt;- if (is.null(labels)) 
##             1
##         else max(nchar(labels))
##         maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), 
##             na.rm = TRUE)
##         myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 
##             1)/1.7
##         max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##         percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##             y = Raw_score, color = Source, group = interaction(Source, 
##                 percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##             linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##             max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##             myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##             name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##             age == max_age_val, show_text, !is.na(line_label)), 
##             ggplot2::aes(label = line_label), nudge_x = 1, hjust = 0, 
##             family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, y = &quot;Test score&quot;, 
##             color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##             hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##             panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##             panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##                 linewidth = 0.3), legend.position = &quot;top&quot;)
##     }
##     final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##         overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##         SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, 
##         percentile_plot = percentile_plot)
##     rm(existing_data, plots, percentile_data)
##     gc(verbose = FALSE)
##     return(final_list)
## }
## debug: message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
## debug: existing_data &lt;- readRDS(output_file)
## debug: means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
## debug: overall_estimates &lt;- existing_data$overall_estimates
## debug: percentile_data &lt;- existing_data$percentile_data
## debug: plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, ps_table)
## debug: percentile_plot &lt;- NULL
## debug: if (!is.null(percentile_data)) {
##     approach_set &lt;- levels(percentile_data$Source)
##     if (&quot;Raw&quot; %in% approach_set) {
##         color_values &lt;- palette
##     }
##     else {
##         color_values &lt;- palette[-1]
##     }
##     baseMaxLabelLen &lt;- if (is.null(labels)) 
##         1
##     else max(nchar(labels))
##     maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
##     myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
##     max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##     percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##         y = Raw_score, color = Source, group = interaction(Source, 
##             percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##         linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##         max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##         myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##         name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##         age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##         nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##         y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##         hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##         panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##         panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##             linewidth = 0.3), legend.position = &quot;top&quot;)
## }
## debug: approach_set &lt;- levels(percentile_data$Source)
## debug: if (&quot;Raw&quot; %in% approach_set) {
##     color_values &lt;- palette
## } else {
##     color_values &lt;- palette[-1]
## }
## debug: color_values &lt;- palette[-1]
## debug: baseMaxLabelLen &lt;- if (is.null(labels)) 1 else max(nchar(labels))
## debug: max(nchar(labels))
## debug: maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
## debug: myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
## debug: max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
## debug: percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##     y = Raw_score, color = Source, group = interaction(Source, 
##         percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##     linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##     max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##     myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##     name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##     age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##     nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##     y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##     hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##     panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##     panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##         linewidth = 0.3), legend.position = &quot;top&quot;)
## debug: final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##     overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##     SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, percentile_plot = percentile_plot)
## debug: rm(existing_data, plots, percentile_data)
## debug: gc(verbose = FALSE)
## debug: return(final_list)
## exiting from: age_norm_comparisons(brm_2, brm_7, brm_7_ab, ps_table = census_sb, 
##     prediction_transform = prediction_transform, sim_size = 100000, 
##     labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, normal&quot;, &quot;RPP, binomial&quot;, 
##         &quot;RPP, binomial + ID intercept&quot;)), palette = c(&quot;#BC3C29FF&quot;, 
##         &quot;#0072B5FF&quot;, &quot;#20854EFF&quot;, &quot;#7876B1FF&quot;), output_file = &quot;data/results/wordsum/sb_nor_bin2.rds&quot;)</code></pre>
<pre class="r"><code>sb_nor_bin2</code></pre>
<pre><code>## $means_ns_sds_and_ses
## # A tibble: 188 × 7
##      age source                        mean seOfmean    sd  seOfsd     n
##    &lt;dbl&gt; &lt;fct&gt;                        &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;
##  1    21 RPP, normal                   6.63    0.218  1.65  0.144     NA
##  2    21 RPP, binomial                 6.54    0.228  1.60  0.0456    NA
##  3    21 RPP, binomial + ID intercept  6.55    0.255  1.83  0.0769    NA
##  4    21 Raw                           6.55    0.545  1.81 NA         11
##  5    22 RPP, normal                   6.66    0.203  1.67  0.133     NA
##  6    22 RPP, binomial                 6.58    0.209  1.61  0.0472    NA
##  7    22 RPP, binomial + ID intercept  6.61    0.235  1.83  0.0752    NA
##  8    22 Raw                           6.84    0.318  1.38 NA         19
##  9    23 RPP, normal                   6.71    0.183  1.69  0.124     NA
## 10    23 RPP, binomial                 6.64    0.185  1.61  0.0496    NA
## # ℹ 178 more rows
## 
## $overall_estimates
## # A tibble: 4 × 5
##    Mean SE_of_Mean    SD SE_of_SD Model       
##   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       
## 1  7.30     NA      1.71  NA      Raw         
## 2  7.01      0.113  1.75   0.0721 RPP_brm_2   
## 3  7.03      0.107  1.60   0.0443 RPP_brm_7   
## 4  7.03      0.115  1.80   0.0666 RPP_brm_7_ab
## 
## $means_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-33-1.svg" width="768" /></p>
<pre><code>## 
## $SDs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_pointrange()`).</code></pre>
<pre><code>## Warning: Removed 46 rows containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-33-2.svg" width="768" /></p>
<pre><code>## 
## $SEs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_point()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-33-3.svg" width="768" /></p>
<pre><code>## 
## $percentile_plot</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-33-4.svg" width="768" /></p>
</div>
<div id="normal-vs.-beta" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> Normal vs. beta</h2>
<pre class="r"><code>prediction_transform = list(
  function(x) round(pmax(0, pmin(10, x))), # for handling normal predictons
  function(x) round(x*11)  # for handling beta predictions
)


sb_nor_beta &lt;- age_norm_comparisons(
  brm_2, brm_8, 
  ps_table = census_sb, 
  # RP = c(&quot;census&quot;, &quot;norming_sample&quot;),
  ps_variables = c(&quot;age&quot;, &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, &quot;region_birth&quot;, &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), 
  prediction_transform  = prediction_transform,
  sim_size = 100000,
  labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, normal&quot;, &quot;RPP, beta&quot;)),
   palette = c(
  &quot;#BC3C29FF&quot;,
  &quot;#0072B5FF&quot;,
  &quot;#20854EFF&quot;
  # &quot;#7876B1FF&quot;,
  # &quot;#6F99ADFF&quot;
  # &quot;#E18727FF&quot;
  # &quot;#FFDC91FF&quot;,
  # &quot;#EE4C97FF&quot;
),
  output_file = &quot;data/results/wordsum/sb_nor_beta.rds&quot;
  )</code></pre>
<pre><code>## debugging in: age_norm_comparisons(brm_2, brm_8, ps_table = census_sb, ps_variables = c(&quot;age&quot;, 
##     &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, 
##     &quot;region_birth&quot;, &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), 
##     prediction_transform = prediction_transform, sim_size = 100000, 
##     labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, normal&quot;, &quot;RPP, beta&quot;)), 
##     palette = c(&quot;#BC3C29FF&quot;, &quot;#0072B5FF&quot;, &quot;#20854EFF&quot;), output_file = &quot;data/results/wordsum/sb_nor_beta.rds&quot;)
## debug: {
##     if (file.exists(output_file)) {
##         message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
##         existing_data &lt;- readRDS(output_file)
##         means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
##         overall_estimates &lt;- existing_data$overall_estimates
##         percentile_data &lt;- existing_data$percentile_data
##         plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##             ps_table)
##         percentile_plot &lt;- NULL
##         if (!is.null(percentile_data)) {
##             approach_set &lt;- levels(percentile_data$Source)
##             if (&quot;Raw&quot; %in% approach_set) {
##                 color_values &lt;- palette
##             }
##             else {
##                 color_values &lt;- palette[-1]
##             }
##             baseMaxLabelLen &lt;- if (is.null(labels)) 
##                 1
##             else max(nchar(labels))
##             maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), 
##                 na.rm = TRUE)
##             myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 
##                 1)/1.7
##             max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##             percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##                 y = Raw_score, color = Source, group = interaction(Source, 
##                   percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##                 linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##                 max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##                 myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##                 name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##                 age == max_age_val, show_text, !is.na(line_label)), 
##                 ggplot2::aes(label = line_label), nudge_x = 1, 
##                 hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##                 y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##                 hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##                 panel.grid.minor.y = ggplot2::element_blank(), 
##                 panel.grid.minor.x = ggplot2::element_blank(), 
##                 panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##                   linewidth = 0.3), legend.position = &quot;top&quot;)
##         }
##         final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##             overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##             SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, 
##             percentile_plot = percentile_plot)
##         rm(existing_data, plots, percentile_data)
##         gc(verbose = FALSE)
##         return(final_list)
##     }
##     if (is.null(RP)) {
##         RP &lt;- &quot;census&quot;
##     }
##     if (is.character(RP) &amp;&amp; length(RP) == 1) {
##         RP &lt;- c(RP)
##     }
##     brms_models &lt;- list(...)
##     raw_call_names &lt;- sapply(substitute(list(...))[-1], deparse)
##     if (!all(sapply(brms_models, inherits, &quot;brmsfit&quot;))) {
##         stop(&quot;All &#39;...&#39; must be brmsfit models.&quot;)
##     }
##     nModels &lt;- length(brms_models)
##     if (is.null(ps_variables)) {
##         ps_variables &lt;- lapply(brms_models, function(model) {
##             all.vars(model$formula$formula)[-1]
##         })
##     }
##     else if (!is.list(ps_variables)) {
##         ps_variables &lt;- replicate(nModels, ps_variables, simplify = FALSE)
##     }
##     else if (length(ps_variables) != nModels) {
##         stop(&quot;If ps_variables is a list, its length must match number of brms models.&quot;)
##     }
##     if (!is.null(prediction_transform)) {
##         if (is.function(prediction_transform)) {
##             prediction_transform &lt;- replicate(nModels, prediction_transform, 
##                 simplify = FALSE)
##         }
##         else if (is.list(prediction_transform)) {
##             if (length(prediction_transform) != nModels) {
##                 stop(&quot;&#39;prediction_transform&#39; must match # of brms models if it&#39;s a list.&quot;)
##             }
##         }
##         else {
##             stop(&quot;&#39;prediction_transform&#39; must be NULL or a function or list of functions.&quot;)
##         }
##     }
##     else {
##         prediction_transform &lt;- replicate(nModels, NULL, simplify = FALSE)
##     }
##     first_mod_data &lt;- brms_models[[1]]$data
##     out_name &lt;- all.vars(brms_models[[1]]$formula$formula)[1]
##     if (is.na(out_name)) {
##         stop(&quot;Could not detect outcome from first brms model (multi-param?).&quot;)
##     }
##     first_mod_data[[out_name]] &lt;- as.numeric(as.character(first_mod_data[[out_name]]))
##     means_sds_and_ses_raw &lt;- first_mod_data %&gt;% dplyr::mutate(age = floor(age)) %&gt;% 
##         dplyr::group_by(age) %&gt;% dplyr::summarise(Raw_n = dplyr::n(), 
##         Raw_mean = mean(.data[[out_name]], na.rm = TRUE), Raw_sd = sd(.data[[out_name]], 
##             na.rm = TRUE), Raw_seOfmean = Raw_sd/sqrt(Raw_n), 
##         .groups = &quot;drop&quot;)
##     row_level_draws &lt;- list()
##     row_level_draws[[&quot;raw&quot;]] &lt;- list()
##     row_level_draws[[&quot;raw&quot;]][[raw_call_names[1]]] &lt;- first_mod_data %&gt;% 
##         dplyr::mutate(age = floor(age), .draw = 1, .prediction = .data[[out_name]])
##     age_level_list &lt;- list()
##     for (this_approach in RP) {
##         prefix &lt;- if (this_approach == &quot;census&quot;) 
##             &quot;RPP_&quot;
##         else &quot;RP_&quot;
##         approach_age_wide_list &lt;- list()
##         row_level_draws[[this_approach]] &lt;- list()
##         for (i in seq_along(brms_models)) {
##             model &lt;- brms_models[[i]]
##             model_name &lt;- raw_call_names[i]
##             short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##             full_name &lt;- paste0(prefix, &quot;brm_&quot;, short_name)
##             this_ps_vars &lt;- ps_variables[[i]]
##             if (this_approach == &quot;census&quot;) {
##                 sim_data &lt;- ps_table %&gt;% dplyr::filter(census_n != 
##                   0) %&gt;% dplyr::ungroup() %&gt;% dplyr::sample_n(size = sim_size, 
##                   weight = census_n, replace = TRUE)
##             }
##             else if (this_approach == &quot;norming_sample&quot;) {
##                 sim_data &lt;- first_mod_data %&gt;% dplyr::select(dplyr::all_of(this_ps_vars)) %&gt;% 
##                   dplyr::mutate(age = floor(age)) %&gt;% dplyr::filter(between(age, 
##                   min(ps_table$age), max(ps_table$age))) %&gt;% 
##                   dplyr::group_by(dplyr::across(dplyr::everything())) %&gt;% 
##                   dplyr::summarise(Raw_n = dplyr::n(), .groups = &quot;drop&quot;) %&gt;% 
##                   dplyr::sample_n(size = sim_size, weight = Raw_n, 
##                     replace = TRUE)
##             }
##             else {
##                 stop(&quot;RP must be &#39;census&#39; or &#39;norming_sample&#39;.&quot;)
##             }
##             sim_data_with_draws &lt;- sim_data %&gt;% mutate(pid = row_number() + 
##                 100000) %&gt;% select(pid, everything()) %&gt;% tidybayes::add_predicted_draws(model, 
##                 ndraws = 1000, seed = 810, re_formula = re_formula, 
##                 allow_new_levels = TRUE)
##             fun_pred &lt;- prediction_transform[[i]]
##             if (!is.null(fun_pred)) {
##                 sim_data_with_draws$.prediction &lt;- fun_pred(sim_data_with_draws$.prediction)
##             }
##             summary_df &lt;- sim_data_with_draws %&gt;% dplyr::group_by(age, 
##                 .draw) %&gt;% dplyr::summarise(mean_prediction = mean(.prediction), 
##                 sd_prediction = sd(.prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::group_by(age) %&gt;% dplyr::summarise(`:=`(!!paste0(full_name, 
##                 &quot;_mean&quot;), mean(mean_prediction)), `:=`(!!paste0(full_name, 
##                 &quot;_seOfmean&quot;), stats::sd(mean_prediction)), `:=`(!!paste0(full_name, 
##                 &quot;_sd&quot;), sqrt(mean(sd_prediction^2))), `:=`(!!paste0(full_name, 
##                 &quot;_seOfsd&quot;), stats::sd(sd_prediction)), .groups = &quot;drop&quot;)
##             approach_age_wide_list[[model_name]] &lt;- summary_df
##             row_level_draws[[this_approach]][[model_name]] &lt;- sim_data_with_draws
##         }
##         approach_age_wide &lt;- purrr::reduce(approach_age_wide_list, 
##             dplyr::left_join, by = &quot;age&quot;)
##         age_level_list[[this_approach]] &lt;- approach_age_wide
##     }
##     if (length(age_level_list) == 1) {
##         combined_results &lt;- age_level_list[[1]]
##     }
##     else if (length(age_level_list) &gt; 1) {
##         combined_results &lt;- purrr::reduce(age_level_list, dplyr::left_join, 
##             by = &quot;age&quot;)
##     }
##     else {
##         combined_results &lt;- means_sds_and_ses_raw
##     }
##     combined_results &lt;- combined_results %&gt;% dplyr::left_join(means_sds_and_ses_raw, 
##         by = &quot;age&quot;)
##     means_ns_sds_and_ses &lt;- combined_results %&gt;% tidyr::pivot_longer(-age, 
##         names_to = c(&quot;source&quot;, &quot;.value&quot;), names_pattern = &quot;(.*)_(.*)&quot;)
##     final_levels &lt;- &quot;Raw&quot;
##     for (i in seq_along(brms_models)) {
##         model_name &lt;- raw_call_names[i]
##         short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##         if (&quot;census&quot; %in% RP) {
##             final_levels &lt;- c(final_levels, paste0(&quot;RPP_brm_&quot;, 
##                 short_name))
##         }
##         if (&quot;norming_sample&quot; %in% RP) {
##             final_levels &lt;- c(final_levels, paste0(&quot;RP_brm_&quot;, 
##                 short_name))
##         }
##     }
##     existing_sources &lt;- unique(means_ns_sds_and_ses$source)
##     level_order &lt;- final_levels[final_levels %in% existing_sources]
##     leftover &lt;- setdiff(existing_sources, level_order)
##     if (length(leftover) &gt; 0) {
##         level_order &lt;- c(level_order, leftover)
##     }
##     means_ns_sds_and_ses &lt;- means_ns_sds_and_ses %&gt;% dplyr::mutate(source = factor(source, 
##         levels = level_order))
##     if (!is.null(labels)) {
##         if (length(labels) != length(level_order)) {
##             stop(&quot;Length of &#39;labels&#39; must match final # of sources.\n&quot;, 
##                 &quot;We have &quot;, length(level_order), &quot; sources in order: &quot;, 
##                 paste(level_order, collapse = &quot;, &quot;), &quot;\n&quot;, &quot;But you supplied &quot;, 
##                 length(labels), &quot; labels.&quot;)
##         }
##         means_ns_sds_and_ses$source &lt;- forcats::fct_relabel(means_ns_sds_and_ses$source, 
##             function(x) labels[match(x, level_order)])
##     }
##     overall_estimates &lt;- list()
##     for (appr in names(row_level_draws)) {
##         prefix &lt;- if (appr == &quot;census&quot;) 
##             &quot;RPP_&quot;
##         else if (appr == &quot;norming_sample&quot;) 
##             &quot;RP_&quot;
##         else &quot;Raw_&quot;
##         for (i in seq_along(brms_models)) {
##             model_name &lt;- raw_call_names[i]
##             short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##             full_label &lt;- if (appr == &quot;raw&quot;) {
##                 &quot;Raw&quot;
##             }
##             else {
##                 paste0(prefix, &quot;brm_&quot;, short_name)
##             }
##             df_sim &lt;- row_level_draws[[appr]][[model_name]]
##             if (!is.data.frame(df_sim)) 
##                 next
##             sum_df &lt;- df_sim %&gt;% dplyr::group_by(.draw) %&gt;% dplyr::summarise(mean_prediction = mean(.prediction), 
##                 sd_prediction = sd(.prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::summarise(Mean = mean(mean_prediction), 
##                   SE_of_Mean = stats::sd(mean_prediction), SD = sqrt(mean(sd_prediction^2)), 
##                   SE_of_SD = stats::sd(sd_prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::mutate(Model = full_label)
##             overall_estimates[[length(overall_estimates) + 1]] &lt;- sum_df
##         }
##     }
##     overall_estimates &lt;- dplyr::bind_rows(overall_estimates)
##     approach_set &lt;- setdiff(names(row_level_draws), &quot;raw&quot;)
##     target_p &lt;- c(0.01, 0.05, 0.5, 0.95, 0.99)
##     df_percentile_curves &lt;- list()
##     for (appr_name in approach_set) {
##         for (i in seq_along(brms_models)) {
##             modn &lt;- raw_call_names[i]
##             shortn &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, modn)
##             prefix_line &lt;- if (appr_name == &quot;census&quot;) 
##                 &quot;RPP_&quot;
##             else &quot;RP_&quot;
##             df_sim &lt;- row_level_draws[[appr_name]][[modn]]
##             if (!is.data.frame(df_sim)) 
##                 next
##             if (!is.numeric(df_sim$.prediction)) 
##                 next
##             source_string &lt;- paste0(prefix_line, &quot;brm_&quot;, shortn)
##             df_percent &lt;- df_sim %&gt;% dplyr::group_by(age) %&gt;% 
##                 dplyr::arrange(.prediction, .by_group = TRUE) %&gt;% 
##                 dplyr::mutate(N = dplyr::n(), percentile = (dplyr::row_number() - 
##                   0.5)/N) %&gt;% dplyr::ungroup() %&gt;% dplyr::group_by(age) %&gt;% 
##                 dplyr::summarise(pvals = list(target_p), scores = list(stats::approx(x = percentile, 
##                   y = .prediction, xout = target_p, ties = &quot;ordered&quot;)$y), 
##                   .groups = &quot;drop&quot;) %&gt;% tidyr::unnest(cols = c(pvals, 
##                 scores)) %&gt;% dplyr::rename(percentile_value = pvals, 
##                 Raw_score = scores) %&gt;% dplyr::mutate(Source = source_string)
##             df_percentile_curves[[length(df_percentile_curves) + 
##                 1]] &lt;- df_percent
##         }
##     }
##     df_percentile_final &lt;- dplyr::bind_rows(df_percentile_curves) %&gt;% 
##         dplyr::mutate(percentile_label = dplyr::case_when(abs(percentile_value - 
##             0.01) &lt; 0.000000001 ~ &quot;1st percentile&quot;, abs(percentile_value - 
##             0.05) &lt; 0.000000001 ~ &quot;5th percentile&quot;, abs(percentile_value - 
##             0.5) &lt; 0.000000001 ~ &quot;50th percentile&quot;, abs(percentile_value - 
##             0.95) &lt; 0.000000001 ~ &quot;95th percentile&quot;, abs(percentile_value - 
##             0.99) &lt; 0.000000001 ~ &quot;99th percentile&quot;, TRUE ~ paste0(round(100 * 
##             percentile_value, 1), &quot;th percentile&quot;)))
##     df_percentile_final$Source &lt;- factor(df_percentile_final$Source, 
##         levels = level_order[level_order != &quot;Raw&quot;])
##     if (!is.null(labels) &amp;&amp; length(labels) == length(level_order)) {
##         adjusted_labels &lt;- labels[-1]
##         level_order_no_raw &lt;- level_order[level_order != &quot;Raw&quot;]
##         if (length(adjusted_labels) != length(level_order_no_raw)) {
##             stop(&quot;Number of labels doesn&#39;t match number of sources for percentiles.&quot;)
##         }
##         df_percentile_final$Source &lt;- forcats::fct_relabel(df_percentile_final$Source, 
##             function(x) adjusted_labels[match(x, level_order_no_raw)])
##     }
##     methodLevels &lt;- levels(df_percentile_final$Source)
##     df_percentile_final &lt;- df_percentile_final %&gt;% dplyr::mutate(show_text = Source == 
##         methodLevels[1], line_label = dplyr::if_else(show_text, 
##         percentile_label, NA_character_))
##     percentile_data &lt;- df_percentile_final
##     final_data &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##         overall_estimates = overall_estimates, percentile_data = percentile_data)
##     saveRDS(final_data, file = output_file, compress = &quot;xz&quot;)
##     plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##         ps_table)
##     approach_set &lt;- levels(percentile_data$Source)
##     color_values &lt;- palette[-1]
##     baseMaxLabelLen &lt;- if (is.null(labels)) 
##         1
##     else max(nchar(labels))
##     maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
##     myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
##     max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##     percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##         y = Raw_score, color = Source, group = interaction(Source, 
##             percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##         linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##         max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##         myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##         name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##         age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##         nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##         y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##         hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##         panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##         panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##             linewidth = 0.3), legend.position = &quot;top&quot;)
##     list(means_ns_sds_and_ses = means_ns_sds_and_ses, overall_estimates = overall_estimates, 
##         means_plot = plots$means_plot, SDs_plot = plots$SDs_plot, 
##         SEs_plot = plots$SEs_plot, percentile_plot = percentile_plot)
## }
## debug: if (file.exists(output_file)) {
##     message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
##     existing_data &lt;- readRDS(output_file)
##     means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
##     overall_estimates &lt;- existing_data$overall_estimates
##     percentile_data &lt;- existing_data$percentile_data
##     plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##         ps_table)
##     percentile_plot &lt;- NULL
##     if (!is.null(percentile_data)) {
##         approach_set &lt;- levels(percentile_data$Source)
##         if (&quot;Raw&quot; %in% approach_set) {
##             color_values &lt;- palette
##         }
##         else {
##             color_values &lt;- palette[-1]
##         }
##         baseMaxLabelLen &lt;- if (is.null(labels)) 
##             1
##         else max(nchar(labels))
##         maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), 
##             na.rm = TRUE)
##         myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 
##             1)/1.7
##         max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##         percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##             y = Raw_score, color = Source, group = interaction(Source, 
##                 percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##             linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##             max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##             myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##             name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##             age == max_age_val, show_text, !is.na(line_label)), 
##             ggplot2::aes(label = line_label), nudge_x = 1, hjust = 0, 
##             family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, y = &quot;Test score&quot;, 
##             color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##             hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##             panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##             panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##                 linewidth = 0.3), legend.position = &quot;top&quot;)
##     }
##     final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##         overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##         SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, 
##         percentile_plot = percentile_plot)
##     rm(existing_data, plots, percentile_data)
##     gc(verbose = FALSE)
##     return(final_list)
## }
## debug: message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
## debug: existing_data &lt;- readRDS(output_file)
## debug: means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
## debug: overall_estimates &lt;- existing_data$overall_estimates
## debug: percentile_data &lt;- existing_data$percentile_data
## debug: plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, ps_table)
## debug: percentile_plot &lt;- NULL
## debug: if (!is.null(percentile_data)) {
##     approach_set &lt;- levels(percentile_data$Source)
##     if (&quot;Raw&quot; %in% approach_set) {
##         color_values &lt;- palette
##     }
##     else {
##         color_values &lt;- palette[-1]
##     }
##     baseMaxLabelLen &lt;- if (is.null(labels)) 
##         1
##     else max(nchar(labels))
##     maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
##     myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
##     max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##     percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##         y = Raw_score, color = Source, group = interaction(Source, 
##             percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##         linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##         max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##         myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##         name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##         age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##         nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##         y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##         hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##         panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##         panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##             linewidth = 0.3), legend.position = &quot;top&quot;)
## }
## debug: approach_set &lt;- levels(percentile_data$Source)
## debug: if (&quot;Raw&quot; %in% approach_set) {
##     color_values &lt;- palette
## } else {
##     color_values &lt;- palette[-1]
## }
## debug: color_values &lt;- palette[-1]
## debug: baseMaxLabelLen &lt;- if (is.null(labels)) 1 else max(nchar(labels))
## debug: max(nchar(labels))
## debug: maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
## debug: myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
## debug: max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
## debug: percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##     y = Raw_score, color = Source, group = interaction(Source, 
##         percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##     linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##     max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##     myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##     name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##     age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##     nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##     y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##     hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##     panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##     panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##         linewidth = 0.3), legend.position = &quot;top&quot;)
## debug: final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##     overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##     SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, percentile_plot = percentile_plot)
## debug: rm(existing_data, plots, percentile_data)
## debug: gc(verbose = FALSE)
## debug: return(final_list)
## exiting from: age_norm_comparisons(brm_2, brm_8, ps_table = census_sb, ps_variables = c(&quot;age&quot;, 
##     &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, 
##     &quot;region_birth&quot;, &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), 
##     prediction_transform = prediction_transform, sim_size = 100000, 
##     labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, normal&quot;, &quot;RPP, beta&quot;)), 
##     palette = c(&quot;#BC3C29FF&quot;, &quot;#0072B5FF&quot;, &quot;#20854EFF&quot;), output_file = &quot;data/results/wordsum/sb_nor_beta.rds&quot;)</code></pre>
<pre class="r"><code>sb_nor_beta[-1]</code></pre>
<pre><code>## $overall_estimates
## # A tibble: 3 × 5
##    Mean SE_of_Mean    SD SE_of_SD Model    
##   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    
## 1  7.30     NA      1.71  NA      Raw      
## 2  7.01      0.113  1.75   0.0721 RPP_brm_2
## 3  7.05      0.119  1.76   0.0798 RPP_brm_8
## 
## $means_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-34-1.svg" width="768" /></p>
<pre><code>## 
## $SDs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_pointrange()`).</code></pre>
<pre><code>## Warning: Removed 46 rows containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-34-2.svg" width="768" /></p>
<pre><code>## 
## $SEs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_point()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-34-3.svg" width="768" /></p>
<pre><code>## 
## $percentile_plot</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-34-4.svg" width="768" /></p>
</div>
<div id="default-vs.-boosted" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Default
vs. boosted</h2>
<pre class="r"><code>prediction_transform = list(
  function(x) round(pmax(0, pmin(10, x))), # for handling normal predictons
  function(x) round(pmax(0, pmin(10, x)))  # for handling normal predictions
)


sb_default_vs_boosted &lt;- age_norm_comparisons(
  brm_2, brm_2_boosted, 
  ps_table = census_sb, 
  # RP = c(&quot;census&quot;, &quot;norming_sample&quot;),
  ps_variables = c(&quot;age&quot;, &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, &quot;region_birth&quot;, &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), 
  prediction_transform  = prediction_transform,
  sim_size = 100000,
  labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, normal&quot;, &quot;RPP, boosted normal&quot;)),
   palette = c(
  &quot;#BC3C29FF&quot;,
  &quot;#0072B5FF&quot;,
  &quot;#20854EFF&quot;
  # &quot;#7876B1FF&quot;,
  # &quot;#6F99ADFF&quot;
  # &quot;#E18727FF&quot;
  # &quot;#FFDC91FF&quot;,
  # &quot;#EE4C97FF&quot;
),
  output_file = &quot;data/results/wordsum/sb_default_vs_boosted.rds&quot;
  )</code></pre>
<pre><code>## debugging in: age_norm_comparisons(brm_2, brm_2_boosted, ps_table = census_sb, 
##     ps_variables = c(&quot;age&quot;, &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, 
##         &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, &quot;region_birth&quot;, 
##         &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), prediction_transform = prediction_transform, 
##     sim_size = 100000, labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, normal&quot;, 
##         &quot;RPP, boosted normal&quot;)), palette = c(&quot;#BC3C29FF&quot;, &quot;#0072B5FF&quot;, 
##         &quot;#20854EFF&quot;), output_file = &quot;data/results/wordsum/sb_default_vs_boosted.rds&quot;)
## debug: {
##     if (file.exists(output_file)) {
##         message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
##         existing_data &lt;- readRDS(output_file)
##         means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
##         overall_estimates &lt;- existing_data$overall_estimates
##         percentile_data &lt;- existing_data$percentile_data
##         plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##             ps_table)
##         percentile_plot &lt;- NULL
##         if (!is.null(percentile_data)) {
##             approach_set &lt;- levels(percentile_data$Source)
##             if (&quot;Raw&quot; %in% approach_set) {
##                 color_values &lt;- palette
##             }
##             else {
##                 color_values &lt;- palette[-1]
##             }
##             baseMaxLabelLen &lt;- if (is.null(labels)) 
##                 1
##             else max(nchar(labels))
##             maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), 
##                 na.rm = TRUE)
##             myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 
##                 1)/1.7
##             max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##             percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##                 y = Raw_score, color = Source, group = interaction(Source, 
##                   percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##                 linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##                 max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##                 myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##                 name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##                 age == max_age_val, show_text, !is.na(line_label)), 
##                 ggplot2::aes(label = line_label), nudge_x = 1, 
##                 hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##                 y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##                 hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##                 panel.grid.minor.y = ggplot2::element_blank(), 
##                 panel.grid.minor.x = ggplot2::element_blank(), 
##                 panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##                   linewidth = 0.3), legend.position = &quot;top&quot;)
##         }
##         final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##             overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##             SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, 
##             percentile_plot = percentile_plot)
##         rm(existing_data, plots, percentile_data)
##         gc(verbose = FALSE)
##         return(final_list)
##     }
##     if (is.null(RP)) {
##         RP &lt;- &quot;census&quot;
##     }
##     if (is.character(RP) &amp;&amp; length(RP) == 1) {
##         RP &lt;- c(RP)
##     }
##     brms_models &lt;- list(...)
##     raw_call_names &lt;- sapply(substitute(list(...))[-1], deparse)
##     if (!all(sapply(brms_models, inherits, &quot;brmsfit&quot;))) {
##         stop(&quot;All &#39;...&#39; must be brmsfit models.&quot;)
##     }
##     nModels &lt;- length(brms_models)
##     if (is.null(ps_variables)) {
##         ps_variables &lt;- lapply(brms_models, function(model) {
##             all.vars(model$formula$formula)[-1]
##         })
##     }
##     else if (!is.list(ps_variables)) {
##         ps_variables &lt;- replicate(nModels, ps_variables, simplify = FALSE)
##     }
##     else if (length(ps_variables) != nModels) {
##         stop(&quot;If ps_variables is a list, its length must match number of brms models.&quot;)
##     }
##     if (!is.null(prediction_transform)) {
##         if (is.function(prediction_transform)) {
##             prediction_transform &lt;- replicate(nModels, prediction_transform, 
##                 simplify = FALSE)
##         }
##         else if (is.list(prediction_transform)) {
##             if (length(prediction_transform) != nModels) {
##                 stop(&quot;&#39;prediction_transform&#39; must match # of brms models if it&#39;s a list.&quot;)
##             }
##         }
##         else {
##             stop(&quot;&#39;prediction_transform&#39; must be NULL or a function or list of functions.&quot;)
##         }
##     }
##     else {
##         prediction_transform &lt;- replicate(nModels, NULL, simplify = FALSE)
##     }
##     first_mod_data &lt;- brms_models[[1]]$data
##     out_name &lt;- all.vars(brms_models[[1]]$formula$formula)[1]
##     if (is.na(out_name)) {
##         stop(&quot;Could not detect outcome from first brms model (multi-param?).&quot;)
##     }
##     first_mod_data[[out_name]] &lt;- as.numeric(as.character(first_mod_data[[out_name]]))
##     means_sds_and_ses_raw &lt;- first_mod_data %&gt;% dplyr::mutate(age = floor(age)) %&gt;% 
##         dplyr::group_by(age) %&gt;% dplyr::summarise(Raw_n = dplyr::n(), 
##         Raw_mean = mean(.data[[out_name]], na.rm = TRUE), Raw_sd = sd(.data[[out_name]], 
##             na.rm = TRUE), Raw_seOfmean = Raw_sd/sqrt(Raw_n), 
##         .groups = &quot;drop&quot;)
##     row_level_draws &lt;- list()
##     row_level_draws[[&quot;raw&quot;]] &lt;- list()
##     row_level_draws[[&quot;raw&quot;]][[raw_call_names[1]]] &lt;- first_mod_data %&gt;% 
##         dplyr::mutate(age = floor(age), .draw = 1, .prediction = .data[[out_name]])
##     age_level_list &lt;- list()
##     for (this_approach in RP) {
##         prefix &lt;- if (this_approach == &quot;census&quot;) 
##             &quot;RPP_&quot;
##         else &quot;RP_&quot;
##         approach_age_wide_list &lt;- list()
##         row_level_draws[[this_approach]] &lt;- list()
##         for (i in seq_along(brms_models)) {
##             model &lt;- brms_models[[i]]
##             model_name &lt;- raw_call_names[i]
##             short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##             full_name &lt;- paste0(prefix, &quot;brm_&quot;, short_name)
##             this_ps_vars &lt;- ps_variables[[i]]
##             if (this_approach == &quot;census&quot;) {
##                 sim_data &lt;- ps_table %&gt;% dplyr::filter(census_n != 
##                   0) %&gt;% dplyr::ungroup() %&gt;% dplyr::sample_n(size = sim_size, 
##                   weight = census_n, replace = TRUE)
##             }
##             else if (this_approach == &quot;norming_sample&quot;) {
##                 sim_data &lt;- first_mod_data %&gt;% dplyr::select(dplyr::all_of(this_ps_vars)) %&gt;% 
##                   dplyr::mutate(age = floor(age)) %&gt;% dplyr::filter(between(age, 
##                   min(ps_table$age), max(ps_table$age))) %&gt;% 
##                   dplyr::group_by(dplyr::across(dplyr::everything())) %&gt;% 
##                   dplyr::summarise(Raw_n = dplyr::n(), .groups = &quot;drop&quot;) %&gt;% 
##                   dplyr::sample_n(size = sim_size, weight = Raw_n, 
##                     replace = TRUE)
##             }
##             else {
##                 stop(&quot;RP must be &#39;census&#39; or &#39;norming_sample&#39;.&quot;)
##             }
##             sim_data_with_draws &lt;- sim_data %&gt;% mutate(pid = row_number() + 
##                 100000) %&gt;% select(pid, everything()) %&gt;% tidybayes::add_predicted_draws(model, 
##                 ndraws = 1000, seed = 810, re_formula = re_formula, 
##                 allow_new_levels = TRUE)
##             fun_pred &lt;- prediction_transform[[i]]
##             if (!is.null(fun_pred)) {
##                 sim_data_with_draws$.prediction &lt;- fun_pred(sim_data_with_draws$.prediction)
##             }
##             summary_df &lt;- sim_data_with_draws %&gt;% dplyr::group_by(age, 
##                 .draw) %&gt;% dplyr::summarise(mean_prediction = mean(.prediction), 
##                 sd_prediction = sd(.prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::group_by(age) %&gt;% dplyr::summarise(`:=`(!!paste0(full_name, 
##                 &quot;_mean&quot;), mean(mean_prediction)), `:=`(!!paste0(full_name, 
##                 &quot;_seOfmean&quot;), stats::sd(mean_prediction)), `:=`(!!paste0(full_name, 
##                 &quot;_sd&quot;), sqrt(mean(sd_prediction^2))), `:=`(!!paste0(full_name, 
##                 &quot;_seOfsd&quot;), stats::sd(sd_prediction)), .groups = &quot;drop&quot;)
##             approach_age_wide_list[[model_name]] &lt;- summary_df
##             row_level_draws[[this_approach]][[model_name]] &lt;- sim_data_with_draws
##         }
##         approach_age_wide &lt;- purrr::reduce(approach_age_wide_list, 
##             dplyr::left_join, by = &quot;age&quot;)
##         age_level_list[[this_approach]] &lt;- approach_age_wide
##     }
##     if (length(age_level_list) == 1) {
##         combined_results &lt;- age_level_list[[1]]
##     }
##     else if (length(age_level_list) &gt; 1) {
##         combined_results &lt;- purrr::reduce(age_level_list, dplyr::left_join, 
##             by = &quot;age&quot;)
##     }
##     else {
##         combined_results &lt;- means_sds_and_ses_raw
##     }
##     combined_results &lt;- combined_results %&gt;% dplyr::left_join(means_sds_and_ses_raw, 
##         by = &quot;age&quot;)
##     means_ns_sds_and_ses &lt;- combined_results %&gt;% tidyr::pivot_longer(-age, 
##         names_to = c(&quot;source&quot;, &quot;.value&quot;), names_pattern = &quot;(.*)_(.*)&quot;)
##     final_levels &lt;- &quot;Raw&quot;
##     for (i in seq_along(brms_models)) {
##         model_name &lt;- raw_call_names[i]
##         short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##         if (&quot;census&quot; %in% RP) {
##             final_levels &lt;- c(final_levels, paste0(&quot;RPP_brm_&quot;, 
##                 short_name))
##         }
##         if (&quot;norming_sample&quot; %in% RP) {
##             final_levels &lt;- c(final_levels, paste0(&quot;RP_brm_&quot;, 
##                 short_name))
##         }
##     }
##     existing_sources &lt;- unique(means_ns_sds_and_ses$source)
##     level_order &lt;- final_levels[final_levels %in% existing_sources]
##     leftover &lt;- setdiff(existing_sources, level_order)
##     if (length(leftover) &gt; 0) {
##         level_order &lt;- c(level_order, leftover)
##     }
##     means_ns_sds_and_ses &lt;- means_ns_sds_and_ses %&gt;% dplyr::mutate(source = factor(source, 
##         levels = level_order))
##     if (!is.null(labels)) {
##         if (length(labels) != length(level_order)) {
##             stop(&quot;Length of &#39;labels&#39; must match final # of sources.\n&quot;, 
##                 &quot;We have &quot;, length(level_order), &quot; sources in order: &quot;, 
##                 paste(level_order, collapse = &quot;, &quot;), &quot;\n&quot;, &quot;But you supplied &quot;, 
##                 length(labels), &quot; labels.&quot;)
##         }
##         means_ns_sds_and_ses$source &lt;- forcats::fct_relabel(means_ns_sds_and_ses$source, 
##             function(x) labels[match(x, level_order)])
##     }
##     overall_estimates &lt;- list()
##     for (appr in names(row_level_draws)) {
##         prefix &lt;- if (appr == &quot;census&quot;) 
##             &quot;RPP_&quot;
##         else if (appr == &quot;norming_sample&quot;) 
##             &quot;RP_&quot;
##         else &quot;Raw_&quot;
##         for (i in seq_along(brms_models)) {
##             model_name &lt;- raw_call_names[i]
##             short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##             full_label &lt;- if (appr == &quot;raw&quot;) {
##                 &quot;Raw&quot;
##             }
##             else {
##                 paste0(prefix, &quot;brm_&quot;, short_name)
##             }
##             df_sim &lt;- row_level_draws[[appr]][[model_name]]
##             if (!is.data.frame(df_sim)) 
##                 next
##             sum_df &lt;- df_sim %&gt;% dplyr::group_by(.draw) %&gt;% dplyr::summarise(mean_prediction = mean(.prediction), 
##                 sd_prediction = sd(.prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::summarise(Mean = mean(mean_prediction), 
##                   SE_of_Mean = stats::sd(mean_prediction), SD = sqrt(mean(sd_prediction^2)), 
##                   SE_of_SD = stats::sd(sd_prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::mutate(Model = full_label)
##             overall_estimates[[length(overall_estimates) + 1]] &lt;- sum_df
##         }
##     }
##     overall_estimates &lt;- dplyr::bind_rows(overall_estimates)
##     approach_set &lt;- setdiff(names(row_level_draws), &quot;raw&quot;)
##     target_p &lt;- c(0.01, 0.05, 0.5, 0.95, 0.99)
##     df_percentile_curves &lt;- list()
##     for (appr_name in approach_set) {
##         for (i in seq_along(brms_models)) {
##             modn &lt;- raw_call_names[i]
##             shortn &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, modn)
##             prefix_line &lt;- if (appr_name == &quot;census&quot;) 
##                 &quot;RPP_&quot;
##             else &quot;RP_&quot;
##             df_sim &lt;- row_level_draws[[appr_name]][[modn]]
##             if (!is.data.frame(df_sim)) 
##                 next
##             if (!is.numeric(df_sim$.prediction)) 
##                 next
##             source_string &lt;- paste0(prefix_line, &quot;brm_&quot;, shortn)
##             df_percent &lt;- df_sim %&gt;% dplyr::group_by(age) %&gt;% 
##                 dplyr::arrange(.prediction, .by_group = TRUE) %&gt;% 
##                 dplyr::mutate(N = dplyr::n(), percentile = (dplyr::row_number() - 
##                   0.5)/N) %&gt;% dplyr::ungroup() %&gt;% dplyr::group_by(age) %&gt;% 
##                 dplyr::summarise(pvals = list(target_p), scores = list(stats::approx(x = percentile, 
##                   y = .prediction, xout = target_p, ties = &quot;ordered&quot;)$y), 
##                   .groups = &quot;drop&quot;) %&gt;% tidyr::unnest(cols = c(pvals, 
##                 scores)) %&gt;% dplyr::rename(percentile_value = pvals, 
##                 Raw_score = scores) %&gt;% dplyr::mutate(Source = source_string)
##             df_percentile_curves[[length(df_percentile_curves) + 
##                 1]] &lt;- df_percent
##         }
##     }
##     df_percentile_final &lt;- dplyr::bind_rows(df_percentile_curves) %&gt;% 
##         dplyr::mutate(percentile_label = dplyr::case_when(abs(percentile_value - 
##             0.01) &lt; 0.000000001 ~ &quot;1st percentile&quot;, abs(percentile_value - 
##             0.05) &lt; 0.000000001 ~ &quot;5th percentile&quot;, abs(percentile_value - 
##             0.5) &lt; 0.000000001 ~ &quot;50th percentile&quot;, abs(percentile_value - 
##             0.95) &lt; 0.000000001 ~ &quot;95th percentile&quot;, abs(percentile_value - 
##             0.99) &lt; 0.000000001 ~ &quot;99th percentile&quot;, TRUE ~ paste0(round(100 * 
##             percentile_value, 1), &quot;th percentile&quot;)))
##     df_percentile_final$Source &lt;- factor(df_percentile_final$Source, 
##         levels = level_order[level_order != &quot;Raw&quot;])
##     if (!is.null(labels) &amp;&amp; length(labels) == length(level_order)) {
##         adjusted_labels &lt;- labels[-1]
##         level_order_no_raw &lt;- level_order[level_order != &quot;Raw&quot;]
##         if (length(adjusted_labels) != length(level_order_no_raw)) {
##             stop(&quot;Number of labels doesn&#39;t match number of sources for percentiles.&quot;)
##         }
##         df_percentile_final$Source &lt;- forcats::fct_relabel(df_percentile_final$Source, 
##             function(x) adjusted_labels[match(x, level_order_no_raw)])
##     }
##     methodLevels &lt;- levels(df_percentile_final$Source)
##     df_percentile_final &lt;- df_percentile_final %&gt;% dplyr::mutate(show_text = Source == 
##         methodLevels[1], line_label = dplyr::if_else(show_text, 
##         percentile_label, NA_character_))
##     percentile_data &lt;- df_percentile_final
##     final_data &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##         overall_estimates = overall_estimates, percentile_data = percentile_data)
##     saveRDS(final_data, file = output_file, compress = &quot;xz&quot;)
##     plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##         ps_table)
##     approach_set &lt;- levels(percentile_data$Source)
##     color_values &lt;- palette[-1]
##     baseMaxLabelLen &lt;- if (is.null(labels)) 
##         1
##     else max(nchar(labels))
##     maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
##     myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
##     max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##     percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##         y = Raw_score, color = Source, group = interaction(Source, 
##             percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##         linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##         max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##         myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##         name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##         age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##         nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##         y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##         hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##         panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##         panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##             linewidth = 0.3), legend.position = &quot;top&quot;)
##     list(means_ns_sds_and_ses = means_ns_sds_and_ses, overall_estimates = overall_estimates, 
##         means_plot = plots$means_plot, SDs_plot = plots$SDs_plot, 
##         SEs_plot = plots$SEs_plot, percentile_plot = percentile_plot)
## }
## debug: if (file.exists(output_file)) {
##     message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
##     existing_data &lt;- readRDS(output_file)
##     means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
##     overall_estimates &lt;- existing_data$overall_estimates
##     percentile_data &lt;- existing_data$percentile_data
##     plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##         ps_table)
##     percentile_plot &lt;- NULL
##     if (!is.null(percentile_data)) {
##         approach_set &lt;- levels(percentile_data$Source)
##         if (&quot;Raw&quot; %in% approach_set) {
##             color_values &lt;- palette
##         }
##         else {
##             color_values &lt;- palette[-1]
##         }
##         baseMaxLabelLen &lt;- if (is.null(labels)) 
##             1
##         else max(nchar(labels))
##         maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), 
##             na.rm = TRUE)
##         myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 
##             1)/1.7
##         max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##         percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##             y = Raw_score, color = Source, group = interaction(Source, 
##                 percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##             linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##             max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##             myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##             name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##             age == max_age_val, show_text, !is.na(line_label)), 
##             ggplot2::aes(label = line_label), nudge_x = 1, hjust = 0, 
##             family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, y = &quot;Test score&quot;, 
##             color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##             hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##             panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##             panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##                 linewidth = 0.3), legend.position = &quot;top&quot;)
##     }
##     final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##         overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##         SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, 
##         percentile_plot = percentile_plot)
##     rm(existing_data, plots, percentile_data)
##     gc(verbose = FALSE)
##     return(final_list)
## }
## debug: message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
## debug: existing_data &lt;- readRDS(output_file)
## debug: means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
## debug: overall_estimates &lt;- existing_data$overall_estimates
## debug: percentile_data &lt;- existing_data$percentile_data
## debug: plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, ps_table)
## debug: percentile_plot &lt;- NULL
## debug: if (!is.null(percentile_data)) {
##     approach_set &lt;- levels(percentile_data$Source)
##     if (&quot;Raw&quot; %in% approach_set) {
##         color_values &lt;- palette
##     }
##     else {
##         color_values &lt;- palette[-1]
##     }
##     baseMaxLabelLen &lt;- if (is.null(labels)) 
##         1
##     else max(nchar(labels))
##     maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
##     myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
##     max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##     percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##         y = Raw_score, color = Source, group = interaction(Source, 
##             percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##         linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##         max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##         myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##         name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##         age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##         nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##         y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##         hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##         panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##         panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##             linewidth = 0.3), legend.position = &quot;top&quot;)
## }
## debug: approach_set &lt;- levels(percentile_data$Source)
## debug: if (&quot;Raw&quot; %in% approach_set) {
##     color_values &lt;- palette
## } else {
##     color_values &lt;- palette[-1]
## }
## debug: color_values &lt;- palette[-1]
## debug: baseMaxLabelLen &lt;- if (is.null(labels)) 1 else max(nchar(labels))
## debug: max(nchar(labels))
## debug: maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
## debug: myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
## debug: max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
## debug: percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##     y = Raw_score, color = Source, group = interaction(Source, 
##         percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##     linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##     max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##     myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##     name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##     age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##     nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##     y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##     hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##     panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##     panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##         linewidth = 0.3), legend.position = &quot;top&quot;)
## debug: final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##     overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##     SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, percentile_plot = percentile_plot)
## debug: rm(existing_data, plots, percentile_data)
## debug: gc(verbose = FALSE)
## debug: return(final_list)
## exiting from: age_norm_comparisons(brm_2, brm_2_boosted, ps_table = census_sb, 
##     ps_variables = c(&quot;age&quot;, &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, 
##         &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, &quot;region_birth&quot;, 
##         &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), prediction_transform = prediction_transform, 
##     sim_size = 100000, labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, normal&quot;, 
##         &quot;RPP, boosted normal&quot;)), palette = c(&quot;#BC3C29FF&quot;, &quot;#0072B5FF&quot;, 
##         &quot;#20854EFF&quot;), output_file = &quot;data/results/wordsum/sb_default_vs_boosted.rds&quot;)</code></pre>
<pre class="r"><code>sb_default_vs_boosted[-1]</code></pre>
<pre><code>## $overall_estimates
## # A tibble: 3 × 5
##    Mean SE_of_Mean    SD SE_of_SD Model            
##   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;            
## 1  7.30     NA      1.71  NA      Raw              
## 2  7.01      0.113  1.74   0.0722 RPP_brm_2        
## 3  7.00      0.115  1.75   0.0720 RPP_brm_2_boosted
## 
## $means_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-35-1.svg" width="768" /></p>
<pre><code>## 
## $SDs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_pointrange()`).</code></pre>
<pre><code>## Warning: Removed 46 rows containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-35-2.svg" width="768" /></p>
<pre><code>## 
## $SEs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_point()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-35-3.svg" width="768" /></p>
<pre><code>## 
## $percentile_plot</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-35-4.svg" width="768" /></p>
</div>
<div id="with-vs.-without-interactions" class="section level2"
number="6.6">
<h2><span class="header-section-number">6.6</span> With vs. without
interactions</h2>
<pre class="r"><code>prediction_transform = list(
  function(x) round(pmax(0, pmin(10, x))), # for handling normal predictons
  function(x) round(pmax(0, pmin(10, x)))  # for handling normal predictions
)


sb_with_vs_without_ints &lt;- age_norm_comparisons(
  brm_2, brm_1, 
  ps_table = census_sb, 
  # RP = c(&quot;census&quot;, &quot;norming_sample&quot;),
  ps_variables = c(&quot;age&quot;, &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, &quot;region_birth&quot;, &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), 
  prediction_transform  = prediction_transform,
  sim_size = 100000,
  labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, without ints&quot;, &quot;RPP, with ints&quot;)),
   palette = c(
  &quot;#BC3C29FF&quot;,
  &quot;#0072B5FF&quot;,
  &quot;#20854EFF&quot;
  # &quot;#7876B1FF&quot;,
  # &quot;#6F99ADFF&quot;
  # &quot;#E18727FF&quot;
  # &quot;#FFDC91FF&quot;,
  # &quot;#EE4C97FF&quot;
),
  output_file = &quot;data/results/wordsum/sb_with_vs_without_ints.rds&quot;
  )</code></pre>
<pre><code>## debugging in: age_norm_comparisons(brm_2, brm_1, ps_table = census_sb, ps_variables = c(&quot;age&quot;, 
##     &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, 
##     &quot;region_birth&quot;, &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), 
##     prediction_transform = prediction_transform, sim_size = 100000, 
##     labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, without ints&quot;, &quot;RPP, with ints&quot;)), 
##     palette = c(&quot;#BC3C29FF&quot;, &quot;#0072B5FF&quot;, &quot;#20854EFF&quot;), output_file = &quot;data/results/wordsum/sb_with_vs_without_ints.rds&quot;)
## debug: {
##     if (file.exists(output_file)) {
##         message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
##         existing_data &lt;- readRDS(output_file)
##         means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
##         overall_estimates &lt;- existing_data$overall_estimates
##         percentile_data &lt;- existing_data$percentile_data
##         plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##             ps_table)
##         percentile_plot &lt;- NULL
##         if (!is.null(percentile_data)) {
##             approach_set &lt;- levels(percentile_data$Source)
##             if (&quot;Raw&quot; %in% approach_set) {
##                 color_values &lt;- palette
##             }
##             else {
##                 color_values &lt;- palette[-1]
##             }
##             baseMaxLabelLen &lt;- if (is.null(labels)) 
##                 1
##             else max(nchar(labels))
##             maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), 
##                 na.rm = TRUE)
##             myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 
##                 1)/1.7
##             max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##             percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##                 y = Raw_score, color = Source, group = interaction(Source, 
##                   percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##                 linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##                 max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##                 myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##                 name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##                 age == max_age_val, show_text, !is.na(line_label)), 
##                 ggplot2::aes(label = line_label), nudge_x = 1, 
##                 hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##                 y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##                 hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##                 panel.grid.minor.y = ggplot2::element_blank(), 
##                 panel.grid.minor.x = ggplot2::element_blank(), 
##                 panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##                   linewidth = 0.3), legend.position = &quot;top&quot;)
##         }
##         final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##             overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##             SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, 
##             percentile_plot = percentile_plot)
##         rm(existing_data, plots, percentile_data)
##         gc(verbose = FALSE)
##         return(final_list)
##     }
##     if (is.null(RP)) {
##         RP &lt;- &quot;census&quot;
##     }
##     if (is.character(RP) &amp;&amp; length(RP) == 1) {
##         RP &lt;- c(RP)
##     }
##     brms_models &lt;- list(...)
##     raw_call_names &lt;- sapply(substitute(list(...))[-1], deparse)
##     if (!all(sapply(brms_models, inherits, &quot;brmsfit&quot;))) {
##         stop(&quot;All &#39;...&#39; must be brmsfit models.&quot;)
##     }
##     nModels &lt;- length(brms_models)
##     if (is.null(ps_variables)) {
##         ps_variables &lt;- lapply(brms_models, function(model) {
##             all.vars(model$formula$formula)[-1]
##         })
##     }
##     else if (!is.list(ps_variables)) {
##         ps_variables &lt;- replicate(nModels, ps_variables, simplify = FALSE)
##     }
##     else if (length(ps_variables) != nModels) {
##         stop(&quot;If ps_variables is a list, its length must match number of brms models.&quot;)
##     }
##     if (!is.null(prediction_transform)) {
##         if (is.function(prediction_transform)) {
##             prediction_transform &lt;- replicate(nModels, prediction_transform, 
##                 simplify = FALSE)
##         }
##         else if (is.list(prediction_transform)) {
##             if (length(prediction_transform) != nModels) {
##                 stop(&quot;&#39;prediction_transform&#39; must match # of brms models if it&#39;s a list.&quot;)
##             }
##         }
##         else {
##             stop(&quot;&#39;prediction_transform&#39; must be NULL or a function or list of functions.&quot;)
##         }
##     }
##     else {
##         prediction_transform &lt;- replicate(nModels, NULL, simplify = FALSE)
##     }
##     first_mod_data &lt;- brms_models[[1]]$data
##     out_name &lt;- all.vars(brms_models[[1]]$formula$formula)[1]
##     if (is.na(out_name)) {
##         stop(&quot;Could not detect outcome from first brms model (multi-param?).&quot;)
##     }
##     first_mod_data[[out_name]] &lt;- as.numeric(as.character(first_mod_data[[out_name]]))
##     means_sds_and_ses_raw &lt;- first_mod_data %&gt;% dplyr::mutate(age = floor(age)) %&gt;% 
##         dplyr::group_by(age) %&gt;% dplyr::summarise(Raw_n = dplyr::n(), 
##         Raw_mean = mean(.data[[out_name]], na.rm = TRUE), Raw_sd = sd(.data[[out_name]], 
##             na.rm = TRUE), Raw_seOfmean = Raw_sd/sqrt(Raw_n), 
##         .groups = &quot;drop&quot;)
##     row_level_draws &lt;- list()
##     row_level_draws[[&quot;raw&quot;]] &lt;- list()
##     row_level_draws[[&quot;raw&quot;]][[raw_call_names[1]]] &lt;- first_mod_data %&gt;% 
##         dplyr::mutate(age = floor(age), .draw = 1, .prediction = .data[[out_name]])
##     age_level_list &lt;- list()
##     for (this_approach in RP) {
##         prefix &lt;- if (this_approach == &quot;census&quot;) 
##             &quot;RPP_&quot;
##         else &quot;RP_&quot;
##         approach_age_wide_list &lt;- list()
##         row_level_draws[[this_approach]] &lt;- list()
##         for (i in seq_along(brms_models)) {
##             model &lt;- brms_models[[i]]
##             model_name &lt;- raw_call_names[i]
##             short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##             full_name &lt;- paste0(prefix, &quot;brm_&quot;, short_name)
##             this_ps_vars &lt;- ps_variables[[i]]
##             if (this_approach == &quot;census&quot;) {
##                 sim_data &lt;- ps_table %&gt;% dplyr::filter(census_n != 
##                   0) %&gt;% dplyr::ungroup() %&gt;% dplyr::sample_n(size = sim_size, 
##                   weight = census_n, replace = TRUE)
##             }
##             else if (this_approach == &quot;norming_sample&quot;) {
##                 sim_data &lt;- first_mod_data %&gt;% dplyr::select(dplyr::all_of(this_ps_vars)) %&gt;% 
##                   dplyr::mutate(age = floor(age)) %&gt;% dplyr::filter(between(age, 
##                   min(ps_table$age), max(ps_table$age))) %&gt;% 
##                   dplyr::group_by(dplyr::across(dplyr::everything())) %&gt;% 
##                   dplyr::summarise(Raw_n = dplyr::n(), .groups = &quot;drop&quot;) %&gt;% 
##                   dplyr::sample_n(size = sim_size, weight = Raw_n, 
##                     replace = TRUE)
##             }
##             else {
##                 stop(&quot;RP must be &#39;census&#39; or &#39;norming_sample&#39;.&quot;)
##             }
##             sim_data_with_draws &lt;- sim_data %&gt;% mutate(pid = row_number() + 
##                 100000) %&gt;% select(pid, everything()) %&gt;% tidybayes::add_predicted_draws(model, 
##                 ndraws = 1000, seed = 810, re_formula = re_formula, 
##                 allow_new_levels = TRUE)
##             fun_pred &lt;- prediction_transform[[i]]
##             if (!is.null(fun_pred)) {
##                 sim_data_with_draws$.prediction &lt;- fun_pred(sim_data_with_draws$.prediction)
##             }
##             summary_df &lt;- sim_data_with_draws %&gt;% dplyr::group_by(age, 
##                 .draw) %&gt;% dplyr::summarise(mean_prediction = mean(.prediction), 
##                 sd_prediction = sd(.prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::group_by(age) %&gt;% dplyr::summarise(`:=`(!!paste0(full_name, 
##                 &quot;_mean&quot;), mean(mean_prediction)), `:=`(!!paste0(full_name, 
##                 &quot;_seOfmean&quot;), stats::sd(mean_prediction)), `:=`(!!paste0(full_name, 
##                 &quot;_sd&quot;), sqrt(mean(sd_prediction^2))), `:=`(!!paste0(full_name, 
##                 &quot;_seOfsd&quot;), stats::sd(sd_prediction)), .groups = &quot;drop&quot;)
##             approach_age_wide_list[[model_name]] &lt;- summary_df
##             row_level_draws[[this_approach]][[model_name]] &lt;- sim_data_with_draws
##         }
##         approach_age_wide &lt;- purrr::reduce(approach_age_wide_list, 
##             dplyr::left_join, by = &quot;age&quot;)
##         age_level_list[[this_approach]] &lt;- approach_age_wide
##     }
##     if (length(age_level_list) == 1) {
##         combined_results &lt;- age_level_list[[1]]
##     }
##     else if (length(age_level_list) &gt; 1) {
##         combined_results &lt;- purrr::reduce(age_level_list, dplyr::left_join, 
##             by = &quot;age&quot;)
##     }
##     else {
##         combined_results &lt;- means_sds_and_ses_raw
##     }
##     combined_results &lt;- combined_results %&gt;% dplyr::left_join(means_sds_and_ses_raw, 
##         by = &quot;age&quot;)
##     means_ns_sds_and_ses &lt;- combined_results %&gt;% tidyr::pivot_longer(-age, 
##         names_to = c(&quot;source&quot;, &quot;.value&quot;), names_pattern = &quot;(.*)_(.*)&quot;)
##     final_levels &lt;- &quot;Raw&quot;
##     for (i in seq_along(brms_models)) {
##         model_name &lt;- raw_call_names[i]
##         short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##         if (&quot;census&quot; %in% RP) {
##             final_levels &lt;- c(final_levels, paste0(&quot;RPP_brm_&quot;, 
##                 short_name))
##         }
##         if (&quot;norming_sample&quot; %in% RP) {
##             final_levels &lt;- c(final_levels, paste0(&quot;RP_brm_&quot;, 
##                 short_name))
##         }
##     }
##     existing_sources &lt;- unique(means_ns_sds_and_ses$source)
##     level_order &lt;- final_levels[final_levels %in% existing_sources]
##     leftover &lt;- setdiff(existing_sources, level_order)
##     if (length(leftover) &gt; 0) {
##         level_order &lt;- c(level_order, leftover)
##     }
##     means_ns_sds_and_ses &lt;- means_ns_sds_and_ses %&gt;% dplyr::mutate(source = factor(source, 
##         levels = level_order))
##     if (!is.null(labels)) {
##         if (length(labels) != length(level_order)) {
##             stop(&quot;Length of &#39;labels&#39; must match final # of sources.\n&quot;, 
##                 &quot;We have &quot;, length(level_order), &quot; sources in order: &quot;, 
##                 paste(level_order, collapse = &quot;, &quot;), &quot;\n&quot;, &quot;But you supplied &quot;, 
##                 length(labels), &quot; labels.&quot;)
##         }
##         means_ns_sds_and_ses$source &lt;- forcats::fct_relabel(means_ns_sds_and_ses$source, 
##             function(x) labels[match(x, level_order)])
##     }
##     overall_estimates &lt;- list()
##     for (appr in names(row_level_draws)) {
##         prefix &lt;- if (appr == &quot;census&quot;) 
##             &quot;RPP_&quot;
##         else if (appr == &quot;norming_sample&quot;) 
##             &quot;RP_&quot;
##         else &quot;Raw_&quot;
##         for (i in seq_along(brms_models)) {
##             model_name &lt;- raw_call_names[i]
##             short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##             full_label &lt;- if (appr == &quot;raw&quot;) {
##                 &quot;Raw&quot;
##             }
##             else {
##                 paste0(prefix, &quot;brm_&quot;, short_name)
##             }
##             df_sim &lt;- row_level_draws[[appr]][[model_name]]
##             if (!is.data.frame(df_sim)) 
##                 next
##             sum_df &lt;- df_sim %&gt;% dplyr::group_by(.draw) %&gt;% dplyr::summarise(mean_prediction = mean(.prediction), 
##                 sd_prediction = sd(.prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::summarise(Mean = mean(mean_prediction), 
##                   SE_of_Mean = stats::sd(mean_prediction), SD = sqrt(mean(sd_prediction^2)), 
##                   SE_of_SD = stats::sd(sd_prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::mutate(Model = full_label)
##             overall_estimates[[length(overall_estimates) + 1]] &lt;- sum_df
##         }
##     }
##     overall_estimates &lt;- dplyr::bind_rows(overall_estimates)
##     approach_set &lt;- setdiff(names(row_level_draws), &quot;raw&quot;)
##     target_p &lt;- c(0.01, 0.05, 0.5, 0.95, 0.99)
##     df_percentile_curves &lt;- list()
##     for (appr_name in approach_set) {
##         for (i in seq_along(brms_models)) {
##             modn &lt;- raw_call_names[i]
##             shortn &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, modn)
##             prefix_line &lt;- if (appr_name == &quot;census&quot;) 
##                 &quot;RPP_&quot;
##             else &quot;RP_&quot;
##             df_sim &lt;- row_level_draws[[appr_name]][[modn]]
##             if (!is.data.frame(df_sim)) 
##                 next
##             if (!is.numeric(df_sim$.prediction)) 
##                 next
##             source_string &lt;- paste0(prefix_line, &quot;brm_&quot;, shortn)
##             df_percent &lt;- df_sim %&gt;% dplyr::group_by(age) %&gt;% 
##                 dplyr::arrange(.prediction, .by_group = TRUE) %&gt;% 
##                 dplyr::mutate(N = dplyr::n(), percentile = (dplyr::row_number() - 
##                   0.5)/N) %&gt;% dplyr::ungroup() %&gt;% dplyr::group_by(age) %&gt;% 
##                 dplyr::summarise(pvals = list(target_p), scores = list(stats::approx(x = percentile, 
##                   y = .prediction, xout = target_p, ties = &quot;ordered&quot;)$y), 
##                   .groups = &quot;drop&quot;) %&gt;% tidyr::unnest(cols = c(pvals, 
##                 scores)) %&gt;% dplyr::rename(percentile_value = pvals, 
##                 Raw_score = scores) %&gt;% dplyr::mutate(Source = source_string)
##             df_percentile_curves[[length(df_percentile_curves) + 
##                 1]] &lt;- df_percent
##         }
##     }
##     df_percentile_final &lt;- dplyr::bind_rows(df_percentile_curves) %&gt;% 
##         dplyr::mutate(percentile_label = dplyr::case_when(abs(percentile_value - 
##             0.01) &lt; 0.000000001 ~ &quot;1st percentile&quot;, abs(percentile_value - 
##             0.05) &lt; 0.000000001 ~ &quot;5th percentile&quot;, abs(percentile_value - 
##             0.5) &lt; 0.000000001 ~ &quot;50th percentile&quot;, abs(percentile_value - 
##             0.95) &lt; 0.000000001 ~ &quot;95th percentile&quot;, abs(percentile_value - 
##             0.99) &lt; 0.000000001 ~ &quot;99th percentile&quot;, TRUE ~ paste0(round(100 * 
##             percentile_value, 1), &quot;th percentile&quot;)))
##     df_percentile_final$Source &lt;- factor(df_percentile_final$Source, 
##         levels = level_order[level_order != &quot;Raw&quot;])
##     if (!is.null(labels) &amp;&amp; length(labels) == length(level_order)) {
##         adjusted_labels &lt;- labels[-1]
##         level_order_no_raw &lt;- level_order[level_order != &quot;Raw&quot;]
##         if (length(adjusted_labels) != length(level_order_no_raw)) {
##             stop(&quot;Number of labels doesn&#39;t match number of sources for percentiles.&quot;)
##         }
##         df_percentile_final$Source &lt;- forcats::fct_relabel(df_percentile_final$Source, 
##             function(x) adjusted_labels[match(x, level_order_no_raw)])
##     }
##     methodLevels &lt;- levels(df_percentile_final$Source)
##     df_percentile_final &lt;- df_percentile_final %&gt;% dplyr::mutate(show_text = Source == 
##         methodLevels[1], line_label = dplyr::if_else(show_text, 
##         percentile_label, NA_character_))
##     percentile_data &lt;- df_percentile_final
##     final_data &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##         overall_estimates = overall_estimates, percentile_data = percentile_data)
##     saveRDS(final_data, file = output_file, compress = &quot;xz&quot;)
##     plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##         ps_table)
##     approach_set &lt;- levels(percentile_data$Source)
##     color_values &lt;- palette[-1]
##     baseMaxLabelLen &lt;- if (is.null(labels)) 
##         1
##     else max(nchar(labels))
##     maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
##     myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
##     max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##     percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##         y = Raw_score, color = Source, group = interaction(Source, 
##             percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##         linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##         max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##         myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##         name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##         age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##         nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##         y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##         hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##         panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##         panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##             linewidth = 0.3), legend.position = &quot;top&quot;)
##     list(means_ns_sds_and_ses = means_ns_sds_and_ses, overall_estimates = overall_estimates, 
##         means_plot = plots$means_plot, SDs_plot = plots$SDs_plot, 
##         SEs_plot = plots$SEs_plot, percentile_plot = percentile_plot)
## }
## debug: if (file.exists(output_file)) {
##     message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
##     existing_data &lt;- readRDS(output_file)
##     means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
##     overall_estimates &lt;- existing_data$overall_estimates
##     percentile_data &lt;- existing_data$percentile_data
##     plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##         ps_table)
##     percentile_plot &lt;- NULL
##     if (!is.null(percentile_data)) {
##         approach_set &lt;- levels(percentile_data$Source)
##         if (&quot;Raw&quot; %in% approach_set) {
##             color_values &lt;- palette
##         }
##         else {
##             color_values &lt;- palette[-1]
##         }
##         baseMaxLabelLen &lt;- if (is.null(labels)) 
##             1
##         else max(nchar(labels))
##         maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), 
##             na.rm = TRUE)
##         myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 
##             1)/1.7
##         max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##         percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##             y = Raw_score, color = Source, group = interaction(Source, 
##                 percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##             linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##             max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##             myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##             name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##             age == max_age_val, show_text, !is.na(line_label)), 
##             ggplot2::aes(label = line_label), nudge_x = 1, hjust = 0, 
##             family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, y = &quot;Test score&quot;, 
##             color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##             hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##             panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##             panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##                 linewidth = 0.3), legend.position = &quot;top&quot;)
##     }
##     final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##         overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##         SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, 
##         percentile_plot = percentile_plot)
##     rm(existing_data, plots, percentile_data)
##     gc(verbose = FALSE)
##     return(final_list)
## }
## debug: message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
## debug: existing_data &lt;- readRDS(output_file)
## debug: means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
## debug: overall_estimates &lt;- existing_data$overall_estimates
## debug: percentile_data &lt;- existing_data$percentile_data
## debug: plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, ps_table)
## debug: percentile_plot &lt;- NULL
## debug: if (!is.null(percentile_data)) {
##     approach_set &lt;- levels(percentile_data$Source)
##     if (&quot;Raw&quot; %in% approach_set) {
##         color_values &lt;- palette
##     }
##     else {
##         color_values &lt;- palette[-1]
##     }
##     baseMaxLabelLen &lt;- if (is.null(labels)) 
##         1
##     else max(nchar(labels))
##     maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
##     myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
##     max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##     percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##         y = Raw_score, color = Source, group = interaction(Source, 
##             percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##         linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##         max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##         myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##         name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##         age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##         nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##         y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##         hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##         panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##         panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##             linewidth = 0.3), legend.position = &quot;top&quot;)
## }
## debug: approach_set &lt;- levels(percentile_data$Source)
## debug: if (&quot;Raw&quot; %in% approach_set) {
##     color_values &lt;- palette
## } else {
##     color_values &lt;- palette[-1]
## }
## debug: color_values &lt;- palette[-1]
## debug: baseMaxLabelLen &lt;- if (is.null(labels)) 1 else max(nchar(labels))
## debug: max(nchar(labels))
## debug: maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
## debug: myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
## debug: max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
## debug: percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##     y = Raw_score, color = Source, group = interaction(Source, 
##         percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##     linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##     max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##     myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##     name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##     age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##     nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##     y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##     hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##     panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##     panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##         linewidth = 0.3), legend.position = &quot;top&quot;)
## debug: final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##     overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##     SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, percentile_plot = percentile_plot)
## debug: rm(existing_data, plots, percentile_data)
## debug: gc(verbose = FALSE)
## debug: return(final_list)
## exiting from: age_norm_comparisons(brm_2, brm_1, ps_table = census_sb, ps_variables = c(&quot;age&quot;, 
##     &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, 
##     &quot;region_birth&quot;, &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), 
##     prediction_transform = prediction_transform, sim_size = 100000, 
##     labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, without ints&quot;, &quot;RPP, with ints&quot;)), 
##     palette = c(&quot;#BC3C29FF&quot;, &quot;#0072B5FF&quot;, &quot;#20854EFF&quot;), output_file = &quot;data/results/wordsum/sb_with_vs_without_ints.rds&quot;)</code></pre>
<pre class="r"><code>sb_with_vs_without_ints[-1]</code></pre>
<pre><code>## $overall_estimates
## # A tibble: 3 × 5
##    Mean SE_of_Mean    SD SE_of_SD Model    
##   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    
## 1  7.30     NA      1.71  NA      Raw      
## 2  7.01      0.112  1.75   0.0720 RPP_brm_2
## 3  7.00      0.131  1.88   0.0835 RPP_brm_1
## 
## $means_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-36-1.svg" width="768" /></p>
<pre><code>## 
## $SDs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_pointrange()`).</code></pre>
<pre><code>## Warning: Removed 46 rows containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-36-2.svg" width="768" /></p>
<pre><code>## 
## $SEs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_point()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-36-3.svg" width="768" /></p>
<pre><code>## 
## $percentile_plot</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-36-4.svg" width="768" /></p>
<p>Same here.</p>
</div>
<div id="effect-of-removing-careless-respondents" class="section level2"
number="6.7">
<h2><span class="header-section-number">6.7</span> Effect of removing
careless respondents?</h2>
<div id="exclude-participants-based-on-various-indicators"
class="section level3" number="6.7.1">
<h3><span class="header-section-number">6.7.1</span> Exclude
participants based on various indicators</h3>
<pre class="r"><code>library(careless)

main_qs &lt;- c(&quot;AAID&quot;, &quot;PANAS&quot;, &quot;PAQ&quot;, &quot;PSS&quot;, &quot;NEPS&quot;, &quot;ULS&quot;, &quot;FCV&quot;, &quot;DAQ&quot;, &quot;CESD&quot;, &quot;HEXACO&quot;, &quot;OCIR&quot;, &quot;PTQ&quot;, &quot;RAAS&quot;, &quot;KSA&quot;, &quot;SAS&quot;, &quot;MFQ&quot;, &quot;CQ&quot;)



sb_data_CR_cleaned &lt;-  sb_data %&gt;% 
  filter(if_all(starts_with(main_qs), ~ !is.na(.x))) %&gt;% 
  mutate(psychsyn = psychsyn(select(., starts_with(main_qs))),
         psychant = psychant(select(., starts_with(main_qs))),
                 CR_psychsyn_outlier = psychsyn &lt; 0.22,
                 CR_psychant_outlier = psychant &gt; -0.03,
                 CR_mahal_outlier = mahad(select(., starts_with(main_qs)), flag = TRUE, confidence = .999, plot = F)$flagged,
                 CR_not_serious = ZY02 == &quot;No, my responses should not be used.&quot;,
                 CR_knows_wordsum = MS04 == &quot;Yes&quot;) %&gt;% 
         filter(!if_any(starts_with(&quot;CR_&quot;), ~ .x == TRUE))</code></pre>
<p>Dropped 85 potentially careless respondents.</p>
</div>
<div
id="refit-model-and-compare-rpp-results-to-the-one-based-on-the-entire-data"
class="section level3" number="6.7.2">
<h3><span class="header-section-number">6.7.2</span> Refit model and
compare RPP results to the one based on the entire data</h3>
<pre class="r"><code>brm_2_non_CR &lt;- brm(bf(wordsum ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets),
                   sigma ~ s(age) + (1 | educ) + (1 | race) + hispan + (1 | region_residence) + (1 | marst) + (1 | degfield_branch) + (1 | occ_category) + (1 | region_birth)  + female + (1 | income_brackets)
                   ),
    seed = 14,
    chains = 4,
    file = &quot;data/brms/wordsum/sb/brm_4_non_CR&quot;,
    data = sb_data_scaled_CR_cleaned) %&gt;%
  add_criterion(&quot;loo&quot;)</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;sb_data_scaled_CR_cleaned&#39; not found</code></pre>
<pre class="r"><code>brm_2_non_CR</code></pre>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;brm_2_non_CR&#39; not found</code></pre>
<pre class="r"><code>prediction_transform = list(
  function(x) round(pmax(0, pmin(10, x))), 
  function(x) round(pmax(0, pmin(10, x)))  
)


sb_vs_non_CR &lt;- age_norm_comparisons(
  brm_2, brm_2_non_CR,
  ps_table = census_sb, 
  # RP = c(&quot;census&quot;, &quot;norming_sample&quot;),
  ps_variables = c(&quot;age&quot;, &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, &quot;region_birth&quot;, &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), 
  prediction_transform  = prediction_transform,
  sim_size = 100000,
  labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, full data&quot;, &quot;RPP, CR cleaned data&quot;)),
   palette = c(
  &quot;#BC3C29FF&quot;,
  &quot;#0072B5FF&quot;,
  # &quot;#20854EFF&quot;
  # &quot;#7876B1FF&quot;,
  # &quot;#6F99ADFF&quot;
  # &quot;#E18727FF&quot;
  # &quot;#FFDC91FF&quot;,
  &quot;#EE4C97FF&quot;
),
  output_file = &quot;data/results/wordsum/sb_vs_non_CR.rds&quot;
  )</code></pre>
<pre><code>## debugging in: age_norm_comparisons(brm_2, brm_2_non_CR, ps_table = census_sb, 
##     ps_variables = c(&quot;age&quot;, &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, 
##         &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, &quot;region_birth&quot;, 
##         &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), prediction_transform = prediction_transform, 
##     sim_size = 100000, labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, full data&quot;, 
##         &quot;RPP, CR cleaned data&quot;)), palette = c(&quot;#BC3C29FF&quot;, &quot;#0072B5FF&quot;, 
##         &quot;#EE4C97FF&quot;), output_file = &quot;data/results/wordsum/sb_vs_non_CR.rds&quot;)
## debug: {
##     if (file.exists(output_file)) {
##         message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
##         existing_data &lt;- readRDS(output_file)
##         means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
##         overall_estimates &lt;- existing_data$overall_estimates
##         percentile_data &lt;- existing_data$percentile_data
##         plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##             ps_table)
##         percentile_plot &lt;- NULL
##         if (!is.null(percentile_data)) {
##             approach_set &lt;- levels(percentile_data$Source)
##             if (&quot;Raw&quot; %in% approach_set) {
##                 color_values &lt;- palette
##             }
##             else {
##                 color_values &lt;- palette[-1]
##             }
##             baseMaxLabelLen &lt;- if (is.null(labels)) 
##                 1
##             else max(nchar(labels))
##             maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), 
##                 na.rm = TRUE)
##             myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 
##                 1)/1.7
##             max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##             percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##                 y = Raw_score, color = Source, group = interaction(Source, 
##                   percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##                 linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##                 max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##                 myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##                 name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##                 age == max_age_val, show_text, !is.na(line_label)), 
##                 ggplot2::aes(label = line_label), nudge_x = 1, 
##                 hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##                 y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##                 hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##                 panel.grid.minor.y = ggplot2::element_blank(), 
##                 panel.grid.minor.x = ggplot2::element_blank(), 
##                 panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##                   linewidth = 0.3), legend.position = &quot;top&quot;)
##         }
##         final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##             overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##             SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, 
##             percentile_plot = percentile_plot)
##         rm(existing_data, plots, percentile_data)
##         gc(verbose = FALSE)
##         return(final_list)
##     }
##     if (is.null(RP)) {
##         RP &lt;- &quot;census&quot;
##     }
##     if (is.character(RP) &amp;&amp; length(RP) == 1) {
##         RP &lt;- c(RP)
##     }
##     brms_models &lt;- list(...)
##     raw_call_names &lt;- sapply(substitute(list(...))[-1], deparse)
##     if (!all(sapply(brms_models, inherits, &quot;brmsfit&quot;))) {
##         stop(&quot;All &#39;...&#39; must be brmsfit models.&quot;)
##     }
##     nModels &lt;- length(brms_models)
##     if (is.null(ps_variables)) {
##         ps_variables &lt;- lapply(brms_models, function(model) {
##             all.vars(model$formula$formula)[-1]
##         })
##     }
##     else if (!is.list(ps_variables)) {
##         ps_variables &lt;- replicate(nModels, ps_variables, simplify = FALSE)
##     }
##     else if (length(ps_variables) != nModels) {
##         stop(&quot;If ps_variables is a list, its length must match number of brms models.&quot;)
##     }
##     if (!is.null(prediction_transform)) {
##         if (is.function(prediction_transform)) {
##             prediction_transform &lt;- replicate(nModels, prediction_transform, 
##                 simplify = FALSE)
##         }
##         else if (is.list(prediction_transform)) {
##             if (length(prediction_transform) != nModels) {
##                 stop(&quot;&#39;prediction_transform&#39; must match # of brms models if it&#39;s a list.&quot;)
##             }
##         }
##         else {
##             stop(&quot;&#39;prediction_transform&#39; must be NULL or a function or list of functions.&quot;)
##         }
##     }
##     else {
##         prediction_transform &lt;- replicate(nModels, NULL, simplify = FALSE)
##     }
##     first_mod_data &lt;- brms_models[[1]]$data
##     out_name &lt;- all.vars(brms_models[[1]]$formula$formula)[1]
##     if (is.na(out_name)) {
##         stop(&quot;Could not detect outcome from first brms model (multi-param?).&quot;)
##     }
##     first_mod_data[[out_name]] &lt;- as.numeric(as.character(first_mod_data[[out_name]]))
##     means_sds_and_ses_raw &lt;- first_mod_data %&gt;% dplyr::mutate(age = floor(age)) %&gt;% 
##         dplyr::group_by(age) %&gt;% dplyr::summarise(Raw_n = dplyr::n(), 
##         Raw_mean = mean(.data[[out_name]], na.rm = TRUE), Raw_sd = sd(.data[[out_name]], 
##             na.rm = TRUE), Raw_seOfmean = Raw_sd/sqrt(Raw_n), 
##         .groups = &quot;drop&quot;)
##     row_level_draws &lt;- list()
##     row_level_draws[[&quot;raw&quot;]] &lt;- list()
##     row_level_draws[[&quot;raw&quot;]][[raw_call_names[1]]] &lt;- first_mod_data %&gt;% 
##         dplyr::mutate(age = floor(age), .draw = 1, .prediction = .data[[out_name]])
##     age_level_list &lt;- list()
##     for (this_approach in RP) {
##         prefix &lt;- if (this_approach == &quot;census&quot;) 
##             &quot;RPP_&quot;
##         else &quot;RP_&quot;
##         approach_age_wide_list &lt;- list()
##         row_level_draws[[this_approach]] &lt;- list()
##         for (i in seq_along(brms_models)) {
##             model &lt;- brms_models[[i]]
##             model_name &lt;- raw_call_names[i]
##             short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##             full_name &lt;- paste0(prefix, &quot;brm_&quot;, short_name)
##             this_ps_vars &lt;- ps_variables[[i]]
##             if (this_approach == &quot;census&quot;) {
##                 sim_data &lt;- ps_table %&gt;% dplyr::filter(census_n != 
##                   0) %&gt;% dplyr::ungroup() %&gt;% dplyr::sample_n(size = sim_size, 
##                   weight = census_n, replace = TRUE)
##             }
##             else if (this_approach == &quot;norming_sample&quot;) {
##                 sim_data &lt;- first_mod_data %&gt;% dplyr::select(dplyr::all_of(this_ps_vars)) %&gt;% 
##                   dplyr::mutate(age = floor(age)) %&gt;% dplyr::filter(between(age, 
##                   min(ps_table$age), max(ps_table$age))) %&gt;% 
##                   dplyr::group_by(dplyr::across(dplyr::everything())) %&gt;% 
##                   dplyr::summarise(Raw_n = dplyr::n(), .groups = &quot;drop&quot;) %&gt;% 
##                   dplyr::sample_n(size = sim_size, weight = Raw_n, 
##                     replace = TRUE)
##             }
##             else {
##                 stop(&quot;RP must be &#39;census&#39; or &#39;norming_sample&#39;.&quot;)
##             }
##             sim_data_with_draws &lt;- sim_data %&gt;% mutate(pid = row_number() + 
##                 100000) %&gt;% select(pid, everything()) %&gt;% tidybayes::add_predicted_draws(model, 
##                 ndraws = 1000, seed = 810, re_formula = re_formula, 
##                 allow_new_levels = TRUE)
##             fun_pred &lt;- prediction_transform[[i]]
##             if (!is.null(fun_pred)) {
##                 sim_data_with_draws$.prediction &lt;- fun_pred(sim_data_with_draws$.prediction)
##             }
##             summary_df &lt;- sim_data_with_draws %&gt;% dplyr::group_by(age, 
##                 .draw) %&gt;% dplyr::summarise(mean_prediction = mean(.prediction), 
##                 sd_prediction = sd(.prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::group_by(age) %&gt;% dplyr::summarise(`:=`(!!paste0(full_name, 
##                 &quot;_mean&quot;), mean(mean_prediction)), `:=`(!!paste0(full_name, 
##                 &quot;_seOfmean&quot;), stats::sd(mean_prediction)), `:=`(!!paste0(full_name, 
##                 &quot;_sd&quot;), sqrt(mean(sd_prediction^2))), `:=`(!!paste0(full_name, 
##                 &quot;_seOfsd&quot;), stats::sd(sd_prediction)), .groups = &quot;drop&quot;)
##             approach_age_wide_list[[model_name]] &lt;- summary_df
##             row_level_draws[[this_approach]][[model_name]] &lt;- sim_data_with_draws
##         }
##         approach_age_wide &lt;- purrr::reduce(approach_age_wide_list, 
##             dplyr::left_join, by = &quot;age&quot;)
##         age_level_list[[this_approach]] &lt;- approach_age_wide
##     }
##     if (length(age_level_list) == 1) {
##         combined_results &lt;- age_level_list[[1]]
##     }
##     else if (length(age_level_list) &gt; 1) {
##         combined_results &lt;- purrr::reduce(age_level_list, dplyr::left_join, 
##             by = &quot;age&quot;)
##     }
##     else {
##         combined_results &lt;- means_sds_and_ses_raw
##     }
##     combined_results &lt;- combined_results %&gt;% dplyr::left_join(means_sds_and_ses_raw, 
##         by = &quot;age&quot;)
##     means_ns_sds_and_ses &lt;- combined_results %&gt;% tidyr::pivot_longer(-age, 
##         names_to = c(&quot;source&quot;, &quot;.value&quot;), names_pattern = &quot;(.*)_(.*)&quot;)
##     final_levels &lt;- &quot;Raw&quot;
##     for (i in seq_along(brms_models)) {
##         model_name &lt;- raw_call_names[i]
##         short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##         if (&quot;census&quot; %in% RP) {
##             final_levels &lt;- c(final_levels, paste0(&quot;RPP_brm_&quot;, 
##                 short_name))
##         }
##         if (&quot;norming_sample&quot; %in% RP) {
##             final_levels &lt;- c(final_levels, paste0(&quot;RP_brm_&quot;, 
##                 short_name))
##         }
##     }
##     existing_sources &lt;- unique(means_ns_sds_and_ses$source)
##     level_order &lt;- final_levels[final_levels %in% existing_sources]
##     leftover &lt;- setdiff(existing_sources, level_order)
##     if (length(leftover) &gt; 0) {
##         level_order &lt;- c(level_order, leftover)
##     }
##     means_ns_sds_and_ses &lt;- means_ns_sds_and_ses %&gt;% dplyr::mutate(source = factor(source, 
##         levels = level_order))
##     if (!is.null(labels)) {
##         if (length(labels) != length(level_order)) {
##             stop(&quot;Length of &#39;labels&#39; must match final # of sources.\n&quot;, 
##                 &quot;We have &quot;, length(level_order), &quot; sources in order: &quot;, 
##                 paste(level_order, collapse = &quot;, &quot;), &quot;\n&quot;, &quot;But you supplied &quot;, 
##                 length(labels), &quot; labels.&quot;)
##         }
##         means_ns_sds_and_ses$source &lt;- forcats::fct_relabel(means_ns_sds_and_ses$source, 
##             function(x) labels[match(x, level_order)])
##     }
##     overall_estimates &lt;- list()
##     for (appr in names(row_level_draws)) {
##         prefix &lt;- if (appr == &quot;census&quot;) 
##             &quot;RPP_&quot;
##         else if (appr == &quot;norming_sample&quot;) 
##             &quot;RP_&quot;
##         else &quot;Raw_&quot;
##         for (i in seq_along(brms_models)) {
##             model_name &lt;- raw_call_names[i]
##             short_name &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, model_name)
##             full_label &lt;- if (appr == &quot;raw&quot;) {
##                 &quot;Raw&quot;
##             }
##             else {
##                 paste0(prefix, &quot;brm_&quot;, short_name)
##             }
##             df_sim &lt;- row_level_draws[[appr]][[model_name]]
##             if (!is.data.frame(df_sim)) 
##                 next
##             sum_df &lt;- df_sim %&gt;% dplyr::group_by(.draw) %&gt;% dplyr::summarise(mean_prediction = mean(.prediction), 
##                 sd_prediction = sd(.prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::summarise(Mean = mean(mean_prediction), 
##                   SE_of_Mean = stats::sd(mean_prediction), SD = sqrt(mean(sd_prediction^2)), 
##                   SE_of_SD = stats::sd(sd_prediction), .groups = &quot;drop&quot;) %&gt;% 
##                 dplyr::mutate(Model = full_label)
##             overall_estimates[[length(overall_estimates) + 1]] &lt;- sum_df
##         }
##     }
##     overall_estimates &lt;- dplyr::bind_rows(overall_estimates)
##     approach_set &lt;- setdiff(names(row_level_draws), &quot;raw&quot;)
##     target_p &lt;- c(0.01, 0.05, 0.5, 0.95, 0.99)
##     df_percentile_curves &lt;- list()
##     for (appr_name in approach_set) {
##         for (i in seq_along(brms_models)) {
##             modn &lt;- raw_call_names[i]
##             shortn &lt;- sub(&quot;^brm_&quot;, &quot;&quot;, modn)
##             prefix_line &lt;- if (appr_name == &quot;census&quot;) 
##                 &quot;RPP_&quot;
##             else &quot;RP_&quot;
##             df_sim &lt;- row_level_draws[[appr_name]][[modn]]
##             if (!is.data.frame(df_sim)) 
##                 next
##             if (!is.numeric(df_sim$.prediction)) 
##                 next
##             source_string &lt;- paste0(prefix_line, &quot;brm_&quot;, shortn)
##             df_percent &lt;- df_sim %&gt;% dplyr::group_by(age) %&gt;% 
##                 dplyr::arrange(.prediction, .by_group = TRUE) %&gt;% 
##                 dplyr::mutate(N = dplyr::n(), percentile = (dplyr::row_number() - 
##                   0.5)/N) %&gt;% dplyr::ungroup() %&gt;% dplyr::group_by(age) %&gt;% 
##                 dplyr::summarise(pvals = list(target_p), scores = list(stats::approx(x = percentile, 
##                   y = .prediction, xout = target_p, ties = &quot;ordered&quot;)$y), 
##                   .groups = &quot;drop&quot;) %&gt;% tidyr::unnest(cols = c(pvals, 
##                 scores)) %&gt;% dplyr::rename(percentile_value = pvals, 
##                 Raw_score = scores) %&gt;% dplyr::mutate(Source = source_string)
##             df_percentile_curves[[length(df_percentile_curves) + 
##                 1]] &lt;- df_percent
##         }
##     }
##     df_percentile_final &lt;- dplyr::bind_rows(df_percentile_curves) %&gt;% 
##         dplyr::mutate(percentile_label = dplyr::case_when(abs(percentile_value - 
##             0.01) &lt; 0.000000001 ~ &quot;1st percentile&quot;, abs(percentile_value - 
##             0.05) &lt; 0.000000001 ~ &quot;5th percentile&quot;, abs(percentile_value - 
##             0.5) &lt; 0.000000001 ~ &quot;50th percentile&quot;, abs(percentile_value - 
##             0.95) &lt; 0.000000001 ~ &quot;95th percentile&quot;, abs(percentile_value - 
##             0.99) &lt; 0.000000001 ~ &quot;99th percentile&quot;, TRUE ~ paste0(round(100 * 
##             percentile_value, 1), &quot;th percentile&quot;)))
##     df_percentile_final$Source &lt;- factor(df_percentile_final$Source, 
##         levels = level_order[level_order != &quot;Raw&quot;])
##     if (!is.null(labels) &amp;&amp; length(labels) == length(level_order)) {
##         adjusted_labels &lt;- labels[-1]
##         level_order_no_raw &lt;- level_order[level_order != &quot;Raw&quot;]
##         if (length(adjusted_labels) != length(level_order_no_raw)) {
##             stop(&quot;Number of labels doesn&#39;t match number of sources for percentiles.&quot;)
##         }
##         df_percentile_final$Source &lt;- forcats::fct_relabel(df_percentile_final$Source, 
##             function(x) adjusted_labels[match(x, level_order_no_raw)])
##     }
##     methodLevels &lt;- levels(df_percentile_final$Source)
##     df_percentile_final &lt;- df_percentile_final %&gt;% dplyr::mutate(show_text = Source == 
##         methodLevels[1], line_label = dplyr::if_else(show_text, 
##         percentile_label, NA_character_))
##     percentile_data &lt;- df_percentile_final
##     final_data &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##         overall_estimates = overall_estimates, percentile_data = percentile_data)
##     saveRDS(final_data, file = output_file, compress = &quot;xz&quot;)
##     plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##         ps_table)
##     approach_set &lt;- levels(percentile_data$Source)
##     color_values &lt;- palette[-1]
##     baseMaxLabelLen &lt;- if (is.null(labels)) 
##         1
##     else max(nchar(labels))
##     maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
##     myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
##     max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##     percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##         y = Raw_score, color = Source, group = interaction(Source, 
##             percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##         linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##         max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##         myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##         name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##         age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##         nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##         y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##         hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##         panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##         panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##             linewidth = 0.3), legend.position = &quot;top&quot;)
##     list(means_ns_sds_and_ses = means_ns_sds_and_ses, overall_estimates = overall_estimates, 
##         means_plot = plots$means_plot, SDs_plot = plots$SDs_plot, 
##         SEs_plot = plots$SEs_plot, percentile_plot = percentile_plot)
## }
## debug: if (file.exists(output_file)) {
##     message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
##     existing_data &lt;- readRDS(output_file)
##     means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
##     overall_estimates &lt;- existing_data$overall_estimates
##     percentile_data &lt;- existing_data$percentile_data
##     plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, 
##         ps_table)
##     percentile_plot &lt;- NULL
##     if (!is.null(percentile_data)) {
##         approach_set &lt;- levels(percentile_data$Source)
##         if (&quot;Raw&quot; %in% approach_set) {
##             color_values &lt;- palette
##         }
##         else {
##             color_values &lt;- palette[-1]
##         }
##         baseMaxLabelLen &lt;- if (is.null(labels)) 
##             1
##         else max(nchar(labels))
##         maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), 
##             na.rm = TRUE)
##         myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 
##             1)/1.7
##         max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##         percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##             y = Raw_score, color = Source, group = interaction(Source, 
##                 percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##             linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##             max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##             myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##             name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##             age == max_age_val, show_text, !is.na(line_label)), 
##             ggplot2::aes(label = line_label), nudge_x = 1, hjust = 0, 
##             family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, y = &quot;Test score&quot;, 
##             color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##             hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##             panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##             panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##                 linewidth = 0.3), legend.position = &quot;top&quot;)
##     }
##     final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##         overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##         SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, 
##         percentile_plot = percentile_plot)
##     rm(existing_data, plots, percentile_data)
##     gc(verbose = FALSE)
##     return(final_list)
## }
## debug: message(&quot;File &#39;&quot;, output_file, &quot;&#39; already exists. Loading from RDS...&quot;)
## debug: existing_data &lt;- readRDS(output_file)
## debug: means_ns_sds_and_ses &lt;- existing_data$means_ns_sds_and_ses
## debug: overall_estimates &lt;- existing_data$overall_estimates
## debug: percentile_data &lt;- existing_data$percentile_data
## debug: plots &lt;- norm_plots(means_ns_sds_and_ses, labels, palette, ps_table)
## debug: percentile_plot &lt;- NULL
## debug: if (!is.null(percentile_data)) {
##     approach_set &lt;- levels(percentile_data$Source)
##     if (&quot;Raw&quot; %in% approach_set) {
##         color_values &lt;- palette
##     }
##     else {
##         color_values &lt;- palette[-1]
##     }
##     baseMaxLabelLen &lt;- if (is.null(labels)) 
##         1
##     else max(nchar(labels))
##     maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
##     myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
##     max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
##     percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##         y = Raw_score, color = Source, group = interaction(Source, 
##             percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##         linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##         max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##         myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##         name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##         age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##         nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##         y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##         hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##         panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##         panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##             linewidth = 0.3), legend.position = &quot;top&quot;)
## }
## debug: approach_set &lt;- levels(percentile_data$Source)
## debug: if (&quot;Raw&quot; %in% approach_set) {
##     color_values &lt;- palette
## } else {
##     color_values &lt;- palette[-1]
## }
## debug: color_values &lt;- palette[-1]
## debug: baseMaxLabelLen &lt;- if (is.null(labels)) 1 else max(nchar(labels))
## debug: max(nchar(labels))
## debug: maxLabelLen2 &lt;- max(nchar(percentile_data$line_label), na.rm = TRUE)
## debug: myExpandRight2 &lt;- max(baseMaxLabelLen, maxLabelLen2, 1)/1.7
## debug: max_age_val &lt;- max(percentile_data$age, na.rm = TRUE)
## debug: percentile_plot &lt;- percentile_data %&gt;% ggplot2::ggplot(ggplot2::aes(x = age, 
##     y = Raw_score, color = Source, group = interaction(Source, 
##         percentile_label))) + ggplot2::geom_step(linewidth = 1, 
##     linetype = 1) + ggplot2::scale_x_continuous(breaks = seq(min(ps_table$age), 
##     max(ps_table$age), by = 2), expand = ggplot2::expansion(add = c(1, 
##     myExpandRight2))) + ggplot2::scale_color_manual(values = color_values, 
##     name = &quot;&quot;) + ggplot2::geom_text(data = dplyr::filter(percentile_data, 
##     age == max_age_val, show_text, !is.na(line_label)), ggplot2::aes(label = line_label), 
##     nudge_x = 1, hjust = 0, family = &quot;Times&quot;) + ggplot2::labs(x = &quot;Age&quot;, 
##     y = &quot;Test score&quot;, color = &quot;&quot;) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, 
##     hjust = 1), panel.grid.major.y = ggplot2::element_blank(), 
##     panel.grid.minor.y = ggplot2::element_blank(), panel.grid.minor.x = ggplot2::element_blank(), 
##     panel.grid.major.x = ggplot2::element_line(linetype = &quot;dashed&quot;, 
##         linewidth = 0.3), legend.position = &quot;top&quot;)
## debug: final_list &lt;- list(means_ns_sds_and_ses = means_ns_sds_and_ses, 
##     overall_estimates = overall_estimates, means_plot = plots$means_plot, 
##     SDs_plot = plots$SDs_plot, SEs_plot = plots$SEs_plot, percentile_plot = percentile_plot)
## debug: rm(existing_data, plots, percentile_data)
## debug: gc(verbose = FALSE)
## debug: return(final_list)
## exiting from: age_norm_comparisons(brm_2, brm_2_non_CR, ps_table = census_sb, 
##     ps_variables = c(&quot;age&quot;, &quot;female&quot;, &quot;educ&quot;, &quot;income_brackets&quot;, 
##         &quot;race&quot;, &quot;hispan&quot;, &quot;region_residence&quot;, &quot;region_birth&quot;, 
##         &quot;degfield_branch&quot;, &quot;marst&quot;, &quot;occ_category&quot;), prediction_transform = prediction_transform, 
##     sim_size = 100000, labels = c(labels = c(&quot;Raw&quot;, &quot;RPP, full data&quot;, 
##         &quot;RPP, CR cleaned data&quot;)), palette = c(&quot;#BC3C29FF&quot;, &quot;#0072B5FF&quot;, 
##         &quot;#EE4C97FF&quot;), output_file = &quot;data/results/wordsum/sb_vs_non_CR.rds&quot;)</code></pre>
<pre class="r"><code>sb_vs_non_CR[-1]</code></pre>
<pre><code>## $overall_estimates
## # A tibble: 3 × 5
##    Mean SE_of_Mean    SD SE_of_SD Model           
##   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;           
## 1  7.30     NA      1.71  NA      Raw             
## 2  7.00      0.113  1.75   0.0722 RPP_brm_2       
## 3  7.06      0.125  1.69   0.0882 RPP_brm_2_non_CR
## 
## $means_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-39-1.svg" width="768" /></p>
<pre><code>## 
## $SDs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_pointrange()`).</code></pre>
<pre><code>## Warning: Removed 46 rows containing missing values or values outside the scale range (`geom_segment()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-39-2.svg" width="768" /></p>
<pre><code>## 
## $SEs_plot</code></pre>
<pre><code>## Warning: Removed 1 row containing missing values or values outside the scale range (`geom_point()`).</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-39-3.svg" width="768" /></p>
<pre><code>## 
## $percentile_plot</code></pre>
<p><img src="tutorial_files/figure-html/unnamed-chunk-39-4.svg" width="768" /></p>
<p>Negligible differences despite dropping 85/478 datapoints.</p>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.4.1 (2024-06-14)
## Platform: x86_64-pc-linux-gnu
## Running under: Rocky Linux 9.6 (Blue Onyx)
## 
## Matrix products: default
## BLAS/LAPACK: FlexiBLAS OPENBLAS;  LAPACK version 3.11.0
## 
## locale:
##  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
##  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8    LC_PAPER=en_US.UTF-8       LC_NAME=C                 
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
## 
## time zone: Europe/Berlin
## tzcode source: system (glibc)
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] careless_1.2.2         rstan_2.32.6           StanHeaders_2.32.10    bayesplot_1.11.1       marginaleffects_0.24.0
##  [6] tidybayes_3.0.7        brms_2.22.0            Rcpp_1.0.12            kableExtra_1.4.0       ggrepel_0.9.6         
## [11] data.table_1.16.4      haven_2.5.4            lubridate_1.9.4        forcats_1.0.0          stringr_1.5.1         
## [16] dplyr_1.1.4            purrr_1.0.2            readr_2.1.5            tidyr_1.3.1            tibble_3.2.1          
## [21] ggplot2_3.5.1          tidyverse_2.0.0       
## 
## loaded via a namespace (and not attached):
##  [1] mnormt_2.1.1         gridExtra_2.3        inline_0.3.20        sandwich_3.1-1       readxl_1.4.3        
##  [6] rlang_1.1.4          magrittr_2.0.3       multcomp_1.4-26      matrixStats_1.5.0    compiler_4.4.1      
## [11] mgcv_1.9-1           loo_2.8.0            reshape2_1.4.4       systemfonts_1.1.0    vctrs_0.6.5         
## [16] pkgconfig_2.0.3      arrayhelpers_1.1-0   crayon_1.5.3         fastmap_1.2.0        backports_1.5.0     
## [21] labeling_0.4.3       utf8_1.2.4           cmdstanr_0.8.0       rmarkdown_2.27       tzdb_0.4.0          
## [26] ps_1.7.6             xfun_0.45            cachem_1.1.0         jsonlite_1.8.8       highr_0.11          
## [31] psych_2.4.12         parallel_4.4.1       R6_2.5.1             bslib_0.7.0          stringi_1.8.4       
## [36] jquerylib_0.1.4      cellranger_1.1.0     estimability_1.5.1   knitr_1.47           zoo_1.8-12          
## [41] Matrix_1.7-1         splines_4.4.1        timechange_0.3.0     tidyselect_1.2.1     rstudioapi_0.16.0   
## [46] abind_1.4-8          yaml_2.3.8           codetools_0.2-20     processx_3.8.4       pkgbuild_1.4.4      
## [51] plyr_1.8.9           lattice_0.22-6       withr_3.0.0          bridgesampling_1.1-2 posterior_1.6.0     
## [56] coda_0.19-4.1        evaluate_0.24.0      survival_3.8-3       RcppParallel_5.1.9   ggdist_3.3.2        
## [61] xml2_1.3.6           pillar_1.9.0         tensorA_0.36.2.1     checkmate_2.3.2      stats4_4.4.1        
## [66] distributional_0.5.0 generics_0.1.3       hms_1.1.3            rstantools_2.4.0     munsell_0.5.1       
## [71] scales_1.3.0         xtable_1.8-4         glue_1.7.0           emmeans_1.10.6       tools_4.4.1         
## [76] mvtnorm_1.3-2        grid_4.4.1           QuickJSR_1.5.1       colorspace_2.1-1     nlme_3.1-166        
## [81] cli_3.6.3            fansi_1.0.6          svUnit_1.0.6         viridisLite_0.4.2    svglite_2.1.3       
## [86] Brobdingnag_1.2-9    gtable_0.3.6         sass_0.4.9           digest_0.6.36        TH.data_1.1-2       
## [91] farver_2.1.2         htmltools_0.5.8.1    lifecycle_1.0.4      MASS_7.3-64</code></pre>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
